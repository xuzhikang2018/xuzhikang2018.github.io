{"pages":[],"posts":[{"title":"MIT概率计算小组","text":"为什么Intel的概率计算会和MIT的概率计算挂钩呢 项目地址：http://probcomp.csail.mit.edu/ 为什么Intel的概率计算会和MIT的概率计算挂钩呢Mayberry在IEEE Spectrum的访谈中提到过：(Mayberry recommends a look at the work of Vikesh Mansighka, who leads the Probablistic Computing Project at MIT.) 同时根据MIT项目小组的新闻公告也提及过： June 2017: Vikash presented at the Technology Strategy and Leadership (TSLRP) meeting at Intel, including Intel’s CEO, management committee, and fellows. We briefed the company on new opportunities in probabilistic AI, including our work on building analogs of TenserFlow and the GPU for probabilistic programing.","link":"/2019/04/02/MIT概率计算小组/"},{"title":"Ubuntu_Linux使用笔记","text":"Ubuntu使用过程遇到的问题所做的笔记 ubuntu 解决“无法获得锁 /var/lib/dpkg/lock -open （11：资源暂时不可用）”的方法 ubuntu 解决“无法获得锁 /var/lib/dpkg/lock -open （11：资源暂时不可用）”的方法在ubuntu系统的termial下，用apt-get install 安装软件的时候，如果在未完成下载的情况下将terminal close。此时 apt-get进程可能没有结束。结果，如果再次运行apt-get install 命令安装如今，可能会发生下面的提示： 无法获得锁 /var/lib/dpkg/lock - open (11: 资源暂时不可用)无法锁定管理目录(/var/lib/dpkg/)，是否有其他进程正占用它？ 解决办法如下： 终端输入 ps aux ，列出进程。找到含有apt-get的进程，直接sudo kill PID。 强制解锁,命令sudo rm /var/cache/apt/archives/locksudo rm /var/lib/dpkg/lock","link":"/2019/04/04/Ubuntu_Linux使用笔记/"},{"title":"实用工具","text":"推荐一下使用的软件 一键生成视频中的字幕，详细介绍字幕通Yee Caption v2.0.0.05官方版 下载youtube（用浏览器自带的下载），网络上的视频，网站Apowersoft免费在线下载 youtube视频支持双语字幕，YouTube双字幕Chrome插件地址 看论文时，复制粘贴英文论文到翻译工具时，会按照原格式换行，原网站 另外一个自动翻译工具，调用google的API，CopyTranslate下载地址","link":"/2019/04/02/实用工具/"},{"title":"工作日志","text":"从2019年4月8日开始的工作日志 2019年4月2日-2019年4月8日 2019年4月2日-2019年4月8日这周主要内容包括： 整理了一下Intel有关概率计算的报道，其中包括3月1日，英特尔新上任的实验室主任Rich Uhlig接受IEEE Spectrum的访谈，从我理解的来看，概率计算（probabilistic computing）应该就是，概率机器学习，贝叶斯机器学习的内容，实现方式就是概率编程（probabilistic programming）,能够进行少样本的数据学习，理解并能处理自然数据中的不确定性。Intel概率计算报道 论文1《Probabilistic programming in Python using PyMC3》概率编程允许用户定义概率模型进行自动贝叶斯推理。马尔可夫链蒙特卡罗(MCMC)抽样的最新进展允许对越来越复杂的模型进行推理。这类MCMC，称为哈密顿蒙特卡罗，需要梯度信息，而这往往是不容易获得的。PyMC3是用Python编写的一个新的开源概率编程框架，它使用Theano通过自动微分来计算梯度，并在运行时将概率程序编译到C中以提高速度。与其他概率编程语言相反，PyMC3允许直接在Python代码中进行模型定义。由于不需要特定于领域的语言，因此具有很大的灵活性和与模型的直接交互。本文是对此软件包的教程式介绍。 论文2《Venture: an extensible platform for probabilistic meta-programming》,该论文是MIT概率编程团队2016年，介绍了Venture这个概率编程平台，Venture和其他编程语言相比最大的特点是可定制性，它把程序执行过程中查看概率选择的迹（trace）,以及搭建推理程序的基本模块，封装成函数提供给用户，可以在这基础上搭建新的推理方法和进行模型验证 在youtube看了有关概率编程的会议PROBPROG 2018，Talks前10个talk，有关介绍他们的编程库，还有关研究团队谈及他们对概率编程的应用。我的简单笔记","link":"/2019/04/08/工作日志/"},{"title":"博客使用","text":"记录下博客使用过程中遇到的问题 1.hexo d后 ERROR Deployer not found: git 2.Hexo添加Toc支持，生成文章目录 3.使用本地的Markdown编辑器 4.添加代码段高亮 1.hexo d后 ERROR Deployer not found: git解决办法 1npm install --save hexo-deployer-git 即可 2.Hexo添加Toc支持，生成文章目录Hexo本身是不支持生成文章目录的，通过如下的方法 参考博客Hexo添加Toc支持，生成文章目录 后面发现不能支持生成目录，是在markdown的笔记中写法不对 开头应该是：1&lt;!-- toc --&gt; 而不是有道云中的[toc] 3.使用本地的Markdown编辑器原来用有道云打开，但是这个蛋疼的是，不会保存本地，只能上传。于是乎下载一个编辑器。 逛了一圈，有收费的还有英文不支持中文的，还有没法调实时显示的。还是用很多人用的MarkdownPad吧。下载地址 安装之后蛋疼的是，右侧也没法实时显示，一直提示有个Bug。 win8和win10,没法实时渲染。解决办法：win10下MarkdownPad 2的html渲染出错解决 4.添加代码段高亮参考：markdwon快速入门","link":"/2019/03/30/博客使用/"},{"title":"博客搭建","text":"2019年3月29号星期五，我花了一个晚上的时间搭建个人的博客。用来记录下博客搭建过程中的坑。 1.搭建步骤 2 安装主题 3. 设置主题 4.编辑博客 1.搭建步骤参考博客：结合hexo在GitHub上搭建个人博客——全过程） 参考博客：超详细Hexo+Github博客搭建小白教程 搭建过程不难，主要过程为 创建github账户 安装Node.js 安装Git Git在某个文件夹下安装Hexo 连接Github与本地 期间遇到的问题是： 123XuZhikang@DESKTOP-U2I0R4H MINGW64 /e/Blog$ cd ~/.sshbash: cd: /c/Users/XuZhikang/.ssh: No such file or directory 原因是安装git后没有ssh 解决方法参考博客：在windows7下安装git后没有ssh 2 安装主题主题下载网站：https://hexo.io/themes/ 期间遇到一个问题：我最先下载的主题是hexo-theme-A-RSnippet,但是这个好像有问题，还是我没有设置正确，不能正常更新主题。 推荐另外的一个主题是：icuras 主题的安装的方法： 用git clone把主题下载下来 把解压的主题放在根目录下的themes下 更改根目录下的_config.yml文件的language 为zh-CN和theme为icarus 更改主题后：1234hexo g 生成静态网页hexo s 打开本地服务器hexo clean 清除缓存hexo d 上传到github 有一个技巧就是不必要每次更改之后都关闭本地服务器，再重新打开本地无服务，*直接刷新网页，可能更改就已经生效。 3. 设置主题主题安装之后，需要改变E:\\Blog\\themes\\icarus下的_config.yml参数 我改动的项为： menu:下英文改为中文 主页 归类 分类 标签 widgets下的：作者名字 作者title等 把social_link注释掉 link注释了，本来想吧github的链接改为邮箱，貌似不能 打赏的全部注释了 icarus的可玩性貌似没有那么高，如果想更多的去添加博客的网页的功能，可以试一试Next这个主题。 bilibili上有专门讲解的使用Hexo博客搭建的个人博客，使用Next主题来进行优化改造 4.编辑博客在E:\\Blog\\source_posts目录下打开Git bash, 创建新文章： 1hexo n &quot;博客搭建&quot; 这里提供一些基本方法 博客的开头你需要更改才能适配到分类和标签下 123456---title: 博客搭建date: 2019-03-29 23:18:54tags: 博客有关categories: 博客--- 为了只显示部分开头内容，下面加上 1&lt;!-- more --&gt; 添加更多的标签12345678---title: 博客搭建date: 2019-03-29 23:18:54tags: -博客有关 -测试等categories: 博客---","link":"/2019/03/29/博客搭建/"},{"title":"语音合成论文","text":"《Efficiency Trainable Text-To-Speech System Based ON Deep Convolutional Networks With Guided Attention》 Abstrace Introduction 1.1 Related Work 1.1.1 Deep Learning and TTS 1.1.2 Sequence to Sequence (seq2seq) Learning 2.PRELIMINARY 2.1 Basic Knowledge of the Audio Spectrograms Abstrace本文提出了一种新的基于深卷积神经网络(CNN)的文本语音转换(TTS)技术，该技术不需要任何递归单元。递归神经络(RecurrentNeuralNetwork，RNN)是近年来用于序列数据建模的一种标准技术，并已在一些前沿的神经TTS技术中得到应用。但是，训练RNN组件通常需要一台功能非常强大的计算机，或者需要很长的时间(通常是几天或几周)。另一方面，最近的其他研究表明，基于CNN的序列合成可以比基于RNN的技术快得多，因为它具有很高的并行性。本文的目的是提出一个替代的神经TTS系统，只基于CNN，可以减少这些经济成本的训练。在我们的实验中，使用配备两个GPU的普通游戏PC，仅在一晚(15小时)内就能充分训练所提出的深层卷积TTS，而合成语音的质量几乎可以接受。 IntroductionTTS(Text-to-Speech)正变得越来越普遍，并逐渐成为许多系统的基本用户界面。为了鼓励在各种系统中进一步使用TTS，开发一个方便的、可维护的、可扩展的TTS组件是非常重要的，该组件可供没有大型计算机的语音非专家、有需求的个人和小型团队访问。 然而，传统的TTS系统对他们来说不一定是友好的，因为这些系统通常由许多特定于领域的模块组成。例如，一个典型的参数化TTS系统是许多模块的精细集成，如文本分析器、 $F_0$ 发生器、频谱发生器、暂停估计器和根据这些数据合成波形的声码器等。 深度学习有时可以将这些内部构建块统一到一个模型中，并直接连接输入和输出；这种类型的技术有时被称为“端到端”学习(end-to-end Learning)。 尽管这种技术有时被批评为“黑匣子”，但是，名为Tacotron[2]的端到端TTS系统(直接从输入文本估计语谱图)最近取得了令人满意的性能，但没有基于领域特定知识的密集设计的参数化模型。 然而，Tacotron有一个缺点，就是它利用了许多经常性的设备，这些设备的培训成本很高，这使得没有豪华机器的普通实验室几乎不可能进一步研究和扩展它。 的确，有些人试图实现Tacotron的公开克隆，但他们正在努力复制出和人声一样清晰、令人满意的语音。 本文的目的是提出一种新颖的、方便的全卷积神经TTS-深卷积TTS(DCTTS)。 该结构在很大程度上类似于Tacotron，但它是基于与文献[7]类似的完全卷积序列对序列学习模型。 我们展示了这个便捷的TTS实际上在一个合理的设置下工作。 本文的贡献有两个方面：(1)提出了一种完全基于CNN的TTS系统，该系统比基于RNN的最先进的神经TTS系统训练速度快得多，而声音质量仍然可以接受。(1)提出了一种完全基于CNN的TTS系统，该系统的训练速度比基于RNN的神经TTS系统要快得多。 (2)提出了一种快速训练注意力的思想，我们称之为“引导注意”。 1.1 Related Work1.1.1 Deep Learning and TTS近年来，基于深度学习的TTS系统得到了广泛的研究，并取得了令人惊讶的显著成果。 基于深度神经网络的TTS系统包括Zen在2013年的工作，基于RNN的研究，例如，以及最近提出的技术，如WaveNet，Char2wav，DeepVoice1&amp;2和Tacotron。 他们中的一些人试图减少对手工设计的内部模块的依赖。 这一趋势中最极端的技术将是Tacotron[2]，它只依赖于MEL和线性谱图，而不依赖于任何其他语音特征，例如 $F_0$ 。 我们的方法在某种意义上接近Tacotron，因为它只依赖于这些音频信号的谱表示。 现有的时间序列预测方法大多采用RNN，这是一种自然的时间序列预测方法。 WaveNet是一个例外，它是完全卷积的。 我们的方法也是基于CNN的，但是我们对CNN的使用将不同于WaveNet，因为WaveNet是一种声码器，或者说是一种后端，它由前端组件提供的一些条件信息合成波形。 另一方面，我们的是一个前端(和大部分后端处理)。 我们使用CNN来合成一个语谱图，一个简单的声码器就可以合成一个波形。 1.1.2 Sequence to Sequence (seq2seq) Learning近年来，递归神经网络(RecurrentNeuralNetwork，RNN)已经成为一种将一个序列转换成另一个序列的标准技术，特别是在自然语言处理领域，如机器翻译，对话系统[19，20]等。 另请参见. 然而，基于RNN的seq2seq有一些缺点。一个是vanilla编码-译码器模型不能有效地将太长的序列编码成固定长度的向量。这个问题已经通过一种称为“注意”的机制[21]得到了解决，注意机制现在已经成为seq2seq学习技术中的一个标准概念；另见[1，sec]。 另一个问题是RNN通常需要很多时间来训练，因为它不太适合使用GPU的并行计算。为了克服这一问题，一些人建议使用CNN，而不是RNN，例如。一些研究表明，基于CNN的替代网络可以训练得更快，甚至可以优于基于RNN的技术。 Gehring等人。 [7]最近将seq2seq学习的这两个改进结合在一起。 他们提出了如何在基于CNN的seq2seq学习模型中使用注意机制的思想，并证明了该方法在机器翻译中的有效性。 实际上，我们提出的方法是基于与文献类似的思想。 2.PRELIMINARY2.1 Basic Knowledge of the Audio Spectrograms音频波形可以通过称为STFT和逆向STFT的线性映射相互转换成复谱图 $Z={Z_{f,t}} \\in \\mathbb{C}^{F’\\times T’}$ ，其中 $F’$ 和 $T’$ 分别表示频率仓和时间仓的数目。通常只考虑震级jzj=fjZf；tjg，因为它仍然有用于许多用途的有用信息，而且jzj在某种意义上与Z几乎相同，即存在许多来自震级谱图的相位估计(波形合成)技术，例如著名的Griffin&amp;Lim算法[27]；也请参见例如[28]。我们通常使用在线G&amp;L的RTISI-LA[29]来合成波形。本文将STFT谱图归一化为jZj(jZj=max(JZj)。，并转换回jzj jZj=。当我们最终需要合成波形时，；是强调前和强调后的因素。通过对jZj应用MEL滤波器组，也可以考虑MEL谱图S2 RFT0，(F F0)。这是语音处理中的一种标准降维技术。本文还通过每四个时间帧提取一个时间帧，将时间维度从T0降低到dT0=4e=：t，以加速Text2MEL的训练，如下所示。我们还将MEL谱图归一化为S(S=max(S)。。","link":"/2019/04/08/语音合成论文/"},{"title":"Pyro:Deep Universal Probabilistic Programming","text":"Pyro:Deep Universal Probabilistic Programming Absract Introduction Design Principle Project Openness and Development 4. Existing Systems 5. Experiments AbsractPyro是一种基于Python的概率编程语言，作为在AI研究中开发高级概率模型的平台。为了扩展到大型数据集和高维模型，Pyro使用基于PyTorch构建的随机变分推理算法和概率分布，PyTorch是一个现代GPU加速的深度学习框架。为了适应复杂或模型特定的算法行为，Pyro利用Poutine，一个可组合构建块库，用于修改概率程序的行为。关键词：概率编程，图形模型，近似贝叶斯推理，生成模型，深度学习 Introduction近年来，结构丰富的概率模型已经在AI的许多基本问题上展示了有希望的结果（Ghahramani（2015））。但是，大多数这样的模型仍然是从零开始实现的系统，这减缓他们的发展，限制他们的范围和可扩展性。概率编程语言（PPL）有望减轻这种负担，但实际上，更高级的模型通常需要针对特定​​应用定制的高性能推理引擎。我们确定了设计原则，使PPL能够在保持灵活性的同时扩展到高级研究应用，我们认为这些原则在Pyro PPL中完全实现。 Design Principle首先，适合开发最先进的AI研究模型的PPL应该具有表现力：它应该能够简明地描述具有数据依赖内部控制流的模型或潜在变量，其存在取决于其他潜在变量的值 ，或仅以封闭形式定义为非标准化联合分布的模型。 为了实现PPL，它必须是可扩展的：其近似推理算法必须能够无缝地处理AI研究中常见的大数据集和非共轭高维模型，并且应尽可能利用编译器加速。 针对研究模型的PPL应该是灵活的：除了可扩展性之外，许多高级模型还需要具有复杂的模型特定行为的推理算法。PPL应该使研究人员能够快速，轻松地实现此类行为，并应在模型，推理和运行时实现之间强制分离关注点。 最后，针对研究人员的PPL作为用户应力求最小化：为了最大限度地减少认知开销，它应该与现有语言和系统共享其大部分语法和语义，并与其他工具（如可视化库）配合使用。 从表2中可以清楚地看出，这四个原则经常是冲突的，其中一个是以牺牲其他原则为代价的。例如，过于灵活的设计可能非常难以有效和可扩展地实现，尤其是在同时将新语言与现有工具集成的同时。类似地，启用自定义推理算法的开发可能是困难的，而不限制模型表达性。在本节中，我们描述了我们在Pyro中做出的设计选择，以平衡所有四个目标。 Pyro嵌入在Python中，Pyro程序被编写为Python函数或callables，只有两个额外的语言原语（其行为被推理算法覆盖）：pyro.sample用于注释对具有内部随机性的函数的调用，以及pyro.param 用可以改变它们的推理算法学习参数。Pyro模型可能包含任意Python代码并以任意方式与其交互，包括通过pyro.sample的obs关键字参数表示非标准化模型。Pyro的语言原语可以与Python的所有控件构造一起使用，包括递归，循环和条件。因此，特定执行中随机变量的存在可能依赖于任何Python控件ow构造。 Pyro实现了几种通用概率推理算法，包括No U-turn采样器（Hoffman和Gelman（2014）），哈密顿蒙特卡罗的变体。然而，主推理算法是基于梯度的随机变分推理（SVI）（Kingma和Welling（2014）），其使用随机梯度下降来优化近似和真实后验分布之间的发散度量的蒙特卡洛估计。由于GPU加速的张量数学和通过PyTorch的反向模式自动分解，Pyro可以扩展到复杂的高维模型，并且由于在SVI中通过小批量数据计算的随机梯度估计，它可以扩展到大型数据集。 Pyro中的一些推理算法，例如SVI和重要性采样，可以使用任意Pyro程序（称为guide，来自webPPL的概念）作为近似后验或提议分布。给定模型的guide必须采用与模型相同的输入参数，并为模型中的每个无约束样本语句包含相应的样本语句，否则不受限制。然后，用户可以自由地表达关于后验分布的复杂假设，例如， 有条件的独立结构。与webPPL和Anglican不同，Pyro guide可能不依赖于模型内部的值。 最后，为了实现灵活性和关注点的分离，Pyro构建在Poutine上，这是一个效果处理程序库(Kammar et al)(2013)实现个人控制和簿记操作，用于检查和修改Pyro程序的行为，将推理算法实现与语言细节分离。 Project Openness and DevelopmentPyro的源代码可以在MIT许可下免费获得，由作者和开源贡献者社区开发，网址为https://github.com/uber/pyro，文档，示例和讨论论坛都在https上在线托管： //pyro.ai。在将代码合并到主代码库之前，通过持续集成服务自动运行全面的测试套件，以保持高水平的项目质量和可用性。 我们还发现，虽然PyTorch是张量运算和自动微分的宝贵基础，但它缺少一个高性能的概率分布库。因此，几位作者在PyTorch分发的上游做了大量的开源贡献。1受TensorFlow分发的启发，一个新的PyTorch核心库(Dillon et al)(2017年)。 4. Existing Systems 概率编程和近似推理是积极研究的领域，因此存在许多现有的概率编程语言和系统。我们简单地提到几个在Pyro开发中特别有用的东西，遗憾地省略（由于空间限制）许多系统，简单的直接比较更加困难。我们还强调，与传统的编程语言开发一样，我们的设计决策并非普遍适用于概率编程，也不适用于概率编程，而其他系统则有目的地使不同的tradof来实现不同的目标。 Stan（Carpenter等人（2017）是一种领域特定语言，用于描述一类受限概率的程序并在这些模型中执行高质量的自动推理。Church（Goodman et al。（2008））是Scheme的概率语言，是一种早期的通用概率编程语言，能够表示任何可计算的概率分布。Venture（Mansinghka et al。（2018））是一种通用语言，专注于表现力和灵活性以及自定义语法和虚拟机。Anglican（Tolpin等人（2016））和webPPL（Goodman和Stuhlmuller（2014））是Church的轻量级后继者，在通用编程语言Clojure和JavaScript中作为句法子集（Wingate等人（2011））嵌入。Edward（Tran et al。（2017））是一个基于静态TensorFlow图的PPL，它具有模型和推理的可组合表示。ProbTorch（Siddharth等人（2017））是一个建立在PyTorch上的PPL，专注于深度生成模型和开发变异推理的新目标。图灵（Ge et al。（2018））是一个嵌入Julia的PPL，具有可组合的MCMC算法 5. Experiments为了证明Pyro符合我们的设计目标，我们实施了几个最先进的模型。这里我们专注于变分自动编码器（VAE; Kingma和Welling（2014））和深马尔可夫模型（DMM; Krishnan等人）（2017）），非线性状态空间模型。 为了证明Pyro满足我们的设计目标，我们实现了几个最先进的模型。2这里我们重点介绍变分自动编码器(VAE；Kingma和Willing(2014)和DeepMarkovModel(DMM；Krishnan等人)。(2017)，这是一个非线性状态空间模型，已用于多种应用，包括音频生成和因果推理。VAE是深度概率建模的标准例子，而DMM有几个特点使其成为理想的比较点：它是一个高维、非共轭的模型，设计为适合于大型数据集；序列中潜在变量的数量取决于输入数据；它使用手工设计的后验近似。 Pyro派生的模型和推理程序几乎完全复制原始论文，除了我们使用蒙特卡罗估计而不是KL分歧项的精确解析表达式。我们使用MNIST数据集和2隐藏层MLP编码器和解码器网络，其中VAE的变化隐藏层大小#h和潜在代码大小#z以及数字化音乐3的相同数据集来训练DMM。 为了证明Pyro的抽象不会通过引入太多开销来降低其可扩展性，我们将VAE实现与惯用的PyTorch实现进行了比较.4在验证它们收敛到相同的测试ELBO之后，我们比较了计算一个时钟所需的wall clock时间。梯度更新，在单个NVIDIA GTX 1080Ti上平均超过10个时期的GPU加速小批量随机梯度变化推断（批量大小128）。图3显示Pyro和PyTorch版本之间的相对性能差距是适中的，更重要的是，它随着执行张量操作所花费的总时间的增加而缩小。 我们使用DMM来评估Pyro的灵活性和表现力。如图4所示，我们发现在5000个训练时期之后，我们能够快速简明地复制完整的DMM模型以及论文中报告的推理配置和定量结果。此外，由于Pyro的模块化设计，我们还能够通过自回归（（IAF）构建具有更具表现力的近似后验的DMM变体（Kingma等人（2016）），用几行代码改善结果，计算成本可忽略不计。","link":"/2019/04/09/Pyro-Deep-Universal-Probabilistic-Programming/"},{"title":"Intel概率计算报道","text":"1.英特尔实验室介绍 神经拟态计算简介 概率计算简介 2.概率计算使人工智能进入下一个时代 3.英特尔开始为人工智能进行概率计算的研发工作 4.英特尔实验室主任谈量子，概率和神经拟态计算 1.英特尔实验室介绍英特尔实验室与全球领先的研究机构合作并为其提供赞助。其中包括著名的大学科技中心，国家科学基金会和半导体研究公司。英特尔和这些机构的研究正在改变机器的思考，学习和适应方式。 神经拟态计算简介随着人工智能工作变得更加多样化和复杂化，而当今主流计算架构将达到极限。英特尔的研究人员认为，神经拟态计算提供了前进的方向，并且正在推进旨在提供百万兆级运算的研究，这将提高传统计算能力并为新的计算应用开辟可能性。2017年9月，英特尔实验室推出了第一款具有自学能力的神经拟态研究芯片“Loihi。”英特尔与领先的大学和研究合作伙伴合作，对Loihi芯片进行测试，该芯片具有模拟大脑基本功能的数字电路，使机器学习更快，更高效，同时降低计算功耗需求，帮助处理复杂的数据集和问题。 由英特尔实验室构建的测试板展示了英特尔Loihi神经形态研究芯片的功能。（来自：英特尔公司） Intel给出的神经拟态视频：1.神经拟态，智能和计算的未来 2.神经拟态，旨在模拟人类大脑 3.Intel实验室中的Loihi 概率计算简介计算机的构建是为了帮助人们完成精确的生产任务，如果使计算机有效地处理大规模概率，可以将当前系统和应用程序从高级计算辅助工具，转变为智能合作伙伴以进行理解和决策。2018年5月，英特尔宣布增加对概率计算研究的投资，并呼吁学术界和初创社区与Intel合作，将实验室中的概率计算推进到这些载体：基准应用，对抗性攻击缓解，概率框架，以及软件和硬件优化。在接下来的几年里，英特尔的领导者预计该公司在概率计算方面的研究将带来可靠性和安全性方面的重大改进， Mayberry：Computing In the Area of AI 原网站链接：https://newsroom.intel.com/press-kits/intel-labs 2.概率计算使人工智能进入下一个时代新闻时间：2018年5月 Intel加速在概率计算方面的研究并诚邀合作伙伴探讨下一代人工智能 By Dr. Michael Mayberry 人工智能（AI）的潜在影响从未如此强大 - 但只有AI能够提供更智能，更直观的答案，我们才能取得成功。 今天人工智能的一个主要障碍是，提供给计算机的自然数据在很大程度上是非结构化的并且“嘈杂”。 人类很容易对自然数据进行处理。例如：如果你在住宅街道上开车并在你面前看到一个球滚动，你会停下来，假设有一个小孩子在球的后面不远处。今天的计算机不这样做。它们旨在帮助人们完成精确的生产任务。使计算机有效地处理大规模概率，是我们将当前系统和应用程序，从高级计算辅助工具转换为智能合作伙伴，以进行理解和决策的能力的核心。 这就是为什么概率计算是人工智能的一个关键组成部分，也是应对这些挑战的关键。概率计算将允许未来的系统理解和计算自然数据中固有的不确定性，这将使我们能够构建能够理解，预测和决策的计算机。 今天在英特尔，我们正在观察依赖于对嘈杂的自然数据进行分析的应用的空前增长 - 不同甚至相互冲突的信息。这些应用旨在帮助人们提供更高水平的智能和对其运行环境的认识。切入这个嘈杂的雷区对我们将计算机转变为智能合作伙伴的能力至关重要，这些合作伙伴可以理解并信息，并以人类般的忠诚度般，采取行动。 对概率计算的研究并不是一个新的研究领域，但高性能计算和深度学习算法的改进可能会使概率计算进入一个新时代。在接下来的几年中，我们预计概率计算的研究将导致AI系统的可靠性，安全性，可维护性和性能的显着提高，包括专为概率计算而设计的硬件。这些进步对于将应用程序部署到现实世界至关重要 - 从智能家居到智能城市。 为了加快我们在概率计算方面的工作，英特尔正在增加对概率计算的研究投资，我们正在与合作伙伴共同努力实现这一目标。 建立英特尔概率计算战略研究联盟 实现概率计算的全部潜力涉及计算技术中多个领域。今天，英特尔强调了其对新兴计算架构的整合，协作实施以及健全的生态系统支持战略的承诺，向学术界和初创社区发出呼吁，通过与Intel合作，将概率计算从实验室推进到现实：基准应用程序，对抗性攻击缓解，概率框架以及软件和硬件优化。 关注下一步是什么 我们非常渴望看到推进概率计算的提议，并继续这项研究，有可能提高人工智能可以帮助我们实现的目标。学术提案预计将在5月25日之前提交，其中我们将选择最好的研究团队。 我们通过对神经形态计算的研究开始了这一旅程 - 专注于我们对人类大脑及其相关计算过程的理解。3月1日宣布的神经拟态研究界的开始也正在进行中，我们计划继续扩大我们在云上的Loihi，以便研究人员能够使用先进硬件。我们看到2019年在单一系统上达到1000亿个突触。 此外，作为与普林斯顿大学合作的一部分，英特尔已经致力于解码大脑并推进神经科学的下一阶段。我们期待通过我们的概率计算工作进一步了解人类理解问题和决策的流程。 原网站链接：概率计算使得人工智能进入下一个时代 3.英特尔开始为人工智能进行概率计算的研发工作时间：2018年5月10日 英特尔今天宣布，它正在组建一个战略研究联盟，将人工智能提升到新的水平。自治系统没有足够好的方法来应对现实世界的不确定性，而且它们没有足够好的方法来理解传感器的不确定性如何影响他们需要做出的决策。根据英特尔首席技术官Mayberry的说法，答案是“概率计算”，他说这可能是人工智能的下一波浪潮。 IEEE Spectrum:这项新研究的主旨是什么？ Mayberry:我们正试图弄清楚下一波人工智能是什么。AI的原始浪潮基于逻辑，它基于写下规则; 它最接近你所谓的经典推理。当前的AI浪潮围绕sensing and perception - 使用卷积神经网络扫描图像并查看是否存在感兴趣的东西。这并不人类认知世界的方式。 假如你听到汽车警报声。您会自动考虑与拥有的数据一致的不同场景，并且还会意识到没有的数据。你会推断一个概率。也许概率是在确定警笛是来自你前面还是后面。或者是否会让你迟到会议。您自动执行机器遇到问题的事情。我们在现实生活中始终遇到这些情况，因为目前的情况始终存在不确定性。 目前人工智能和深度学习系统被认为是脆弱的。意思是他们对答案过于自信。他们会毫不犹豫地说，它认为图片中有某些内容可以识别它。但在许多情况下，概率是不正确的; 信心并不像[AI]认为的那么高。 因此，我们想要在一般研究重点中做的是弄清楚如何在我们的推理系统和我们的传感系统中建立概率。而且真的有两个挑战。一个是你如何用概率进行计算，另一个是如何用概率存储记忆或场景。 所以我们已经做了一定数量的内部工作和学术界，我们已经决定在这里有足够的东西我们将开始研究社区。目标是让人们分享他们对它的了解，进行协作，编写软件时如何表示概率，以及如何构建计算机硬件。我们认为这将是……第三波人工智能的一部分。 IEEE Spectrum:概率计算用于描述过去与AI无关的许多事情，例如随机计算(stochastic computing)和容错计算(error-tolerant computing)。它到底是什么样的？ Mayberry:我们使用[概率计算]与以前略有不同。例如，随机计算即使有错误也能获得足够好的答案。模糊逻辑实际上更接近我们在这里讨论的概念，在处理信息时，你故意跟踪不确定性。还有统计计算，这实际上更像是一种软件方法，你可以通过构建树来跟踪概率。所以，这些不一定是新概念。但我们打算以不同于过去的方式应用它们. IEEE Spectrum:这会涉及新型设备吗？ Mayberry:我们最初会通过查看算法来接近它。我们对英特尔的偏见是构建硬件，但如果我们不真正了解使用模型将如何演变或算法将如何演变，那么我们就有可能过早地承诺使用这条路径。因此，我们最初将围绕算法和软件框架进行研究。你必须尽早考虑安全问题。这些是我们将要接近的事情。 （Mayberry推荐了了Vikesh Mansighka 的工作， 他是麻省理工学院Probablistic Computing Project的负责人。） IEEE Spectrum:这如何适应英特尔现有的AI工作？ Mayberry:这是一个包含我们现有工作的大型系统的一部分…. 您不希望您的逻辑系统假设您的传感是100％准确的，但您不希望传感器必然也有关于置信度的错误信息。因此，您必须围绕这两个组件如何相互通信并跟踪这类信息来构建一个系统。因此传感系统可能会报告“我的亮度发生了变化” - 因此我的答案比以前更有信心。 跟踪这类信息是系统设计的一部分。从软件框架的角度来看，我们并不确切知道如何实现这一点。 IEEE Spectrum:有哪些潜在的应用？Mayberry:当然，我们的目标之一是拥有更好的自动机器，无论是汽车还是家用机器人，还是类似的东西。我们认为[概率计算]是使系统更加健壮的重要部分。受到高度约束的系统不太可能需要这种能力。您将系统置于一个开放的环境中的时间越多，有更多的东西需要改变，您就越有可能需要补充我们今天使用的系统。我们当然希望这将在几年内变成产品，但这是前路线图。所以我们现在不承诺任何事情。原网站链接：英特尔开始为人工智能进行概率计算的研发工作# 4.英特尔实验室主任谈量子，概率和神经拟态计算4.英特尔实验室主任谈量子，概率和神经拟态计算 报道时间：2019年3月1日 去年年底接管英特尔实验室的Rich Uhlig讨论了英特尔对未来计算的愿景 英特尔通过不断寻找使CPU更快，更高效的方法，为自己做得非常好。但随着摩尔定律的终结，英特尔一直在探索利用创新架构扩展计算的方法。 量子计算是其中一项举措，英特尔实验室一直在测试自己的49-qubit处理器。除此之外，英特尔实验室正在探索神经形态计算（模拟结构，并希望通过人工神经网络模拟人脑的一些功能）以及概率计算，旨在帮助满足量化人工智能不确定性的应用需求。 Rich Uhlig自2018年12月以来一直担任英特尔实验室的主管，自1996年以来一直在英特尔工作（最近担任英特尔实验室的系统和软件研究总监），所以他似乎很有资格担任该职务。我们与Uhlig讨论了量子，神经形态和概率计算，这些系统将如何帮助我们管理AI，以及这些技术将使这些技术成为可能的事情至少应该引起我们的关注。 IEEE Spectrum:根据英特尔量子计算的时间表，我们目前处于“系统阶段”。这意味着什么，我们将如何过渡到商业阶段？ Rich Uhlig：在英特尔，我们专注于开发商业上可行的量子计算机，这需要比量子比特本身更多。我们已经成功制造了一个49比特的超导芯片，这使我们能够开始将量子处理单元（QPU）集成到一个系统中，在这个系统中我们可以构建所需的所有元件，使量子位同时协同工作以改善效率和可扩展性。我们正在努力创建一个可行的量子系统，从50个量子比特扩展到商业系统所需的数百万个量子比特。 IEEE Spectrum:我们希望通过神经形态计算来模仿它的大脑有什么好处？ Rich Uhlig：大脑的魅力在于它能够实时处理高度复杂的信息，并且能量很少。我们的目标不一定是模仿大脑，而是要了解为大脑提供如此令人印象深刻和高效的功能的原则，然后将这些原则应用于我们可以构建的芯片。许多与细粒度并行性，动态计算，信息时间编码，事件驱动操作等相关的原则直接激发了我们认为将导致两者的突破性增益的新特性，体系结构和算法。计算系统的能力和效率。 IEEE Spectrum:为什么概率计算足以使英特尔的量子和神经拟态并列？ Rich Uhlig：概率计算使我们能够处理我们周围的自然数据的不确定性，并通过理解数据和模型的不确定性来预测世界上的事件。只有当我们知道如何用概率分布模拟我们周围的世界时，才能预测场景中接下来会发生什么，以及我们的行动的影响。通过使用概率方法增强深度学习所提供的不确定性测量打开了理解人工智能系统为何做出决策的大门，这将有助于解决人工智能系统中的偏差等问题。 我们对概率计算的研究实际上是关于建立一种评估下一波人工智能性能的新方法 - 一种需要对“噪声”数据进行实时评估的方法。第一代AI系统专注于逻辑：预编程规则。第二波人工智能旨在提高感知和感知信息的能力，利用神经网络随着时间的推移进行学习。但是，这些解决方案都不能做到人类在我们在真实世界自然而然地做的事情。无法根据您手头的数据思考多种潜在的情景，同时意识到您没有的潜在数据。 为什么这个概念如此重要的一个例子是，如果你正在开车并且看到一个足球滚到街上，你的直接和自然的反应是停车，因为我们可以假设一个孩子在球后跑，并且离的不远。 根据自然数据的经验和人类行为的假设，驾驶员决定停车。但是，传统的计算机很可能无法实时得出相同的结论，因为今天的系统没有被编程为有效地挖掘噪声数据并根据环境意识做出决策。但是，对于像自动驾驶这样的应用程序，可能需要一个概率系统来调用一个可以快速评估情况并立即采取行动。 IEEE Spectrum:是否需要用于神经形态和概率计算的新型设备？这些需要具备哪些属性？ Rich Uhlig：目前，我们相信受这些新计算范例启发的创新可以为使用当今工艺技术制造的芯片提供有意义的收益。但是，在未来几年，并且要继续发展，我们将需要设备级的进步。在神经形态计算的情况下，将需要更密集的存储器技术和具有非易失性塑性动力学的新材料。在概率计算的情况下，它将扩展AI解决方案以包括能够以概率分布进行计算的新颖且有效的实现。对于神经形态和概率计算，最终的效率增益可能需要利用物理噪声源的设备和电路直接体现随机动态。 IEEE Spectrum:新设备是否会影响英特尔所关注的计算类型，或者是为设备设计新的计算方法？ Rich Uhlig：它是两个方向的相互作用。设备技术和摩尔定律的发展使新架构成为可能，新的架构理念正在推动未来设备技术的需求。但是，对两者的真正驱动要求是我们在世界上收集的指数数量的新数据。这些数据的收集，存储和分析将需要新的计算模型，并有可能为我们所有人创造难以置信的新体验。 IEEE Spectrum:AI的未来是否会刺激神经网络？ Rich Uhlig：脉冲神经网络（SNN）是当今用于深度学习的人工神经网络的自然继承者。通过将时间动态直接集成到其操作中，SNN非常适合于处理真实的感觉数据，例如声音或视频，尤其是在需要快速响应和适应时。从算法的角度来看，脉冲神经元为构建神经网络提供了一种原则性方法，可以及时处理事件，例如支持一次性学习或做出决策。从实现角度来看，脉冲允许神经形态体系结构利用这些算法的高度稀疏活动来提高能效。这些优势为边缘设备提供了巨大价值，例如在制造车间，自动驾驶车辆， IEEE Spectrum:您认为大多数人将从中受益的量子和神经形态计算的第一个实际应用是什么？？ Rich Uhlig：量子计算将解决传统计算机需要数月或数年才能解决的问题，或者今天完全难以解决的问题。这可能包括药物开发，财务建模和气候预测等问题。对于神经形态芯片，第一个应用可能是那些需要实时定制预训练功能的应用，这取决于特定设备的独特环境。例如，神经形态芯片可以使语音识别系统能够自主地适应以识别具有强烈重音的用户，或者在动态环境中控制机器人手臂。 IEEE Spectrum:有没有人担心使用这些计算技术会让我们更难理解为什么未来的计算系统会做出他们做出的决定？决策在何种程度上可以解释，我们如何改进？ Rich Uhlig：这是一个有效的关注和活跃的研究领域，你可以称之为“可解释的人工智能”。例如，我们绝不会建议推出一种可能危及人类安全的设备，如果它的工程师无法清楚说明它是如何或为什么会出现在它做了。我们认为概率计算可能提供一些优势，因为它提供了一个框架，用于理解答案中的潜在错误，这可能对更高级别的策略有用，这些策略决定系统最终如何参与物理世界。","link":"/2019/04/01/Intel概率计算报道/"},{"title":"研电赛_语音合成","text":"论文《基于卷积神经网络的语音合成声码器研究》 中科大 2018年 第一章 绪论 1.1 语音合成技术概述 1.2 语音信号的生成机理 1.3 现阶段主流语音合成方法 1.3.2 统计参数语音合成 1.4 语音合成声码器 1.4.1 线性预测分析合成器 1.4.2 共振峰合成器 1.4.3 STRAIGHT分析合成算法 1.5 该论文的研究目标与内容 第二章 基于卷积神经网络的语音合成声码器 2.1 WaveNet简介 2.2 语音合成声码器从基频、频谱等声学特征中重构语音波形，是统计参数语音合成系统中不可或缺的一部分。 但是以STRAIGHT为代表的传统源－滤波器结构声码器仍然存在频谱细节丢失、相位依赖人工设计以及线性滤波框架等问题。 2016年， DeepMind研宄者提出了直接对语音波形建模与生成的深度卷积神经网络结构， 并将其用于从文本特征预测语音波形， 取得了优于传统统计参数方法的合成语音自然度。 论文工作： 设计实现了基于卷积神经网络的话者相关语音合成声码器 提出了神经网络声码器的话者无关及自适应训练方法， 在目标语音数据有限情形下实现高质量声码器的训练； 设计实现了多分辨率层级化网络结构， 提升语音合成声码器的生成效率。 论文整体安排：概述语音合成技术，波形拼接合成方法和统计参数合成方法， 然后回顾了常用的语音合成声码器并分析其优势和不足。 DeepMing研宄者提出的WaveNet模型，卷积神经网络对语音波形建模的动机与出发点，并详细介绍本文设计实现的基于卷积神经网络的语音合成声码器模型。该模型构造了一个上采样网络实现了声学特征采样率与输出语音采样率的匹配， 然后将变换后的声学条件信息加入网络激活函数中指导语音的生成。 第三章首先回顾了说话人自适应技术历史， 介绍了语音识别与语音合成任务中的自适应方法； 然后介绍了本文提出的神经网络语音合成声码器的话者无关及自适应训练方法； 最后利用自然声学特征和声学模型预测声学特征作为输入重构语音， 实验验证了自适应训练的有效性。 第四章首先分析了神经网络语音合成声码器生成语音速度较慢的问题， 其次介绍了基于扩张卷积神经网络的语音频带扩展工作， 然后在此基础上提出了多分辨率层级化生成网络， 最后实验评估了该模型的效率提升结果以及合成语音质量 第一章 绪论语音人机交互技术包含语音识别（将人类语音转换为文字) ,自然语音理解（理解自然语言的意思） 以及与语音合成（将文字转换为对应语音） 这三种高难度技术。技术上分为波形拼接语音合成方法和统计参数语音合成方法两大流派。在目前的统计参数语音合成系统中， 合成语音质量主要受声码器、声学模型建模精度以及过平滑效应影响。近年来， 随着深度神经网络（Deep Neural Network, DNN） 在语音合成声学建模中的广泛应用， 声学模型精度与合成语音自然度均得到了有效改善。但是在声码器特征提取与波形重构过程中的音质损失仍然制约着统计参数合成语音质量的进一步提升。研宄高质量的语音合成声码器对语音合成有至关重要的作用， 可以有效提升语音合成系统上限。 1.1 语音合成技术概述语音合成可以分为三类： 文字按规则映射到语音波形， 简称文语转换（Text-To-Speech,TTS) 概念按规则映射到语音 意向按规则映射到语音 图1.1展示了一个典型的语音合成系统。文语转换是一个层次化的信息处理过程，而且层次越高信息越丰富，这也是文字转换到语音的难点。首先，根据给定语言的词典和相应的语法规则在语言层、语法层和语义层分析，以获得不同层级的文本信息(包括词组，短语，句子和韵律划分信息等)：然后对不同层级的文本信息做韵律分析，获到语音级别的韵律信息(包括谱参数，基频，时长)；最后 根据预测的声学参数利用语音合成声码器合成语音波形或者从音库数据中挑选最优的波形单元拼接合成语音。 文语转换系统的层次化信息处理过程可以划分为前端的文本分析和后端的语音合成。前端文本分析将字符型文字转换为层次化的语音学中间表征；后端语音合成则将这些层次化表征映射到韵律特征，然后根据韵律信息利用合成声码器合成语音或者利用单元挑选与波形拼接方法合成语音。本文研究工作聚焦在后端的语音合成部分，具体研究高质量语音合成声码器的构造，将韵律参数转换成自然度高音质好的语音波形。 1.2 语音信号的生成机理了解语音产生的物理过程, 然后才能用计算机精确地模拟语音信号产生过程，使得计算机像人类一样自如的说话。语音生成系统可以分为三个部分，如图1.2所示： (1)激励系统：人体肺部呼出的空气经过声门的快速开启闭合产生激励振动, 因此将声带以下部位称之为激励系统。(2)声道系统：声门到嘴唇之间的气流通道被称之为声道，其形状主要由嘴唇、 颚和舌头等发音器官的位位置决定。气流撞击声门上的声带进行振动，然后 通过声道响应变为语音；颅神经会根据发音内容控制肌肉调整声道形状，从而发出不同的声音。(3)辐射系统：指经过声道滤波后的忾流从嘴唇、鼻孔向空间辐射过程。 对人发声的认识导致了对声道系统模型的不同建模 1.3 现阶段主流语音合成方法基于机器学习准则利用大量语音数据训练的语音模型是目前主流的语音合成方法，单元挑选与波形拼接方法和统计参数语音合成方法是当下应用最广泛的两种模型。 波形拼接合成系统的优点是用于拼接的波形单元来自自然音库，所以其合 成的语音和自然语音比较接近，自然度比较高；但是它音库制作周期长，人工录音、标注成本较高，并且它对于不同语种、语言环境的推广能力差，系统占用空间大，魯棒性不好。缺点是：语库构建周期太长，合成语音质量不稳定以及合成系统的可扩展性太差。 1.3.2 统计参数语音合成语音合成方法，其可以借助机器学习方法自动训练声学模型，进而构建TTS系统, 所以又被称为可训练的语音合成(Trainable TTS）。Trainable TTS首先利用声码器提取语咅波形的声学参数（基频、倒谱等参数)，然后将标注数据（主要包括 音段切分和韵律标注）作为输入、声学参数作为输出利用机器学习方法训练对应的声学模型，最后以声学模型为基础加上后端的合成声码器构成统计参数合成系统，该系统结构如图1.3所示。 研究者提出了若干种统计参数语音合成方法，其中基于隐马尔可夫模型 (Hidden Markov Model,HMM)的统计参数语音合成方法得到了最为充分的发展，并取得了良好的效果。在人的发音过程中，人脑根据语言需求和语法规则发出一系列指令（不可观察的隐状态）指挥发音器官发出可观察的语音参数流，这是一种双重随机过程，与隐马尔可夫链非常类似。因此通常用隐马尔可夫模型对声学参数建模，近几十年来该模型在自动语音识别任务中取得很好的 效果。早期研究者将HMM用于语音合成任务，由于其模型训练算法不成熟，语音合成声码器性能也比较差，导致其合成语音质童比较差，与波形拼接合成方法 相比有较大的差距。不过随着模型训练算法的改进以及高性能的STRAIGHT分析合成算法的提出，其合成效果有了明显的提高。相对于单元挑选与波形拼接合成系统，基于HMM的统计参数合成可以在短时间内、基本不需要人工干预的情况下自动构建一个新的系统，而且对于不同发音人、不同发音风格、甚至不同语种的依赖性非常小。但是它也有一些缺陷，如采用混合高斯模型（Gaussian Mixture Model, GMM)对声学参数建模，并且使用最火似然准则训练GMM-HMM 模型，导致模型精度不够、参数生成过平滑，并且最后合成语音波形很依赖声码器性能。这些问题使得基于HMM的统计参数合成系统合成语音质童较差，自然度不够，人工痕迹明显。 随着神经网络理论发展以及行之有效的训练方法引入,研究者将DNN 用于语音识别任务中并取得巨大成功。2013年谷歌学者将DNN用于语音 合成任务的声学建模，实验表明其声学模型精度与合成语音自然度相对于 基于HMM的统计参数建模方法均得到了有效改善。DNN是一种前馈神经网络 (FeedforwardNeural Network)，基于DNN的声学模型如图1.4所不，这种层级化结构和人类的发音过程有一定相似之处。==该模型的输入是–帧语音数值化的文本特征，包含该帧韵律信息对各音素的文本上下文问题的回答结果，还有当前音素时长信息以及该帧在当前音素的位罝信息：模型输出则是这一帧的声学特征参数（如基频、倒谱等)==。模型采用输出预测的声学参数与当前帧的真实声学参数的均方误差作为损失函数，采用反向传播算法优化网络参数，最小化模型预测声学参数的均方误差。 虽然利用DNN替换HMM对声学特征建模，改善了声学参数生成精度，但是合成声码器性能仍然停留在STRAIGHT分析合成算法阶段。STRAIGHT分析 合成算法是基于语音信号的诸多假设（如语音帧是平稳过程，相位依赖人工设计等)提出的模型，其重构语音与原始录音还有一些差别。本文研究基于卷积神经网络的语音合成声码器，有望提升统计参数语音合成系统的合成语音质量。 1.4 语音合成声码器合成质量依赖于声学建模精度和对应的合成声码器性能。常用的合成声码器如下： 源-滤波器思想设计的，声音由激励和相应的声道滤波器形成。其中激励通常分为类似噪声激励和周期性脉冲串，非浊音语音信号由类噪声激励形成，浊音信号由周期性脉冲串形成。但是某些浊辅音信号不能单纯由上述的某一种激励产生，需要两种激励共同作用形成。源-滤波器产生语音时，首先系统会预先准备好相应的激励特征和频谱特征，根据基频和淸浊标志生成相应的激励，然后根据频谱参数改变声道滤波器形状，以合成出指定的语音，其结构框图如图1.5所示。线性预测分析 (Linear Prediction Coefficient, LPC)合成、共振峰合成以及 STRAIGHT 分析合成 算法是这种思想衍生的比较常用的语音合成方法，下面将对这三种方法进行简单介绍。 1.4.1 线性预测分析合成器用线性误差滤波器来模型声道响应，详细描述见原文 1.4.2 共振峰合成器人的声道模型其实看成一个谐振腔，这个腔体的谐振频率与语音信号的共 振峰一一对应，基于这种谐振腔思想的合成方法叫做共振峰合成。 详细见原文 相比于LPC方法，共振峰合成在参数调整合适的情况下，可以产生较高质量的合成语音。共振峰合成最大的优点是谐振器理论与人的发音机理契合，模型 参数都有明确的物理含义，通过调整模型参数可以改变共振峰位置，从而合成出不同发音风格的语音波形。然而由于共振峰合成器模型复杂，声道滤波器参数较多，很难将所有的谐振器参数都调整至最优，所以其实际合成音质往往也难以达到TTS系统的要求。 1.4.3 STRAIGHT分析合成算法前面介绍的线性预测分析合成器和共振峰合成器在输入自然声学参数时可以重构出音质不错的语音，但是在输入预测的声学参数时重构语音质最较差，不能满足实际语音合成系统的要求。STRAIGHT分析合成算法即使输入预测的声学参数也能重构音质不错的声音，该方法一定程度上提升了统计参数语音合成的语音质量。下面将介绍STRAIGHT分析合成算法及其算法流程。 STRAIGHT算法利用源-滤波器的思想，通过提取语音信号中的基频以及谱信息，来重构语音信号；在重构的过程中，可以实现对基频、时长等参数进行有效的调整，同时保证语音音质损失较小。它包含下面三个重要环节：去除周期影响的谱估汁，平滑可靠的基频轨迹提取，基于听觉感知的合成器实现。 假设是浊音信号，其谱包络$S(w,t)$是频率轴与时间轴上二维信号。实际的语音信号可以用下式的调频调幅信号表达： 其中 $\\alpha_k(t)$。是第$k$个谐波的时变幅度， $w(\\tau)$ 是时变的基频角频率， $w_k(\\tau)$ 是第 $k$ 个谐波的基频扰动，$\\phi_k$ 第 $k$ 个谐波在 $t_0$ 时刻的初始相位。在分析语音信号的谱结构时，加窗计算短时谱是一种常用的手段。而在对 $s(t)$ 进行短时傅立叶分析时，得到的短时谱由于受到加的时间窗的影响，在时间轴以及频率轴上都呈现出一定的周期性，并不能反应谱包络 $S(w,t)$ 的真实情况。因此需要去除 $F(w,t)$ 中的周期性影响，还原出满足要求的谱包络 $S(w,t)$ 首先采用基音同 步并叠加补偿窗的方法来计算频谱，并在时域上平滑，来消除时间轴的周期性影响：然后利用三角窗对谱参数进行频率轴上的一维平滑即可得到圾终的消除周 期性的谱包络。接下来需要对语音信号进行小波分析，得到信号的“基成分”即 谐波信号，从谐波信号中提取精确稳定的基频。最后在合成语音时，输入待合成 语音的蕋频曲线数值和经过时间轴和频率轴平滑后的二维谱包络，基于基音同 步叠加和最小相位冲击响应的方法合成目标语音。STRAIGHT分析合成算法在合成过程中还可以实现时长、基频和谱参数的灵活调整。 在实际语音合成过程中，STRAIGHT算法提取的谱包络维数较高无法用于直接建模，因此研究将谱包络特征转换为维数较低的频谱特征参数。通常使 用的参数有线谱频率（Linear Spectral Frequencies, LSF)参数和Mel倒谱（Mel-Cepstrum)参数。 1.5 该论文的研究目标与内容现阶段统计参数语音合成系统主要使用STRAIGHT声码器来实现从声学特 征到语音波形的重构。STRAIGHT声码器虽然能从模型预测的声学参数中恢复出较好的语音，但是其重构语音仍存在频谱细节丢失，相位依赖最小相位假设和人工设计等问题，导致重构语音自然度下降，和原始录音存在一定差距。 本文以基于卷积祌经网络的语音合成声码器为研究目标。在第2章中先介 绍了WavcNetN络结构，然后构建了基于卷积神经网络的语音合成声码器。这种神经网络声码器直接在波形层面建模，避免了频谱细节丢失，较奸的恢复了语音相位信息，但是也存在一些不足。一方面利用目标说话人数据基于机器学习方法构建的话者相关神经网络声码器，模型泛化能力弱，同时对目标说话人数据量依赖较大；另一方面由于模型自回归的生成方式和网络参数规模较大，导致模型合成语音效率较低。在第3章和第4章中将分別对这两点不足提出改进方法。 第二章 基于卷积神经网络的语音合成声码器STRAIGHT存在频谱细节丢失，语音相位依赖最小相位假设和人工设计等问题。DeepMing研究者提出的WaveNet模型，实现从==倒谱基频语音声学特征中重构语音波形==。 2.1 WaveNet简介 2.2","link":"/2019/04/08/研电赛-语音合成/"},{"title":"数字IC设计面试100题","text":"主要来自知乎的整理 1. 什么是同步逻辑和异步逻辑？ 2.同步电路和异步电路的区别： 3. 时钟设计的实质： 4. 建立时间和保持时间的改变： 5. 为什么触发器要满足建立时间和保持时间？ 6. 什么是亚稳态？为什么两级触发器可以防止亚稳态？ 7. 系统最高速度计算（最快时钟频率）和流水设计思想？ *8.时钟约束的基本概念和基本策略？ 9.附加约束的作用？ 10.FPGA设计工程师努力的方向： 11.对于多位的异步信号如何进行同步？ 12.FPGA和CPLD的区别？ 13.锁存器（latch）和触发器(flip-flop)的区别？ 14.FPGA芯片内有哪两种的存储器资源？ 15.什么是时钟抖动？ 16.FPGA设计中对时钟的使用 17: FPGA设计中如何实现同步时序电路的延时 18.FPGA中可以综合实现为RAM/ROM/CAM的三种资源及其他注意事项？ 19. Xilinx中与全局时钟资源和DLL相关的硬件原语 20. HDL语言的层次概念？ 21:查找表的原理与结构？ 22.IC设计前端到后端的流程的EDA工具？ *23.寄生电容效应在IC设计中怎样克服和利用 24.设计题1–用触发器和逻辑门设计一个一位加法器 25. 设计自动饮料贩卖机 *26.什么是“线与逻辑”，要实现它，在硬件特性上有什么具体要求？ 27.什么是竞争冒险？怎么判断？如何消除？ *28.常用的逻辑电平？TTL和CMOS电平可以相互直连吗？ 29：IC设计中同步复位与异步复位的区别？ 30.Moore与Meeley状态机的特征？ 31.多时钟域设计中，如何处理信号跨时域问题？ 32.说说静态、动态时序模拟的优缺点？ *33.一个四级的Mux，其中第二级为关键信号，如何改善timing? 34.给出一个门级图，又给出了各个门的传输延时，问关键路径是什么？给出了输入，使得输出依赖于关键路径？ 35.为什么一个标准的倒相器中P管的宽长比要比N管的宽长比大？ 36.用mos管搭出一个与非门？ 37.画出NOT,NAND,NOR的符号，真值表，还有transistor level的电路 38.画出CMOS图，画出two-to-one mux gate(二选一电路)？ 39.用一个二选一mux和一个inv实现异或？ 40.画出CMOS电路的晶体管架构，实现Y=AB+C(D+E)?画出Y=AB+C的CMOS电路图，画出Y=AB+CD的CMOS电路图。 41.用与非门等设计全加法器？ 未解答*42.A、B、C、D、E进行投票，少数服从多数，输出是F(ABCDE中1的个数比0的多输出1，否则输出0)，用与非门实现，输出数目没有限制？ 未解答*43.画出一种CMOS的D锁存器的电路图和版图？ 44.LATCH和DFF概念和区别？ 45.latch和register的区别，为什么现在多用register.行为级描述中latch是如何产生的？ 46.用D触发器做个二分频电路 47.什么是状态图？ 48.用你熟悉的设计方式设计一个可以预置初值的7进制循环计数器，15进制呢？ 49.你知道的可编程逻辑器件有哪些？ 50.用Verilog或VHDL写一段代码，实现消除一个glitch(毛刺)？ 51. SRAM、FLASH、Memory, DRAM, SSRAM和SDRAM有什么区别？ 52.有四种复用方式，频分多路复用，写出另外三种？ 未解答53.ASIC设计流程中什么时候修正Setup time violation 和Hold time violation?如何修正？解释setup和hold time violation，画图说明，并说明解决办法。 54.给出一个组合逻辑电路，要求分析逻辑功能。 55.如何防止亚稳态？ 56.基尔霍夫定理的内容 57.描述反馈电路的概念，列举他们的应用。 58.有源滤波器和无源滤波器的区别 59.给出了reg的Setup,Hold时间，求中间组合逻辑的delay范围 60.时钟周期为T,触发器D1的寄存器到输出时间（触发器延时Tco）最大为T1max，最小为T1min。组合逻辑电路最大延迟为T2max,最小为T2min。问，触发器D2的建立时间T3和保持时间应满足什么条件。 原文地址ictown_数字IC设计工程师笔试面试经典100题-有答案陈恩 1. 什么是同步逻辑和异步逻辑？答：同步逻辑是电路中的信号和FPGA时钟信号存在逻辑上的因果关系，而异步逻辑则是电路中的信号和FPGA时钟信号没有固有的因果关系。 同步时序逻辑电路的特点：各触发器的时钟端全部连在同一个时钟，只有在时钟上升沿或者下降沿，电路状态才会发生改变，改变的状态将保持到下一个时钟脉冲到来。因此无论外部输入信号有无变化，在这段时间内，状态表中的每个状态是稳定的。 异步时序电路：电路中除了可以使用带时钟的触发器以外，还可以使用不带时钟的触发器和延迟元件作为存储元件，电路中没有统一的时钟，电路的状态由外部输入的变化直接引起。 2.同步电路和异步电路的区别：答：同步电路：电路中所有的触发器都连接的是同一个时钟源，因此所有触发器的状态的变化都与所加的时钟脉冲信号同步。 异步电路：电路中没有统一的时钟，有的触发器的时钟输入与时钟脉冲源相连，只有这些脉冲的状态变化和时钟脉冲源同步，而其他的触发器状态不与时钟脉冲同步。 3. 时钟设计的实质：答：时钟设计的实质是满足每一个触发器的建立/保持时间的要求。 4. 建立时间和保持时间的改变：答：建立时间，触发器在时钟上升沿到来之前，数据输入端的数据必须保持不变的最小时间。 保持时间，触发器在时钟上升沿到来之后，数据输入端的数据必须保持不变的最小时间。 5. 为什么触发器要满足建立时间和保持时间？答：因为触发器内部数据的形成是需要一定的时间的，如果不满足建立时间和保持时间，输入在这段时间变化，触发器将进入亚稳态，进入亚稳态的输出将不稳定，在0和1之间变化，这时需要一个恢复时间，输出才能变得稳定。但稳定之后的输出可能不是你的输出值。 为了防止亚稳态的传播，我们通常用两级触发器来同步异步输入信号，这样可以防止异步输入信号对于本级时钟可能不满足建立保持时间而使本级触发器产生的亚稳态传播到下一级。 6. 什么是亚稳态？为什么两级触发器可以防止亚稳态？答：这是一个异步电路同步化的问题。亚稳态指的是触发器无法在某个规定时间段内到达一个可以确认的状态。使用两级触发器来使异步电路同步化的电路其实叫做“一位同步器”，他只能用来对一位异步信号进行同步。 两级触发器可以防止亚稳态传播的原理：假设第一级触发器输入不满足其建立时间保持时间，它的第一个脉冲到来后输出的数据就为亚稳态，那么在下一个脉冲到来之前，其输出的亚稳态数据将在一段恢复时间后必须平稳下来，而且稳定的数据必须满足第二级触发器的建立时间，如果都满足了，下一个脉冲沿到来之前，第二级脉冲器便不会出现亚稳态，因为其输入端的数据满足其建立保持时间。同步的有效条件：第一级触发器的进入亚稳态后的恢复时间+第二级触发器的建立时间&lt;=时间周期。 更确切的说，输入脉冲宽度必须大于同步时钟周期与第一级触发器所需的保持时间之和。最保险的脉冲宽度是两倍同步时钟周期，所以，这样的同步电路对于从慢的时钟域来的异步信号进入较快的时钟域是比较有效的，对于进入一个较慢的时钟域，则没有效果。 7. 系统最高速度计算（最快时钟频率）和流水设计思想？答：同步电路的速度是指同步系统时钟的速度，同步时钟越快，电路处理数据的时间间隔越短，电路在单位时间内处理的数据量就越大。 假设Tco是触发器的输入数据被时钟打入到触发器到数据到达触发器的输出端的延时（Tco=Tsetup+Thold)。Tsetup是D触发器的建立时间；Tdelay是组合逻辑的延时。 加入数据已经被打入D触发器，那么数据到达第一个触发器Q输入出端需要的延时是Tco，经过组合逻辑延时Tdeleay，到达第二个触发器的D端，要希望时钟能在第二个触发器再次被稳定的打入到触发器，则时钟的延迟必须大于Tco+Tdelay+Tsetup，也就是说最小的时钟周期为Tmin=Tco+Tdelay+Tsetup，最快的时钟频率为Fmax=1/Tmin。 FPGA开发软件也是通过这种方式来计算系统的最高允许速度Fmax。因为Tco和Tsetup都是由具体的器件工艺决定的，固设计电路只能改变组合逻辑的延迟时间Tdelay，所以说缩短触发器间的组合逻辑的延时时间是提高同步电路速度关键所在。 由于一般同步电路都大于以及锁存，而要是电路稳定工作，时钟周期必须满足最大延时要求。故只有缩短最长延时路径，才能提高电路的工作频率，可以将较大的组合逻辑分为N个小模块，通过适当的方法平均分配组合逻辑，然后中间插入寄存器，并和原触发器使用相同的时钟。这样就可以提高电路的工作频率。这就是所谓的“流水线技术”实现的基本设计思想，即原设计速度受限部分用一个时钟周期实现，采用流水线技术插入寄存器，可以用N个时钟周期实现，因此系统的工作速度可以加快，吞吐量加大。但是，流水线设计会在源数据通路上加上延时，另外硬件面积开销增加。 *8.时钟约束的基本概念和基本策略？答：时钟约束主要包括周期约束，偏移约束，静态时序路径约束三种。通过附加时序约束可以综合布线工具调整映射和布局布线，使设计达到时序要求。 附加时序约束一般策略是先附加全局约束，然后对快速和慢速例外路径附加专门约束。附加全局约束时，首先先定义设计的所有时钟，对各时钟域的同步元件进行分组，对分组附加周期约束，然后对FPGA/CPLD输入输出PAD附加偏移约束、对全组合逻辑的PAT TO PAD路径附加约束。附加专门约束时，首先约束分组之间的路径，然后约束快，慢速路径和多周期路径，以及其他特殊路径。 9.附加约束的作用？答： 提高设计的工作频率（减少逻辑和布线延时)； 获得正确的时序分析报告；(静态时序分析工具以约束作为判断时序是否满足设计要求的标准，因此要求设计者正确输入约束，以便静态时序分析工具可以正确输出时序报告） 指定FPGA/CPLD的电器标准和引脚位置 10.FPGA设计工程师努力的方向：答：SOPC，高速串行I/O，低功耗，可靠性，可测试性和设计验证流程优化等方面。 随着芯片工艺的提高，芯片容量、密集度都在增加，FPGA设计也在朝着高速，高度集成、低功耗、高可靠性、高可测、可验证性发展。 芯片可测、可验证，正成为复杂设计所必备的条件，尽量在上板之前查出BUG，将发现BUG的时间提前，这也是一些公司花大气力设计仿真平台的原因。随着单板功能的提高、成本的压力，低功耗也逐渐进入FPGA设计者考虑的范围，完成相同的功能下如何能够使芯片的功耗最低，据说altera、xilinx都在根据自己的芯片特点整理出如何降低功耗的文档。 高速串行IO的应用，也丰富了FPGA的应用范围，像xilinx的v2 pro中的高速链路也逐渐被应用。 11.对于多位的异步信号如何进行同步？答：对于一位的异步信号可以使用“一位同步器进行同步”（使用两级触发器），而对于多位的异步信号，可以采用如下方法：1：可以采用保持寄存器加握手信号的方法（多数据，控制，地址）；2：特殊的具体应用电路的结构，根据应用的不同而不同；3：异步FIFO。（最常用的是DPRAM） 12.FPGA和CPLD的区别？答： CPLD更适合完成各种算法和组合逻辑，FPGA更适合于完成时序逻辑。换句话说，FPGA更适合于触发器丰富的结构，而CPLD更适合触发器有限而乘积项丰富的结构。 CPLD的连续式布线结构决定了它的时序延迟是均匀的和可预测的，而FPGA的分段式布线结构决定了其延迟的不可预测性。 在编程上FPGA比CPLD具有更大的灵活性。CPLD通过修改具有固定内连电路的逻辑功能来编程，FPGA主要通过改变内部连线的布线来编程；FPGA可在逻辑门下编程，而CPLD是在逻辑块下编程。 FPGA的集成度比CPLD高，具有更复杂的布线结构和逻辑实现。 CPLD比FPGA使用起来更方便。CPLD的编程采用E2PROM或FASTFLASH技术，无需外部存储器芯片，使用简单。而FPGA的编程信息需存放在外部存储器上，使用方法复杂。 CPLD的速度比FPGA快，具有较大的时间可预测性。这是由于FPGA是门级编程，并且CLB之间采用分布式互联，而CPLD是逻辑块级编程，并且其逻辑块之间互联是集总式的。 在编程方式上，CPLD主要是基于E2PROM或FLASH存储器编程，编程次数可达1万次，优点是系统断电时编程信息也不丢失。CPLD又可分为在编 程器上编程和在系统编程两类。FPGA大部分是基于SRAM编程，编程信息在系统断电时丢失，每次上电时，需从器件外部将编程数据重新写入SRAM中。其 优点是可以编程任意次，可在工作中快速编程，从而实现板级和系统级的动态配置。 CPLD保密性好，FPGA保密性差。 一般情况下，CPLD的功耗要比FPGA大，且集成度越高越明显。 13.锁存器（latch）和触发器(flip-flop)的区别？答：电平敏感的存储器称为锁存器。可分为高电平锁存器和低电平锁存器，用于不同时钟之间信号的同步。 由交叉耦合的门构成的双稳态的存储原件称为触发器。分为上升沿触发和下降沿触发。可以认为是两个不同电平敏感的锁存器串联而成。前一个锁存器决定触发器的建立时间，后一个锁存器决定保持时间。 14.FPGA芯片内有哪两种的存储器资源？答：FPGA芯片内部有两种存储器资源：一种是BLOCK RAM，另一种是由LUT配置成的内部存储器（分布式RAM）。 BLOCK RAM是由一定数量固定大小的存储块构成的，使用BLOCK RAM资源不占额外的逻辑资源，而且速度快。但是使用的时候消耗的BLOCK RAM资源是其块大小的整数倍。 15.什么是时钟抖动？答：时钟抖动是指芯片的某一个点上时钟周期发生暂时性的变化，也就是时钟周期在不同的周期上可能加长或者缩短。它是一个平均值为0的平均变量。 16.FPGA设计中对时钟的使用答：FPGA芯片有固有的时钟路由，这些路由能有减少时钟抖动和偏差。需要对时钟进行相位移动和变频的时候，一般不允许对时钟进行逻辑操作，这样会增加时钟的偏差和抖动，还会使时钟带上毛刺，一般的处理方法是采用FPGA芯片自带的时钟管理器PLL,DLL或DCM，或者把逻辑转换到触发器的D输入（这些也是对时钟逻辑操作的替代方案） 17: FPGA设计中如何实现同步时序电路的延时答：首先异步电路的延时实现：异步电路一半是通过加Buffer、两级与非门等来实现延时，但这不是很适合同步电路实现延时。在同步电路中，对于比较大的和特殊的要求的延时，一般是通过高速时钟产生计数器，通过计数器来控制延时，对于比较小的延时，可以通过触发器打一拍，不过这样只能延迟一个时钟周期。 18.FPGA中可以综合实现为RAM/ROM/CAM的三种资源及其他注意事项？答：三种资源：BLOCK RAM，触发器（FF），查找表（LUT）; 注意事项： 在生成RAM等存储单元时，应该首选BLOCK RAM；原因有二：第一：使用BLOCK RAM等资源，可以节约更多的FF和4-LUT等底层可编程单元。使用BLOCK RAM可以说是“不用白不用”，是最大程度发挥器件性能，节约成本的一种体现。第二：BLOCK RAM是一种可以配置的硬件结构，其可靠性和速度与用LUT和Register构建的存储更有优势的。 弄清FPGA的硬件结构，合理使用BLOCK RAM资源。 分析BLOCK RAM容量，高效使用BLOC RAM资源。 分布式RAM资源（Distribute RAM） 19. Xilinx中与全局时钟资源和DLL相关的硬件原语答：常用的与全局时钟资源有关的Xilinx器件原语包括：IBUFG,IBUFGS,BUFG,BUFGP,BUFGCE,BUFGMX,BUFGDLL,DCM等，关于各个器件原语的解释可以参考《FPGA设计指导准则》p50部分 20. HDL语言的层次概念？答：HDL语言是分层次的、类型的，最常用的层次概念有系统与标准级，行为级，寄存器传输级和门级。 系统级，算法级，RTL级(行为级)，门级，开关级。 21:查找表的原理与结构？答：查找表（Look up table）简称LUT, LUT本质上就是一个RAM。目前FPGA中多使用4输入LUT,所以每一个LUT可以看成一个有4位地址线的16x1的RAM。当用户通过原理图或者HDL语言描述了一个逻辑电路，PLD/FPGA开发软件会自动计算逻辑电路的所有可能的结果，并把结果事先写入RAM，每输入一个信号进行逻辑运算就等于输入一个地址进行查表，找出地址对应的内容，然后输出即可。 22.IC设计前端到后端的流程的EDA工具？答：设计前端也称为逻辑设计，后端也称为物理设计，两者并没有严格的界限，一般涉及与工艺有关的设计就是后端设计。 规格制定：客户向芯片设计公司提出设计要求。 详细设计：芯片设计公司（Fabless）根据客户提出的规格要求，拿出设计解决方案和具体实现架构，划分模块功能。目前架构的验证一般基于systemC语言，对价后模型的仿真可以使用systemC的仿真工具。例如CoCentric和Visual Elite等。 HDL编码：设计输入工具：ultra， visiual VHDL等 仿真验证：modelsim 逻辑综合：synplify 静态时序分析：synopsys的Prime Time 形式验证：Synopsys的Formality *23.寄生电容效应在IC设计中怎样克服和利用或者，IC设计过程中将寄生效应怎样反馈影响设计师的设计方案？答：所谓寄生效应就是那些溜进你的PCB并在电路中大破坏、令人头疼、原因不明的小故障。他们就是渗入高速电路中隐藏的寄生电容和寄生电感。其中包括由封装引脚和印制线过长形成的寄生电感；焊盘到地、焊盘到电源平面和焊盘到印制线之间形成的寄生电容；通孔之间的相互影响，以及许多其它可能的寄生效应。 理想状态下，导线是没有电阻，电容和电感的。而在实际中，导线用到了金属铜，它有一定的电阻率，如果导线足够长，积累的电阻也相当可观。两条平行的导线，如果互相之间有电压差异，就相当于形成了一个平行板电容器。通电的导线周围会形成磁场（特别是电流变化时），磁场会产生感生电场，会对电子的移动产生影响，可以说每条实际的导线包括元器件的管脚都会产生感生电动势，这也就是寄生电感。 在直流或者低频情况下，这种寄生效应看不太出来。而在交流特别是高频交流条件下，影响就非常巨大了。根据复阻抗公式，电容、电感会在交流情况下会对电流的移动产生巨大阻碍，也就可以折算成阻抗。这种寄生效应很难克服，也难摸到。只能通过优化线路，尽量使用管脚短的SMT元器件来减少其影响，要完全消除是不可能的。 24.设计题1–用触发器和逻辑门设计一个一位加法器1234567891011121314151617181920212223module (clk, rst_n, current_stage, carryin,next_stage,carryout);input clk, rst_n;//时钟和复位，复位低电平有效input current_stage; //输人加数input carryin; //输入进位output reg next_stage; //加法输出output reg carryout;// 输出进位标识always @(posedge clk or rst_n)begin//触发器 if(!rst_n) begin carryout &lt;= 1'b0; next_stage &lt;= 1'b0; end else begin carryout &lt;= carryin &amp;&amp; current_stage; //与门 next_stage &lt;= (~carryin&amp;&amp;current_stage)||(carryin&amp;&amp;~current_stage); //两个与门加上或门 endendendmodule 25. 设计自动饮料贩卖机要求：饮料10分钱，硬币有5分钱和10分钱两种，并考虑找零 画出fsm(有限状态机) 用verilog编程，语法要符合FPGA设计的要求 设计工程中可食用的工具及设计过程 设计过程： 首先确定输入输出，A=1表示投入10分，B=1表示投入5分，Y=1表示弹出饮料，Z=1表示找零 画出电路的状态，S0表示没有进行投币，S1表示已有的5分硬币 画出状态转移图 12345678910111213141516171819202122232425262728293031323334353637383940414243444546module test(clk, rst_n, a, b, y, z);input clk, rst_n;input a, b; //a, 投入5分；b, 投入10分output reg y; //弹出饮料output reg z; //找零reg state, next_state; //两段式状态机写法parameter s0 = 1'b0, s1 = 1'b1;//s0: 没有进行投币， s1,已经有5分硬币always @(posedge clk or negedge rst_n)beginif(!rst_n) state &lt;= s0;else state &lt;= next_state;endalways @(posedge clk or negedge rst_n)beginif(!rst_n) begin y &lt;= 1'b0; z &lt;= 1'b0;endelse begin case(state) s0: if(a&amp;&amp;!b) next_state &lt;= s1; //投入了5分 else if(!a&amp;&amp;b) begin //投入了10分 next_state &lt;= s0; y &lt;= 1'b1; end else next_state &lt;= s0; s1: if(a&amp;&amp;!b) begin //再投入5分 next_state &lt;= s0; y &lt;= 1'b1; end else if(!a&amp;&amp;b) begin next_state &lt;= s0; y &lt;= 1'b1; z &lt;= 1'b1; end else next_state &lt;= s1; default : next_state &lt;= s0; endcaseendendendmodule 状态转移图如下所示： *26.什么是“线与逻辑”，要实现它，在硬件特性上有什么具体要求？答：线与逻辑是两个输出信号相连可以实现与的功能。在硬件上，要用oc门来实现，由于不用oc门可能使灌电流过大，而烧坏逻辑门，同时在输出端口应加一个上拉电阻。oc 门是集电极开路门。od门是漏机开路门。 27.什么是竞争冒险？怎么判断？如何消除？答：在组合电路，门电路两个输入信号同时向相反的逻辑电平跳变称为竞争，某输入变量经过不同的路径传输后，到达电路中某一回合点的时间有先后，由于竞争而使电路输出发生错误的现象称为冒险。（也就是由于竞争产生的毛刺） 判断方法： 代数法（如果布尔式中有相反的信号则可能产生竞争和冒险现象） 卡诺图：有两个相切的卡诺圈并且相切处没有被其他卡诺圈包围，就有出现竞争冒险的可能 实验法: 示波器观测 解决方法： 加滤波电容，消除毛刺的影响 加选通信号，避开毛刺 增加冗余项，消除逻辑冒险 *28.常用的逻辑电平？TTL和CMOS电平可以相互直连吗？答：常用的逻辑电平有12v、5v、3.3v TTL和CMOS不可以直连，由于TTL是在0.3-3.6v，而CMOS是12v有的是5v，CMOS输出接到TTL可以直连。TTL接到CMOS需要在输出端口加上一上拉电阻接到5v或者12v 用CMOS可以直接驱动TTL; 加上上拉电阻后，TTL可以驱动CMOS 上拉电阻用途： 当TTL电路驱动COMS电路时，如果TTL电路输出的高电平低于COMS电路的最低高电平（一般为3.5V），这时就需要在TTL的输出端接上拉电阻，以提高输出高电平的值。 OC门电路必须加上拉电阻，以提高输出的高电平值。 为加大输出引脚的驱动能力，有的单片机管脚上也常使用上拉电阻。 在COMS芯片上，为了防止静电造成损坏，不用的管脚不能悬空，一般接上拉电阻产生降低输入阻抗，提供泄荷通路。 芯片的管脚加上拉电阻来提高输出电平，从而提高芯片输入信号的噪声容限增强抗干扰能力。 提高总线的抗电磁干扰能力。管脚悬空就比较容易接受外界的电磁干扰。 长线传输中电阻不匹配容易引起反射波干扰，加上下拉电阻是电阻匹配，有效的抑制反射波干扰。 上拉电阻阻值的选择原则包括: 从节约功耗及芯片的灌电流能力考虑应当足够大；电阻大，电流小。 从确保足够的驱动电流考虑应当足够小；电阻小，电流大。 对于高速电路，过大的上拉电阻可能边沿变平缓。综合考虑以上三点,通常在1k到10k之间选取。对下拉电阻也有类似道理。 OC门电路必须加上拉电阻，以提高输出的高电平值。 OC门电路要输出“1”时才需要加上拉电阻不加根本就没有高电平 在有时我们用OC门作驱动（例如控制一个 LED）灌电流工作时就可以不加上拉电阻 总之加上拉电阻能够提高驱动能力。 29：IC设计中同步复位与异步复位的区别？答：同步复位在时钟沿变化，完成复位动作。异步复位不管时钟，只要复位信号满足条件，就完成复位动作。异步复位对复位信号要求比较高，不能有毛刺，如果其与时钟关系不确定，也可能出现亚稳态。 30.Moore与Meeley状态机的特征？答：Moore状态机的输出仅与当前状态值有关，且只在时钟边沿到来时才会发生变化。 Mealy状态机的输出不仅与当前状态值有关，而且与当前输入值有关。 31.多时钟域设计中，如何处理信号跨时域问题？答：不同时钟域之间的信号通信需要进行同步处理，这样可以防止新时钟域中的第一级触发器出现的亚稳态对下级逻辑造成影响。 信号跨时钟域同步：当单个信号跨时钟域时，可以采用两次触发器来同步；数据或地址总线跨时钟域时可以采用异步FIFO来实现时钟同步；第三种方法是采用握手信号。 32.说说静态、动态时序模拟的优缺点？答：静态时序分析是采用穷尽的分析方式来提取出整个电路存在的所有时序，计算信号在这些路径上的传播延时，检查信号的建立时间和保持时间是否满足时序的要求，通过最大路径延时和最小路径延时延时的分析，找出违背时序约束的错误。它不需要输入向量就能穷尽所有路径，且运行速度快，占用内存较少，不仅可以对芯片设计进行全面的时序功能检查，而且还可以利用时序分析的结果优化设计，因此时序分析越来越多的被用到了数字集成电路设计的验证中。 动态时序模拟就是通常的仿真，因为不可能产生完备的测试向量，覆盖门级网表的每一条路径。因此在动态时序分析中，无法暴露一些路径上可能存在的时序问题。 *33.一个四级的Mux，其中第二级为关键信号，如何改善timing?答：将第二级信号放到最后一级输出，同时注意改善片选信号，保证其优先级没有被修改。 34.给出一个门级图，又给出了各个门的传输延时，问关键路径是什么？给出了输入，使得输出依赖于关键路径？答:关键路径就是输入到输出的延时路径的最大路径，找到了关键路径就能求最大时钟频率。 35.为什么一个标准的倒相器中P管的宽长比要比N管的宽长比大？答：和载流子有关，P管是空穴导电，N管是电子导电，电子迁移率大于空穴，同样的电场下，N管的电流大于P管，因此要增大P管的宽长比，使之对称，这样才能使得两者上升时间下降时间相等、高低电平的噪声容限一样、充放电的时间相等。 36.用mos管搭出一个与非门？答：与非门，上并下串。或非门，上串下并 参考博客：MOS管及简单的CMOS逻辑门电路原理图 37.画出NOT,NAND,NOR的符号，真值表，还有transistor level的电路答：NOT门,其他两个门参考题36 38.画出CMOS图，画出two-to-one mux gate(二选一电路)？答：CMOS图为 Y=SA+S’B利用与非门和反相器，进行变换后Y=((SA)’*(S’A)’)’，三个与非门，一个反相器。也可以用传输门来实现数据选择器或者异或门 39.用一个二选一mux和一个inv实现异或？答:异或的逻辑为Y=AB’+A’B，而二选一的逻辑为Y=SA+S’B,可以让选择S解B,输入信号分别接A和A’,Y=SA+S’B=BA’+B’A 利用四选一实现F(x,y,z)=xz+yz’ F(x,y,z)=xyz + xy’z + xyz’ + x’yz’=x’y’0 + x’yz’ + xy’z + xy1 Y = A’B’D0 + A’BD1 + AB’D2 + ABD3 所以D0=0, D1=z’, D2=z, D3=1 40.画出CMOS电路的晶体管架构，实现Y=AB+C(D+E)?画出Y=AB+C的CMOS电路图，画出Y=AB+CD的CMOS电路图。答：CMOS电路和与非门的电路图在题38和题36，考虑用与非门实现上诉电路 Y=AB+C(D+E)=((AB)’(CD)’(CE)’)’, 三个两输入与非门，一个三输入与非门 Y=AB+C=((AB)’C’)’，两个与非门，两个反相器 Y=AB+CD=((AB)’(CD)’)’，三个两输入与非门 41.用与非门等设计全加法器？答： 全加法器的输入为A, B, Cin。 A，B是加法的输入，Cin是进位输入。输出是Sum和Cout，Sum是加法输出，Cout是进位输出。 未解答*42.A、B、C、D、E进行投票，少数服从多数，输出是F(ABCDE中1的个数比0的多输出1，否则输出0)，用与非门实现，输出数目没有限制？未解答*43.画出一种CMOS的D锁存器的电路图和版图？44.LATCH和DFF概念和区别？答：DFF是边沿敏感，LATHC是电平敏感。 latch（锁存器）与 DFF（D触发器）的区别 latch由电平触发，非同步控制。在使能信号有效时latch相当于通路，在使能信号无效时latch保持输出状态。DFF由时钟沿触发，同步控制。 latch容易产生毛刺（glitch），DFF则不易产生毛刺。 如果使用门电路来搭建latch和DFF，则latch消耗的门资源比DFF要少，这是latch比DFF优越的地方。所以，在ASIC中使用latch的集成度比DFF高，但在FPGA中正好相反，因为FPGA中没有标准的latch单元，但有DFF单元，一个LATCH需要多个LE才能实现。 latch将静态时序分析变得极为复杂。 一般的设计规则是：在绝大多数设计中避免产生latch。它会让您设计的时序完蛋，并且它的隐蔽性很强，非老手不能查出。latch最大的危害在于不能过滤毛刺。这对于下一级电路是极其危险的。所以，只要能用D触发器的地方，就不用latch。 45.latch和register的区别，为什么现在多用register.行为级描述中latch是如何产生的？答： latch是电平敏感，register是边沿触发，register在同一时钟边沿边沿触发下动作，符合同步电路的设计思想，而Latch则属于异步电路设计，往往会导致时序分析困难，不适合的应用到Latch则会大量浪费芯片资源。 1234567891011121314module latch(Din, Dout, enable);input enable;input Din;output reg Dout;always @(enable or Din)begin if(enable) Dout &lt;= Din; else Dout &lt;= Dout;endendmodule 46.用D触发器做个二分频电路答：由D触发器构建的二分频电路 现实工程中一般不采用这样的方式实现，二分频一般通过DCM或者PLL产生，这样得到的分频信号没有相位差 47.什么是状态图？答：状态图是以几何图形的方式描述时序逻辑电路的状态转移规律以及输入和输出的关系。 48.用你熟悉的设计方式设计一个可以预置初值的7进制循环计数器，15进制呢？答：7位进制循环计数器123456789101112131415161718192021222324252627module counter7(clk , rst_n, load, data_in, counter_out, carry_out);input clk, rst_n;input load; //加载数字开始计数input[2:0] data_in;output reg [2:0] counter_out;output reg carry_out; //计数满输出always @(posedge clk or negedge rst_n)beginif(!rst_n) begin counter_out &lt;= 3'b0; carry_out &lt;= 1'b0;endelse if(load) counter_out &lt;= data_in;else if(counter_out=3'd6) begin counter_out &lt;= 3'b0; carry_out &lt;= 1'b1;endelse begin counter_out &lt;= counter_out + 3'b1; carry_out &lt;= 1'b0endendendmodule 15进制循环计算器，对应的将上面位宽加1，计数满和达到计数值改为14 49.你知道的可编程逻辑器件有哪些？答：PAL，PLA，GAL，CPLD，FPGA 50.用Verilog或VHDL写一段代码，实现消除一个glitch(毛刺)？答：将通过传输过来的信号经过两级触发器就可以消除毛刺（这种消除毛刺的方式是需要满足一定的条件的，并不能保证一定可以消除）123456789101112131415161718192021module (clk, rst_n, data_in, data_out);input clk, rst_n;input data_in;output data_out;reg data_r1, data_r2;always @(posedge clk or negedge rst_n)beginif(!rst_n) begin data_r1 &lt;= 1'b0; data_r2 &lt;= 1'b0;endelse begin data_r1 &lt;= data_in; data_r2 &lt;= data_r1;endendassign data_out &lt;= data_r2;endmodule 51. SRAM、FLASH、Memory, DRAM, SSRAM和SDRAM有什么区别？答：SRAM:静态随机存储，存取速度快，但是容量小，掉电后数据会丢失，不像DRAM那样需要不停的REFLASH，制造成本比较高，通常用来作为(CACHE)记忆体使用。 FLASH:闪存，存取速度慢，容量大，掉电后数据不会丢失 DRAM:动态随机存储器，必须不断的更新加强（REFRESHED）电位差，否则电位差将降低至无法有足够的能力表现每一个记忆体单位处于何种状态。价格是比SRAM便宜，但是访问速度慢，耗电量较大，常用作计算机的内存使用。 SSRAM:即同步静态随机存储器。对于SSRAM的所有访问都在时钟的上升、下降沿启动。地址、数据输入和其他控制信号均于时钟信号相关。 SDRAM:即同步动态随机存取存储器 52.有四种复用方式，频分多路复用，写出另外三种？答：四种复用方式，频分多路复用（FDMA），时分多路复用（TDMA），码分多路复用（CDMA），波分多路复用（WCDMA）。 未解答53.ASIC设计流程中什么时候修正Setup time violation 和Hold time violation?如何修正？解释setup和hold time violation，画图说明，并说明解决办法。54.给出一个组合逻辑电路，要求分析逻辑功能。答：所谓组合逻辑电路的分析，就是要找出给定逻辑电路输入和输出的关系，并指定电路的逻辑功能。 分析的过程一般按以下的步骤进行： 根据给定的逻辑电路，从输入端开始，逐级的推导出输出端的逻辑函数表达式。 根据输出函数的表达式列出真值表 用文字概括电路的逻辑功能 55.如何防止亚稳态？答：亚稳态是指触发器无法在某个规定时间段内达到一个可以确认的状态，当一个触发器进入亚稳态时，即无法预测该单元的输出电平，也无法预测何时输出才能稳定在某个正确的电平。在这个稳定期间，触发器输出一些中间级电平，或者可能处于震荡状态，并且这种无用的输出电平可以沿信号通道上的各个触发器级联式传播下去。 解决方法： 降低系统的时钟频率 用更快的FF 引入同步机制，防止亚稳态（可以用两级触发器） 改善时钟质量，用边沿变化更快的时钟信号 56.基尔霍夫定理的内容答：基尔霍夫定理包括电流定律和电压定律： 电流定律：在集总电路中，在任意一瞬间，流向某一节点的电流之和恒等于有该节点流出的电流之和。 电压定律：在集总电路中，在任一瞬间，沿电路中任一回路绕行一周，在该回路上的电动势之和恒等于个电阻上的电压降之和。 57.描述反馈电路的概念，列举他们的应用。答：反馈，就是在电路系统中，把输出回路中的电量（电流或者电压），输出到输入回路中去。 反馈的类型有：电压串联负反馈，电流串联负反馈，电压并联负反馈，电流并联负反馈。 负反馈的优点：降低放大器的增益灵敏度，改变输入电阻和输出电阻，改善放大器的线性和非线性失真，有效地扩展放大器的通频带，自动调节的作用。 电压负反馈的特点：电路的输出电压趋于维持恒定。 电路负反馈的特点：电路的输出电流趋于维持恒定。 58.有源滤波器和无源滤波器的区别答：无源滤波器：这种电路主要有无源元件R、L、C组成 有源滤波器：集成运放和R、C组成，具有不用电感，体积小，重量轻等优点 集成运放的开环电压增益和输入阻抗均很高，输出电阻小，构成有源滤波电路后还具有一定的电压放大和缓冲作用。但集成运放带宽有限，所以目前有源电路的工作频率难以做的很高 59.给出了reg的Setup,Hold时间，求中间组合逻辑的delay范围答：$$T_{delay} &lt;T_{period}-T_{setup}-T_{hold}\\T_{period}&gt;T_{setup}+T_{hold}+T_{delay}(用来计算最高时钟频率)\\T_{co}=T_{setup}+T_{hold} $$ 触发器的传输延时 60.时钟周期为T,触发器D1的寄存器到输出时间（触发器延时Tco）最大为T1max，最小为T1min。组合逻辑电路最大延迟为T2max,最小为T2min。问，触发器D2的建立时间T3和保持时间应满足什么条件。答：T3setup&gt;T+T2max 时钟沿到来之前数据稳定的时间（越大越好），一个时钟周期T加上最大的逻辑延时。 T3hold&gt;T1min+T2min 时钟沿到来之后数据保持的最短时间，一定要大于最小的延时也就是T1min+T2min","link":"/2019/03/30/数字IC设计面试100题/"},{"title":"概率编程之PyMC3","text":"《Probabilistic programming in Python using PyMC3》 Abstract Introduction 安装 示例：线性回归模型 generate data Model specification model fitting Maximum a posteriori methods 采样的方法 基于梯度的采样方法 Posterior analysis CASE STUDY 1: STOCHASTIC VOLATILITY model data model implementation Fitting Case study 2:Coal mining disasters PYMC3 FEATURES Arbitrary deterministic variables Arbitrary distributions Generalized linear models Backends DISCUSSION Abstract概率编程允许用户定义概率模型进行自动贝叶斯推理。马尔可夫链蒙特卡罗(MCMC)抽样的最新进展允许对越来越复杂的模型进行推理。这类MCMC，称为哈密顿蒙特卡罗，需要梯度信息，而这往往是不容易获得的。PyMC3是用Python编写的一个新的开源概率编程框架，它使用Theano通过自动微分来计算梯度，并在运行时将概率程序编译到C中以提高速度。与其他概率编程语言相反，PyMC3允许直接在Python代码中进行模型定义。由于缺乏特定于领域的语言，因此具有很大的灵活性和与模型的直接交互。本文是对此软件包的教程式介绍。 Introduction概率编程(PP)允许对贝叶斯统计模型进行灵活的描述和拟合。 PyMC3是一种新的开源PP框架，它具有直观、可读、功能强大的语法，与统计学家用来描述模型的自然语法非常接近。 它具有下一代马尔可夫链蒙特卡罗(MCMC)采样算法，如No-U-Turn(NUTS)(Hoffman&amp;Gelman，2014年)，这 是哈密顿蒙特卡罗(HMC)的自校正变体(Duane等人，1987年)。 这类采样器很好地工作在高维和复杂的后验分布上，并且允许许多复杂的模型在没有关于拟合算法的专门知识的情况下可以被拟合。 HMC和NUTS利用了来自似然的梯度信息，与传统的采样方法相比，具有更快的收敛速度，特别是对于较大的模型。 NUTS也有几种自校正策略来自适应地设置哈密顿蒙特卡罗的可调参数，这意味着不需要关于算法如何工作的专门知识。 PyMC3、STAN(STAN开发团队，2015)和LaplacesDemon R包是目前唯一提供HMC的PP包。 在过去的2-3年中，出现了许多概率编程语言和系统。 最早得到广泛使用的语言之一是Bug语言(Spiegelhalter等人，1995年)，它允许简单地指定贝叶斯模型，并通过马尔可夫链蒙特卡罗方法对其进行拟合。 新的、更具表现力的语言允许创建因子图和概率图形模型。 这些系统中的每一个都是在现有低级语言之上构建的特定于领域的语言；值得注意的例子包括Church(Goodman等人，2012年)(源自Plan)、Anglican(Wood，Van de Meent&amp;Mansinghka，2014年)(与Clojure集成并使用Java虚拟机进行编译)、Venture(Mansinghka，Selsam&amp;Perov，2014年)(构建于C+)、Infer.NET(Minka等人，2010)(基于.NET框架)，Figaro(Pfeffer，2014)(嵌入Scala)，WebPPL。 (Goodman&amp;Stuhlmüller，2014年)(嵌入JavaScript)、Picture(Kulkarni等人，2015年)(嵌入Julia)和Quicksand线(Ritchie，2014年)(嵌入Lua)。 Python中的概率编程(PythonSoftwareFoundation，2010)提供了许多优势，包括多平台兼容性、表达能力强但清晰易读的语法、与其他科学库的轻松集成，以及通过C、C+、Fortran或Cython实现的可扩展性(Behnel等人，2011)。 这些特性使编写和使用自定义统计分布、采样器和转换函数变得非常简单，正如贝叶斯分析所要求的那样。 虽然PyMC3的大多数面向用户的特性都是用纯Python编写的，但它利用Theano(Bergstra等人，2010；Bastian等人，2012)透明地将模型代码转换为C并将其编译为机器码，从而提高了性能。 Theano是一个库，它允许使用称为Tensor的广义矢量数据结构定义表达式，这些数据结构与流行的NumPy(Van der Walt，Colbert，Varoquaux，2011)ndarray数据结构紧密集成，并且类似地允许广播和高级索引，就像NumPy数组一样。 Theano还自动优化可能的计算图形的速度，并提供简单的GPU集成。 在这里，我们介绍了一个使用PyMC3解决一般贝叶斯统计推断和预测问题的引物。 我们将首先描述PyMC3的基本用法，包括安装、数据创建、模型定义、模型拟合和后验分析。 然后，我们将使用两个案例研究来说明如何定义和适应更复杂的模型。 最后，我们将展示如何扩展PyMC3，并讨论更高级的特性，如广义线性模型(GeneralizedLinearModels，GLM)子包、自定义分布、自定义转换和备用存储备份。 安装运行PyMC3需要一个工作的Python解释器(PythonSoftwareFoundation，2010)，版本2.7(或更新的版本)或3.4(或更新的版本)；我们建议新用户安装版本3.4。通过ContinuumIO下载并安装免费的AnacondaPythonDistributions，可以最容易地获得适用于MacOSX、Linux和Windows的完整Python安装。 PyMC3可以使用“pip”安装： 1pip install git+https://github.com/pymc-devs/pymc3 PyMC3依赖于几个第三方Python软件包，这些软件包将在通过PIP安装时自动安装。四个必需的依赖项是：Theano、NumPy、SciPy和Matplotlib。为了充分利用PyMC3，还应该安装可选的依赖 项Pandas和Patsy。 1pip install patsy pandas PyMC3的源代码托管在GitHub的PyMC3上，并在自由的ApacheLicense2.0下分发。在GitHub站点上，用户还可以报告bug和其他问题，并为项目贡献代码，这是我们积极鼓励的。全面的文档可在pymc3文档上找到。 示例：线性回归模型为了介绍模型的定义、拟合和后验分析，我们首先考虑一个参数具有正态先验的简单贝叶斯线性回归模型。我们感兴趣的是作为正态分布的观测值来预测结果Y，其期望值是两个预测变量X1和X2的线性函数。\\begin{equation}\\begin{split}Y \\sim N(\\mu, \\sigma^2)\\newline \\mu= \\alpha+\\beta_{1}X_1+\\beta_2X_2\\end{split}\\end{equation} 这里是截距，是协变量$\\x_i$的系数，而代表观测或测量误差。 我们将对两个回归系数应用方差为10的零均值正态先验，这两个回归系数对应于关于真实参数值的弱信息。 由于方差必须是正的，我们还将选择一个半正态分布(正态分布在零下界)作为先验。 generate data我们可以使用NumPy的随机模块来模拟这个模型中的一些数据，然后使用PyMC3来尝试恢复相应的参数。下面的代码实现了这个模拟，结果数据如图所示。123456789101112131415import numpy as npimport matplotlib.pyplot as plt# Intialize random number generatornp.random.seed(123)# True parameter valuesalpha, sigma = 1, 1beta = [1, 2.5]# Size of datasetsize = 100# Predictor variableX1 = np.linspace(0, 1, size)X2 = np.linspace(0,.2, size)# Simulate outcome variableY = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(size)*sigma Model specification在PyMC3中指定此模型很简单，因为语法类似于统计表示法。在大多数情况下，每行Python代码对应于上面模型符号中的一行。首先，我们从PyMC3导入我们需要的组件。123456789101112from pymc3 import Model, Normal, HalfNormalbasic_model = Model()with basic_model:# Priors for unknown model parameters alpha = Normal('alpha', mu=0, sd=10) beta = Normal('beta', mu=0, sd=10, shape=2) sigma = HalfNormal('sigma', sd=1) # Expected value of outcome mu = alpha + beta[0]*X1 + beta[1]*X2 # Likelihood (sampling distribution) of observations Y_obs = Normal('Y_Obs', mu=mu, sd=sigma, observed=Y) 第一行basic_model = Model() 创建一个新的Model对象，它是模型随机变量的容器。在实例化模型之后，模型组件的后续规范在with语句中执行： with basic_model: 这将创建一个上下文管理器，我们的basic_model作为上下文，包括所有语句，直到缩进块结束。这意味着在with语句下面的缩进代码块中引入的所有PyMC3对象都将添加到幕后的模型中。如果没有这个上下文管理器习惯用法，我们将被迫在创建时将每个变量与basic_model手动关联，这将导致更详细的代码。如果您尝试在模型上下文管理器之外创建新的随机变量，则会引发错误，因为没有明显的模型可以添加变量。 上下文管理器中的前三个语句创建随机随机变量，其中回归系数的正态先验分布，以及观察标准偏差的半正态分布 这些是随机的，因为它们的值部分地由其父项在随机变量的依赖图中确定，其对于先验是简单常数，并且根据指定的概率分布是部分随机的。 Normal构造函数创建一个正常的随机变量以用作先验。随机变量构造函数的第一个参数始终是变量的名称，它应该几乎总是与分配给的Python变量的名称匹配，因为它可以用于在汇总输出时从模型中检索变量。随机对象的剩余必需参数是参数，在正态分布的情况下是平均μ和标准差sd，我们为模型分配超参数值。通常，分布的参数是确定随机变量的位置，形状或比例的值，具体取决于分布的参数化。最常用的分布，如Beta，Exponential，Categorical，Gamma，Binomial等，可作为PyMC3对象使用，不需要由用户手动编码。 beta变量有一个附加的Shape参数，将其表示为大小为2的向量值参数。Shape参数可用于所有分布，并指定随机变量的长度或形状；如果未指定，则默认为1的值(即标量)。它可以是指定数组的整数，也可以是指定多维数组的元组。例如，Shape=(5，7)创建以5×7矩阵为其值的随机变量。 有关分布，采样方法和其他PyMC3功能的详细说明可通过帮助功能获得。 定义了先验后，下一个语句创建结果的预期值mu，指定线性关系： 1mu = alpha + beta[0]*X1 + beta[1]*X2 这会创建一个确定性的随机变量，这意味着它的值完全由其父项的值决定。也就是说，变量没有超出父母价值所固有的不确定性。这里，mu只是截距α与β系数和预测变量的两个乘积之和，无论它们的当前值是什么。 PyMC3随机变量和数据可以任意添加，减去，分割或相乘，以及索引（提取值的子集）以创建新的随机变量。还提供了许多常见的数学函数，如sum，sin，exp和线性代数函数，如dot（用于内积）和inv（用于逆）。将运算符和函数应用于PyMC3对象会产生巨大的模型表达能力。 模型的最后一行定义了Y_obs，即响应数据的采样分布。 1Y_obs = Normal(’Y_obs’, mu=mu, sd=sigma, observed=Y) 这是随机变量的一种特殊情况，我们称之为观测随机变量，它是模型的数据似然(likehood)。它与标准随机变量相同，只是其观察到的参数(将数据传递给变量)表明该变量的值已被观察到，并且不应通过应用于模型的任何拟合算法进行更改。数据可以numpy.ndarray或Pandas.DataFrame对象的形式传递。 注意，与先前的分布不同，Y_obs的正态分布的参数不是固定值，而是确定性对象mu和随机sigma。这在可能性和这两个变量之间创建了父子关系，作为模型的有向无环图的一部分。 model fitting完全指定了我们的模型后，下一步是获得模型中未知变量的后验估计。理想情况下，我们可以通过分析得出后验估计值，但对于大多数非平凡模型，这是不可行的。我们将考虑两种方法，其适当性取决于模型的结构和分析的目标：使用优化方法找出最大后验（MAP）点，并使用MCMC采样方法基于从后验分布中抽取的样本计算summaries。 Maximum a posteriori methods模型的最大后验（MAP）估计是后验分布的模式，并且通常使用数值优化方法找到。这通常是快速且容易的，但是仅给出参数的点估计，并且如果模式不代表分布则可能误导。PyMC3使用find_MAP函数提供此功能。 下面我们找到原始模型的MAP。MAP作为参数点返回，该参数点始终由变量名称的Python字典表示为参数值的NumPy数组。 123456from pymc3 import find_MAPmap_estimate = find_MAP(model=basic_model)print(map_estimate){‘alpha’: array(1.0136638069892534),‘beta’: array([ 1.46791629, 0.29358326]),‘sigma_log’: array(0.11928770010017063)} 默认情况下，find_MAP使用Broyden-Fletcher-Goldfarb-Shanno（BFGS）优化算法来查找log-posterior的最大值，但也允许scipy.optimize模块中选择其他优化算法。例如，下面我们使用Powell的方法来查找MAP。 12345map_estimate = find_MAP(model=basic_model, fmin=optimize.fmin_powell)print(map_estimate){’alpha’: array(1.0175522109423465),’beta’: array([ 1.51426782, 0.03520891]),’sigma_log’: array(0.11815106849951475)} 重要的是要注意MAP估计并不总是合理的，特别是如果模式处于极端。这可能是一个微妙的问题; 由于样本集非常小，所以可以具有极高密度但总概率低的区域。这通常发生在具有随机效应的方差参数的分层模型中。如果单个组均值相同，则组均值的比例参数几乎为零，则后验将具有接近无限密度，即使这样的小比例参数的概率很小，因为组均值必须非常接近一起。 此外，用于查找MAP估计的大多数技术仅发现本地优化（这通常足够好），并且因此如果不同模式有意义地不同，则可能对于多模式后验很难。 采样的方法尽管找到MAP是获得良好行为模型的参数估计的快速且简单的方法，但是它是有限的，因为没有与MAP估计产生的参数值的不确定性性的估计。相反，基于模拟的方法（例如MCMC）可用于获得马尔可夫值链，其在给定满足某些条件的情况下与来自后验分布的样本无法区分。 为了在PyMC3中进行MCMC采样以生成后验样本，我们指定了一个步骤方法对象，该对象对应于特定MCMC算法的单次迭代，例如Metropolis，Slice采样或No-U-Turn采样器（NUTS）。PyMC3的step_methods子模块包含以下采样器：NUTS，Metropolis，Slice，HamiltonianMC和BinaryMetropolis。 基于梯度的采样方法PyMC3实现了几种标准采样算法，例如自适应MetropolisHastings和自适应切片采样，但PyMC3最有能力的步骤方法是No-U-Turn采样器。NUTS对于从具有许多连续参数的模型中采样特别有用，这种情况下较旧的MCMC算法工作得非常慢。它利用有关较高概率区域的信息，基于对数后验密度的梯度。与传统的采样方法相比，这有助于它在大问题上实现快速收敛。PyMC3依靠Theano通过自动区分后密度来分析计算模型梯度。NUTS还有几种自适应策略，用于自适应地设置Hamiltonian Monte Carlo的可调参数。对于不可区分的随机变量（即离散变量），不能使用NUTS，但它仍可用于包含不可微变量的模型中的可微变量。 NUTS需要一个缩放矩阵参数，类似于Metropolis-Hastings中跳转建议分布的方差参数，尽管NUTS使用它有些不同。矩阵给出了后验分布的近似形状，因此NUTS不会使跳跃在某些方向上过大而在其他方向上过小。将此缩放参数设置为合理的值以便于有效采样非常重要。对于具有许多未观察到的随机随机变量或具有高度非正态后验分布的模型的模型尤其如此。较差的缩放参数会显着减慢NUTS，有时几乎完全停止它。采样的合理起点对于有效采样也很重要，但并不常见。 幸运的是，NUTS通常可以对缩放参数做出好的猜测。如果将参数空间中的一个点（作为变量名的字典到参数值，与find_MAP返回的格式相同）传递给NUTS，它将查看对数后验密度的局部曲率（Hessian矩阵的对角线） ）在那一点上猜测一个好的缩放矢量的值，这可以产生一个好的值。MAP估计通常是用于启动采样的好点。也可以将自己的矢量或缩放矩阵提供给NUTS。另外，find_hessian或find_hessian_diag函数可用于修改特定点处的Hessian以用作缩放矩阵或向量。 在这里，我们将使用NUTS使用MAP作为起始点和缩放点从后验采样2000个绘制。在模型的上下文中执行采样。 12345678from pymc3 import NUTS, samplewith basic_model: # obtain starting values via MAP start = find_MAP(fmin=optimize.fmin_powell) # instantiate sampler step = NUTS(scaling=start) # draw 2000 posterior samples trace = sample(2000, step, start=start) 样本函数运行传递给它的步骤方法达到给定的迭代次数，并按照收集的顺序返回包含所收集样本的Trace对象。跟踪对象的查询方式与包含从变量名到numpy.arrays的映射的dict类似。数组的第一个维度是采样索引，后面的维度与变量的形状匹配。我们可以如下提取alpha变量的最后5个值 12trace[’alpha’][-5:]array([ 0.98134501, 1.04901676, 1.03638451, 0.88261935, 0.95910723]) Posterior analysisPyMC3提供绘图和汇总功能，用于检查采样输出。可以使用traceplot创建一个简单的后验图，其输出如图2所示。 12from pymc3 import traceplottraceplot(trace) 左列包括每个随机随机变量的边缘后验的平滑直方图（使用核密度估计），而右列包含按顺序绘制的马尔可夫链的样本。作为矢量值的β变量产生两个直方图和两个样本迹线，对应于两个预测器系数。 对于表格分析，分析函数提供基于文本的常见后验统计信息输出： CASE STUDY 1: STOCHASTIC VOLATILITY我们提出了随机波动率，时变股市波动性的案例研究，以说明PyMC3解决更现实问题的能力。市场回报的分布非常不正常，这使得对波动率的抽样变得更加困难。此示例具有400多个参数，因此使用较旧的采样算法（如Metropolis-Hastings）效率较低，会生成具有较低有效样本量的高度自相关样本。相反，我们使用NUTS，效率显着提高。 model资产价格具有随时间变化的波动性（日常回报的差异）。在某些时期，回报变化很大，而在其他时期，回报非常稳定。随机波动率模型用潜在波动率变量解决这个问题，允许随时间变化。以下模型类似于NUTS论文中描述的模型（Hoffman＆Gelman，2014，第21页）。 这里，y是响应变量，每日返回系列，我们用具有未知自由度参数的Student-T分布建模，以及由潜在过程s确定的标度参数。单个si是潜在对数波动率过程中的每日对数波动率。 这里，y是响应变量，每日返回系列，我们用具有未知自由度参数的Student-T分布建模，以及由隐过程s确定的标度参数。单个si是潜在对数波动率过程中的每日对数波动率。 data我们的数据包括2008年金融危机期间标准S&amp;P 500指数的每日回报。有关每日回报数据的图表，请参见图3。可以看出，2008年金融危机期间股市波动性显着增加。 12import pandas as pdreturns = pd.read_csv(’data/SP500.csv’, index_col=0, parse_dates=True) model implementation与线性回归示例一样，在PyMC3中实现模型反映了其统计规范。该模型采用了几种新的分布：指数分布为？和？的先验，返回分布的Student-T（StudentT）分布，以及潜在波动率的先验的GaussianRandomWalk。 虽然(与PyMC2中的模型规范不同)我们通常不会在模型规范阶段为变量提供起始点，但是可以使用testval参数为任何发行版(在Theano中称为“测试值”)提供初始值。这将覆盖分布的默认测试值(通常是分布的平均值、中值或模式)，如果某些值无效，并且我们希望确保选择有效的值，这通常是有用的。默认情况下，分布的测试值也被用作采样和优化的起点，尽管这很容易被忽略。 潜在波动率s的矢量由GaussianRandomWalk对象给出先验分布。顾名思义，GaussianRandomWalk是一个向量值分布，其中向量的值形成长度为n的随机正态步行，由shape参数指定。随机游走sigma的创新规模是根据正态分布式创新的精确度来规定的，可以是标量或向量。 12345678from pymc3 import Exponential, StudentT, exp, Deterministicfrom pymc3.distributions.timeseries import GaussianRandomWalkwith Model() as sp500_model: nu = Exponential(’nu’, 1./10, testval=5.) sigma = Exponential(’sigma’, 1./.02, testval=.1) s = GaussianRandomWalk(’s’, sigma**-2, shape=len(returns)) volatility_process = Deterministic(’volatility_process’, exp(-2*s)) r = StudentT(’r’, nu, lam=1/volatility_process, observed=returns[’S&amp;P500’]) 请注意，我们通过exp（-2 * s）将对数波动率过程转换为波动率过程。这里，exp是一个Theano函数，而不是NumPy中的相应函数; Theano提供了NumPy所做的大部分数学函数。 Fitting在我们从后验中抽取样本之前，谨慎的做法是找到一个合适的起始值，我们指的是一个相对较高概率的点。对于该模型，所有变量的完全最大后验（MAP）点是简并的并且具有无限密度。但是，如果我们修复log_sigma和nu它不再退化，那么我们发现MAP只关注波动率过程，使log_sigma和nu保持其默认值（请记住我们为sigma设置testval = .1）。我们使用由scipy.optimize包提供的限制内存BFGS（L-BFGS）优化器，因为它对于高维函数更有效; 该模型包括400个随机随机变量（主要来自s）。 作为抽样策略，我们执行短暂的初始运行以定位高概率的体积，然后在新的起始点再次开始以获得可用于推断的样本。trace [-1]给出了采样跟踪的最后一点。NUTS将根据新点重新计算缩放参数，在这种情况下，由于更好的缩放，它会导致更快的采样。 12345678import scipywith sp500_model: start = find_MAP(vars=[s], fmin=scipy.optimize.fmin_l_bfgs_b) step = NUTS(scaling=start) trace = sample(100, step, progressbar=False) # Start next run at the last sampled position. step = NUTS(scaling=trace[-1], gamma=.25) trace = sample(2000, step, start=trace[-1], progressbar=False, njobs=2) 请注意，对sample的调用包括一个可选的njobs = 2参数，它允许对4个链进行并行采样（假设我们有2个处理器可用）。我们可以通过查看nu和sigma的traceplot来检查我们的样本; 每条平行链将绘制在同一组轴内（图4）。 1traceplot(trace, [nu, sigma]); 最后，我们通过在同一图表上绘制我们的许多采样波动率路径来绘制波动率路径的分布（图5）。每个都呈现为部分透明（通过Matplotlib的绘图函数中的alpha参数），因此许多路径重叠的区域被更加阴暗地着色。 12345fig, ax = plt.subplots(figsize=(15, 8))returns.plot(ax=ax)ax.plot(returns.index, 1/np.exp(trace[’s’,::30].T), ’r’, alpha=.03);ax.set(title=’volatility_process’, xlabel=’time’, ylabel=’volatility’);ax.legend([’S&amp;P500’, ’stochastic volatility process’]) 如您所见，该模型正确地推断出2008年金融危机期间波动性的增加。 由于其在随机游走分布中的高维度和依赖性结构，值得强调该模型的复杂性。然而，在PyMC3中实现的NUT正确地推断了后验分布。 Case study 2:Coal mining disasters本案例研究实现了1851年至1962年英国记录的煤矿灾害时间序列的变点模型（Jarrett，1979）。据认为，在此期间，每年的灾害数量都受到安全法规变化的影响，如图6所示。我们还包括一对缺失数据的年份，被NumPy MaskedArray确认为缺失 - 999作为该值。 我们的目标是在存在缺失数据的情况下估计变化发生的时间，使用多步法使我们能够拟合包含离散和连续随机变量的模型。 1234567891011disaster_data = np.ma.masked_values([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,2, 2, 3, 4, 2, 1, 3, -999, 2, 1, 1, 1, 1, 3, 0, 0,1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,3, 3, 1, -999, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1], value=-999)year = np.arange(1851, 1962)plot(year, disaster_data, ’o’, markersize=8);ylabel(\"Disaster count\")xlabel(\"Year\") 时间序列中的灾难计数被认为遵循泊松过程，在时间序列的早期具有相对大的速率参数，而在后面的部分中具有较小的速率。这种问题的贝叶斯方法是将变化点视为模型中的未知量，并为其分配先验分布，我们使用数据集中的证据将其更新为后验。 在我们的模型中： 参数定义如下： 1234567891011from pymc3 import DiscreteUniform, Poisson, switch with Model() as disaster_model: switchpoint = DiscreteUniform(’switchpoint’, lower=year.min(), upper=year.max(), testval=1900) # Priors for pre- and post-switch rates number of disasters early_rate = Exponential(’early_rate’, 1) late_rate = Exponential(’late_rate’, 1) # Allocate appropriate Poisson rates to years before and after current rate = switch(switchpoint &gt;= year, early_rate, late_rate) disasters = Poisson(’disasters’, rate, observed=disaster_data) 该模型引入了具有泊松似然性的离散变量和在变化点s上的离散均匀先验。我们对rate变量的实现是一个条件确定性变量，其值取决于s的当前值。 1rate = switch(switchpoint &gt;= year, early_rate, late_rate) 使用Theano函数开关实现条件语句，该函数开关使用第一个参数来选择接下来的两个参数中的任何一个。 在创建观察到的随机随机变量时，通过将带有NaN值的MaskedArray或pandas.DataFrame传递给观察到的参数来简明地处理缺失值。由此，PyMC3自动创建另一个随机变量disasters.missing_values，它将缺失值视为未观察到的随机节点。我们需要做的就是处理缺失值，确保我们为这个随机变量分配一个步骤方法。 不幸的是，因为它们是离散变量，因此没有有意义的梯度，我们不能使用NUTS对开关点或丢失的灾难观测进行采样。相反，我们将使用Metroplis步骤方法进行采样，该方法实现了自调整Metropolis-Hastings，因为它旨在处理离散值。 这里，样本函数接收包含NUTS和Metropolis采样器的列表，并且通过首先在每次迭代时应用step1然后step2来进行采样。 123456from pymc3 import Metropoliswith disaster_model: step1 = NUTS([early_rate, late_rate]) step2 = Metropolis([switchpoint, disasters.missing_values[0]] ) trace = sample(10000, step=[step1, step2])[-----------------100%-----------------] 10000 of 10000 complete in 6.9 sec PYMC3 FEATURESArbitrary deterministic variables由于依赖于Theano，PyMC3提供了许多数学函数和运算符，用于将随机变量转换为新的随机变量。但是，Theano中的函数库并不详尽，因此PyMC3提供了在纯Python中创建任意Theano函数的功能，并在PyMC3模型中包含这些函数。as_op函数装饰器支持此功能。 12345678910111213import theano.tensor as Tfrom theano.compile.ops import as_op@as_op(itypes=[T.lscalar], otypes=[T.lscalar])def crazy_modulo3(value): if value &gt; 0: return value % 3 else : return (-value + 1) % 3with Model() as model_deterministic: a = Poisson(’a’, 1) b = crazy_modulo3(a) Theano要求声明函数的输入和输出的类型，这些类型是由输入的itypes和输出的otype指定的as_op。这种方法的一个重要缺点是Theano无法检查这些函数以计算基于哈密顿量的采样器所需的梯度。因此，不可能将HMC或NUTS采样器用于使用这种运算符的模型。但是，如果我们从theano.Op继承而不是使用as_op，则可以添加渐变。 Arbitrary distributionsPyMC3中的统计分布库虽然很大，但并不详尽，但PyMC允许创建用户定义的概率分布。对于简单的统计分布，DensityDist函数将任何计算对数概率日志（p（x））的函数作为参数。该函数可以在其计算中使用其他父随机变量。这是一个受VanderPlas（2014）博客文章启发的例子，其中Jeffreys先验用于指定对变换不变的先验。在简单线性回归的情况下，这些是： 可以将这些函数的对数指定为DensityDist的参数并插入到模型中。 12345678910import theano.tensor as Tfrom pymc3 import DensityDist, Uniformwith Model() as model: alpha = Uniform(’intercept’, -100, 100) # Create custom densities beta = DensityDist(’beta’, lambda value: -1.5 * T.log(1 + value**2), testval=0) eps = DensityDist(’eps’, lambda value: -T.log(T.abs_(value)), testval=1) # Create likelihood like = Normal(’y_est’, mu=alpha + beta * X, sd=eps, observed=Y) 对于更复杂的分布，可以根据需要创建Continuous或Discrete的子类并提供自定义logp函数。这就是如何指定PyMC3中的内置分布函数。例如，心理学和天体物理学等领域对于可能需要数值近似的特定过程具有复杂的似然函数。在这些情况下，根据预定义的Theano运算符编写函数是不可能的，我们必须使用as_op或继承自theano.Op的自定义Theano运算符。 下面显示了将上面的beta变量实现为Continuous子类，以及使用as_op装饰器的子函数，尽管这不是绝对必要的。 123456789101112131415161718from pymc3.distributions import Continuousclass Beta(Continuous): def __init__(self, mu, *args, **kwargs): super(Beta, self).__init__(*args, **kwargs) self.mu = mu self.mode = mu def logp(self, value): mu = self.mu return beta_logp(value - mu)@as_op(itypes=[T.dscalar], otypes=[T.dscalar])def beta_logp(value): return -1.5 * np.log(1 + (value)**2)with Model() as model: beta = Beta(’slope’, mu=0, testval=0) Generalized linear models广义线性模型(GLM)是一类灵活的模型，广泛用于估计单个结果变量与一个或多个预测因子之间的回归关系。由于这些模型非常常见，PyMC3提供了一个GLM子模块，该模块允许灵活地创建简单的GLM，以及通过Patsy模块实现的直观的类R语法。 glm子模块需要将数据包含为pandas DataFrame。因此，对于我们的线性回归示例： 123# Convert X and Y to a pandas DataFrameimport pandasdf = pandas.DataFrame({’x1’: X1, ’x2’: X2, ’y’: Y}) 然后可以在一行代码中非常简洁地指定模型。 123from pymc3.glm import glmwith Model() as model_glm: glm(’y ~ x1 + x2’, df) 如果未通过family参数指定，则错误分布被认为是正常的。在逻辑回归的情况下，可以通过传入二项式族对象来修改它。 1234from pymc3.glm.families import Binomial df_logistic = pandas.DataFrame({’x1’: X1, ’x2’: X2, ’y’: Y &gt; 0})with Model() as model_glm_logistic: glm(’y ~ x1 + x2’, df_logistic, family=Binomial()) 通过glm指定的模型可以使用与标准PyMC3模型相同的样本函数进行采样。 BackendsPyMC3支持不同的方法来存储来自MCMC模拟的样本，称为后端。这些包括将输出存储在内存中，文本文件中或SQLite数据库中。默认情况下，使用内存中的ndarray，但是对于非常大的模型运行很长时间，这可能会超出可用的RAM，并导致失败。例如，将SQLite后端指定为sample的trace参数将导致将样本保存到由模型自动初始化的数据库中。 1234567from pymc3.backends import SQLitewith model_glm_logistic: backend = SQLite(’logistic_trace.sqlite’) trace = sample(5000, Metropolis(), trace=backend)[-----------------100%-----------------] 5000 of 5000 complete in 2.0 sec 使用磁盘后端的第二个优点是模型输出的可移植性，因为随后可以使用加载函数重新加载存储的跟踪（例如，在另一个会话中）：1234from pymc3.backends.sqlite import loadwith basic_model: trace_loaded = load(’logistic_trace.sqlite’) DISCUSSION概率编程是统计学习中的一种新兴范式，其中贝叶斯建模是一个重要的子学科。概率编程的特征特征？将变量指定为概率分布和其他变量和观测值的条件变量？使其成为在各种设置和模型复杂度范围内构建模型的有力工具。伴随着概率编程的兴起，贝叶斯模型拟合方法的创新突然爆发，代表了对现有MCMC方法的显着改进。然而，尽管有这种扩展，但很少有软件包能够跟上方法创新的步伐，而且很少有非专家用户能够实现模型。 PyMC3为定量研究人员提供了一个概率编程平台，可灵活，简洁地实施统计模型。一个庞大的统计分布库和几个预定义的拟合算法允许用户专注于手头的科学问题，而不是贝叶斯建模的实现细节。选择Python作为开发语言而不是特定于域的语言意味着PyMC3用户能够使用动态的高级编程语言以交互方式工作来构建模型，内省模型对象以及调试或分析他们的工作 这很容易学习。PyMC3的模块化，面向对象设计意味着添加新的拟合算法或其他功能非常简单。此外，PyMC3具有大多数其他软件包中没有的几个特性，最值得注意的是基于哈密顿量的采样器以及仅由STAN提供的约束随机变量的自动变换。然而，与STAN不同，PyMC3支持离散变量以及非基于梯度的采样算法，如Metropolis-Hastings和Slice采样。 PyMC3的开发是一项持续的工作，并计划在未来版本中使用多种功能。最值得注意的是，变分推理技术通常比MCMC采样更有效，但代价是普遍性。然而，最近，已经开发了黑盒变分推理算法，例如自动微分变分推理（ADVI）（Kucukelbir等，2015）。该算法计划添加到PyMC3。作为一个开源科学计算工具包，我们鼓励研究人员为贝叶斯模型开发新的拟合算法，以便在PyMC3中提供参考实现。由于采样器可以用纯Python代码编写，因此可以通常实现它们以使它们在任意PyMC3模型上工作，从而为作者提供更多的用户来使用它们的方法。","link":"/2019/04/03/概率编程之PyMC3/"},{"title":"MIT论文1-Venture:用于概率元编程的可扩展平台","text":"《Venture: an extensible platform for probabilistic meta-programming》 Abstract Introduction 概率密度的元程序 2.1标准分布的密度和模拟器 2.2 贝叶斯规则作为概率元程序 2.3 隐藏马尔可夫模型的优化边缘密度 3.Probabilistic execution traces 3.1 跟踪作为概率空间的元素 3.2 概率执行跟踪的接口 3.3 Stochastic regeneration of trace fragments 4.Meta-programs for stochastic inference 4.1 Exact stochastic inference via rejection sampling 4.2 Approximate stochastic inference via Metropolis-Hastings 4.3 Custom model-specific inference meta-programs 4.3.1 Custom Metropolis-Hastings samplers 4.4 Scaling of stochastic regeneration for approximate inference 5 Stochastic procedures 5.1 Generic stochastic procedures 5.2 “Simple” stochastic procedures 5.3 “Tail-assessable” stochastic procedures Tradeoffs between different representations of the Beta-Bernoulli process 5.5 Memoization as a user-space stochastic procedure 6 Discussion Abstract本文描述了Venture，一个用于概率元编程的可扩展平台。 在Venture中，概率生成模型，概率密度函数和概率推理算法都是第一类对象。任何随机选择的Venture程序都可以被视为在程序可能执行的空间中定义的概率模型。这些概率模型程序也可以在记录它们所做的随机选择的同时运行。Venture中的建模和推理涉及两类额外的概率程序。第一，概率密度元程序部分地描述了概率模型程序的输入 - 输出行为。第二个随机推理元程序在给定随机约束的情况下识别模型程序的可能执行，并且通常使用密度元程序作为指导。与其他概率编程平台不同，Venture允许将模型程序，密度元程序和推理元程序编写为单个概率编程语言中的用户空间代码。Venture本质上是一种类似Lisp的高阶语言，增加了两个新颖的抽象：（i）概率执行轨迹，表示概率程序产生的随机选择序列的第一类对象，以及（ii）随机过程， 封装了允许简单概率分布，用户空间VentureScript程序和外来的概率程序所需的概率程序和元程序，它们被统一视为概率计算的组成部分。Venture还为执行跟踪片段的随机再生提供运行时支持，该跟踪片段利用在执行原始跟踪程序期间调用的所有随机过程的程序和元程序。本文描述了Venture的一个新的原型实现，结合了这些想法，并通过为Church和其他概率语言内置的原语和推理策略提供简洁的用户空间实现来说明Venture的灵活性。 Introduction概率编程是一个新兴领域，旨在使用编程语言和系统软件的思想形式化和简化概率建模和推理。几种早期的概率编程语言[5] [9] [13] [11] [3]侧重于概率生成建模，其中使用随机选择的程序来定义概率模型。在这些语言中，以及随后开发的大多数语言中，概率推断是通过用户空间程序无法替换或扩展的语言中的内置机制来完成的。 本文描述了Venture，一个用于概率元编程的可扩展平台。在Venture中，概率生成模型，概率密度函数和概率推理算法都是一级的对象。任何随机选择的Venture程序都可以被视为在程序可能执行的空间中定义的概率模型。这种“概率模型程序”也可以在记录它们所做的随机选择的同时运行。这种“跟踪执行”作为普通的原始过程暴露给最终用户，并且是用于概率推理的蒙特卡罗技术的核心，但对于检查和调试也是有用的。 本文使用术语“元程序”来指代描述，检查，创建和/或转换其他程序的文本或执行的程序。在Venture，到目前为止我们已经看到了两种类型的元程序的需求： 1.概率密度元程序：这些部分描述了概率模型程序的输入 - 输出行为。密度有时可以通过简单的分析公式给出，但有时它们本身由复杂的算法组成。例如，可以通过简单的动态程序计算来自隐马尔可夫模型[12]的输出符号序列的边际概率密度; 在Venture中，这个程序是一个有效的元程序，可以与一个程序相关联，该程序对潜在序列及其产生的观察结果进行采样。贝叶斯规则可以被视为用于评估后验密度的密度元程序，给出两个密度元程序 - 一个用于先验，一个用于可能性 - 以及（数据依赖）值的边际概率。先前和可能密度下的数据。 2.随机推理元程序。这些元程序在给定随机约束的情况下发现模型程序的可能执行，并且通常使用密度元程序作为指导。本论文包括一个拒绝抽样推理元程序，它可以执行受“足够随机”约束的任意模型程序，即对具有已知边界的已知边际概率密度的模型程序所代表的随机选择的约束（作为函数的函数） 输入，用于固定输出）。本论文还提出了使用Metropolis-Hastings方法构建的推理元程序，包括特定模型的专用采样器以及适用于同一类推理问题的通用近似推理算法。 与其他概率编程平台不同，Venture允许将模型程序，密度元程序和推理元程序编写为单个概率编程语言中的用户空间代码。通过这种方式，Venture旨在充分表达和扩展以用于通用目的。尽管Venture有一个用于建模和推理的内置标准库，但该库并不是为了提供高性能。相反，它旨在促进快速原型设计和运行时反射，以便进行测试和调试。一旦调试了概率计算，就可以通过用高性能本机代码替换关键组件来逐步优化它。这一目标仅在早期版本的Venture [6]中得到部分实现。 概率执行痕迹（PET），有时也简称为“痕迹”。PET是第一类对象，表示概率程序产生的随机选择序列。PET在Venture中作为可变存储的唯一本机形式，并将在程序执行过程中分配的动态“地址”映射到程序在这些地址处采用的清单值。Venture支持“平面轨迹”，它简单地记录了从地址到值的映射，遵循[14]，以及“依赖图形轨迹”，可以看作是有向图形模型的扩展[10] [6] [2]。这些跟踪可以通过统一接口访问，以（重新）生成程序片段的跟踪，从而促进推理元程序的开发。平面轨迹和依赖图轨迹表现出不同的渐近缩放行为，并且还支持不同的常数因子优化和运行时，使它们适用于不同类别的推理策略。 随机程序（SP）。SP用于封装简单概率分布，以及用户空间VentureScript程序和外部概率对象。SP由一组链接的程序和元程序组成，这些程序和元程序共同描述概率程序的各个方面，这些方程对于其在建模和推理中的使用非常重要。例如，SP是将模型程序与其相关密度和推理元程序链接起来的主要手段。SP被设计为允许简单的概率分布，用户空间VentureScript和外部概率程序被统一地视为复杂概率计算的构建块。 本文描述了Venture的一个新的原型实现，其中包含了这些想法，并通过为Church [3]以及其他概率语言内置的原语和推理策略提供简洁的用户空间实现来说明Venture的灵活性。 概率密度的元程序概率建模和推理的数学处理使用概率分布的多个表示。最常见的选择是使用概率密度函数：计算特定输出值的概率密度的数学函数（可能给定输入参数）。 在编程术语中，密度函数可以被视为从生成过程模拟的代码行为的不完整声明性规范。在Venture中，概率程序可以与表征其输入 - 输出密度的概率密度元程序相关联。这种关联对程序的行为进行了数学断言，后续的元程序如随机推理元程序可以依赖。 本节的其余部分将介绍如何将概率程序与Venture中的概率密度元程序相关联，以便其他元程序可以利用此信息。 2.1标准分布的密度和模拟器图2.1显示了表示标准正态分布的Venture程序，其中包括从分布模拟的过程和计算其（对数）概率密度函数的过程。 模拟过程使用众所周知的Box-Muller变换，该变换从标准正态分布生成示例X： 以下是BoX-Muller变换，推导的x的概率分布的原文： 作为第二个例子，图2.2显示了一个代表Gamma分布的Venture程序，包括模拟和密度程序。这里的模拟器是一个更复杂的程序，由于[8]实现了一个拒绝采样算法，用于生成具有形状参数α的Gamma随机变量y： 采样得到的x服从如下的分布，经过变换可以得到y的分布，服从参数为α的Gamma分布 在这些示例程序中，我们已经看到用于将模拟过程与密度相关联的原始make_elementary_sp。在后面的部分中，我们将看到这对于Venture的内置跟踪和推理工具进行互操作是如何有用的。同时，也可以编写直接使用密度模拟器的用户程序。 2.2 贝叶斯规则作为概率元程序某些形式的贝叶斯规则可以理解为概率密度元程序。回想一下，贝叶斯规则给出了条件概率密度的公式 就先前的p（x）而言，似然性p（y|x）和数据的边际概率p（y）。通常，p（y）不是以闭合形式给出，而是可以用x上的蒙特卡罗积分近似： 图2.3显示了实施蒙特卡罗方法的Venture计划。先验分布通过随机过程表示，该过程生成样本并具有相关的密度; 贝叶斯规则元程序使用来自该过程的样本来形成蒙特卡罗估计。似然分布由另一个随机过程表示，该过程仅需要具有概率密度。 为了说明，请考虑以下简单的正态-正态模型： 图2.3 一个元程序，通过贝叶斯规则计算后验密度，使用蒙特卡罗估计来计算边际密度。 我们观察y的值，并对后验分布p（x|y）感兴趣。我们将使用它作为一个运行示例来演示各种推理元程序; 这个问题虽然简单，但它可以作为一个有用的最小测试用例来检查各种推理策略的工作情况。 图2.4显示应用于此问题的贝叶斯规则元程序，观察值y = 4.0，使用N = 500个样本估算密度。 2.3 隐藏马尔可夫模型的优化边缘密度对于受限类别的概率模型，通常可以给出用于评估边际概率密度的优化算法。其中一些，例如隐马尔可夫模型的前向后向算法[12]，最初被视为具有里程碑意义的结果。Venture可以将这些算法创新表示为普通的用户空间元程序，并将它们附加到随机过程中。这样，无论何时请求随机过程的概率密度，都可以使用优化的算法。 图2.5显示了描述HMM模型的模拟器和密度程序的集合，包括模拟隐藏状态和观察序列的程序; 评估隐藏状态和观察的联合概率的程序; 使用前向算法计算观测的精确边际概率的过程; 以及使用两个密度程序直接计算给定观察的状态的后验概率的过程。 图2.5：一组元程序，用于从隐藏的马尔可夫模型进行模拟，并评估隐藏状态和观察结果的联合，边际和后验概率密度。 具体代码略，可以参考原论文 3.Probabilistic execution traces对于做出许多随机选择的较大概率程序，我们通常有兴趣不仅仅是用密度程序表征其输入 - 输出行为。我们希望捕获有关程序中发生的所有随机选择的信息，以便我们可以对其他部分的程序调节部分进行推断。 概率执行轨迹（PET），有时也缩写为“轨迹”，是一类新的第一类对象，表示概率程序所做的随机选择序列。PET明确表示概率程序对特定执行的明显行为。所有PET都包含从动态“地址”的映射，每个动态“地址”对应于执行某些概率程序的可区分位置，以及程序在这些地址处采用的清单值。因此，它们包含对程序源代码的补充信息，这隐含地表示程序的潜在行为。换句话说，程序的可能行为空间对应于可以通过跟踪其执行而生成的PET空间。 这种“跟踪执行”的概念对于Venture的核心能力至关重要：能够将任何概率程序视为在程序可能执行的空间中定义的概率模型。概率模型程序在可能的PET空间上定义概率模型，该模型可以通过追踪其执行来产生。Venture将“跟踪执行”作为语言中的普通原始程序公开，允许用户运行Venture程序并记录程序所做的随机选择序列。PET中的值可以通过简单的界面进行变异，该界面会反射回用户空间。改变PET中的值的能力是用于概率推理的蒙特卡罗技术的核心，但也可用于调试。图3.1显示了运行模型程序，捕获其执行跟踪以及通过探索替代执行历史来执行推理的示例。 Venture支持两种迹： 扁平迹。这些记录了从地址到值的映射，如下[14]。因为它们不表示依赖性信息，所以它们消耗更少的内存并支持广泛的常量性能优化。但是，由于它们不表示依赖性信息，因此如果更改某个其他值，则很难确定平面跟踪中的哪些值可能会失效。最简单的一般策略是在更改单个值后始终重新执行整个跟踪程序。该策略导致关键推理操作的不利渐近缩放，尤其是对于局部采样和基于梯度的优化算法。有关示例模型程序及其相应扁平迹线的表示，请参见图3.2。 依赖关系图跟踪。这些可以看作是有向图形模型的扩展[10] [6] [2]。因为它们包含依赖性信息，所以它们可用于重新执行跟踪程序的片段而无需重新执行整个程序。有关示例，请参见图3.3。 图3.2 图3.2：示例tricky硬币模型程序和示例程序的平面跟踪数据结构的打印输出。/ 2/0/1表达式是地址; 看主要文字。 在跟踪执行中，寻址方案用于为程序执行期间的每个随机选择分配名称，类似于[14]。在我们的方案中，为每个产生结果的子计算分配一个唯一的地址。地址是以下之一： Toplevel地址。每个顶层建模命令(assume, observe, or generate)触发跟踪子计算，该子计算与从1开始的递增序列号相关联。例如，在图3.2中的程序中，地址/ 1指的是假设表达式bernoulli（0.1 ），地址/ 3指的是观察到的表达bernoulli（weight）。 Subexpression地址。这对应于遍历抽象语法树中的边。子表达式地址由基地址后跟数字索引组成。当基地址引用过程应用程序的结果时，索引0选择正在应用的运符，索引1选择第一个操作数等。例如，/ 1/0指的是第一个顶层表达式的运算符 在程序中，和1/1到它的参数。 请求地址。一些随机程序在应用时将“请求”执行另一个程序片段。最常见的例子是复合过程，它要求执行它们的过程体。当这样的过程发出执行请求时，它给请求一个唯一的ID，以便为所请求的子程序分配地址r（sp_address，request_id），其中sp_address是创建或定义请求过程的地址。在复合过程的情况下，请求ID是呼叫站点的地址，因此该地址类似于调用堆栈地址。例如，由于在/ 2处应用过程，r（/ 1，/ 2）指的是在/ 1处定义的过程的主体的执行。 在依赖关系图跟踪中，依赖关系图中的节点与地址一一对应。因此，每个节点表示程序执行中的子计算的结果。 值得注意的是，PET也是Venture中唯一的可变存储本地形式。通过跟踪随机选择的执行来分配新的存储位置，并且可以为了执行概率推断之外的目的而进行突变。例如，可交换耦合的基元可以使用跟踪来存储和更新足够的统计信息。这允许用户空间VentureScript程序模拟在其本机实现中使用变异操作的外来原语的行为。 3.1 跟踪作为概率空间的元素执行跟踪代表一个点$\\rho$在所有可能的程序执行的示例空间$\\Omega$中。在形式上，我们定义为$\\Omega$从所有可能的随机过程应用程序到这些应用程序的结果的映射空间： 给定$\\rho$，产生结果的每个程序子计算对应于随机变量$f:\\Omega$V将样本空间中的点映射到可能值为V的空间。f（？）的值由程序以？为条件执行时对应于f的子计算结果确定，即使用？确定所有随机选择的结果。 因为跟踪是Venture中的第一类对象，所以可以使用与随机变量相对应的表达式，这些随机变量本身具有值。这允许随机推断程序表示为输出其他程序的随机执行轨迹的程序，其通常从与模型程序的无条件分布不同的分布中进行采样。通常，所述不同分布是对感兴趣条件分布的近似。 请注意，在上面的定义中，元素是抽象的无限维对象，它们代表潜在的程序执行，描述程序可以做出的每个可能的随机选择的结果。相反，通过跟踪执行Venture程序获得的PET对应于该程序的实现执行，其包含由程序做出的有限数量的随机选择（假设程序停止）。这两种追踪概念 - 粗略地说，执行“未来”和执行“历史” - 是不同的，但密切相关。鉴于未来的执行？和程序的源代码，有一个相应的执行历史，它是通过执行程序使用？获得的。作为发生的所有随机选择的随机性来源并记录这些选择的结果。换句话说，执行历史是限制？在程序执行期间实际实现的随机选择集。相反，如果给定通过跟踪程序执行而获得的执行历史，则可以通过使用随机数生成器状态来增强它来构建执行未来，该随机数生成器状态用于生成程序执行过程中实现的随机选择以外的任何随机选择的结果。 这两个跟踪概念一起提供了一个框架，用于修改程序的执行历史并根据这些修改重新运行程序。Venture以随机再生的形式提供此功能的一个版本（在第3.3节中描述）。随机再生可以被视为一种操作，它提取执行历史的一部分并将其转换为可能的执行未来的表示，然后对新的执行未来进行采样，然后可以将其合并回历史。 在本论文的其余部分，PET和跟踪将用于指代实现的执行历史和表示它们的数据结构。跟踪“未来”目前在随机再生中使用的对象之外没有明确的表示; 进一步统一这些概念是未来工作的有趣基础，但超出了本论文的范围。 3.2 概率执行跟踪的接口本节简要介绍Venture原型实现中概率执行跟踪支持的关键操作。在下文中，跟踪对象表示为T. a &lt;- next_base_address(T) 获取跟踪中的下一个未分配的基址，并递增下一个地址指针。 T &lt;- global_env(T) 获取跟踪的全部环境。 eval_request(T, base_address:a, expression: e, enviroment:T) 执行环境中表达式表示的程序片段并记录所有中间结果，将结果存储在给定的基址中。 v &lt;- value_at(T, address:a) 获取给定地址处跟踪中记录的值。 blind_global(T, symbol:s, address:a) 将跟踪的全局环境中的符号绑定到给定地址的结果。 a &lt;- find_symbol(T, enviroment: T, symbol, s) 在给定环境中查找符号并返回相应的地址 register_observation(T, address:a, value:v) 记录已观察到给定地址的结果为给定值。就其本身而言，这对执行跟踪没有影响，特别是不会修改存储在该地址的值以与观察一致。但是，各种元程序将检查不一致的跟踪并将它们视为零概率（例如，通过拒绝导致这种跟踪的转换）。 {(address:a, value:v)} &lt;- get_observation{T} 获取已记录的观察列表。这可以与value_at一起使用，以检查跟踪是否与所有观察结果一致。 set_value_at{T, address:a, value:v} 修改为地址结果存储的值。这主要用于低级推理程序而不是最终用户。 T* &lt;- clone_trace(T) 创建当前跟踪的副本 S &lt;- single_site_subproblem(T, address:a) 将跟踪的分区定义为子集，当重新生成单个随机选择（随机过程应用程序）时，这些子集将被重新生成并保留。这大致相当于[6,2]中“支架”的概念。 表3.1给出了我们原型中定义的跟踪数据结构中这些操作的渐近运行时间。 表3.1：跟踪操作的索引，具有渐近运行时。|e|是运行给定程序e所涉及的子操作的数量; |T|是概率执行轨迹的大小; |S|是子问题的大小，它由取决于建议值的下游随机选择的数量确定。 使用这些跟踪原语，可以定义建模指令以及推理过程和实用程序。有关常见建模指令的实现，请参见图3.4。推理编程将在第4节中介绍。 在我们的原型中，跟踪还提供了可以调用随机过程的关键行为的接口。例子包括应用随机程序; 评估对数密度; 还有模拟内核。这些实现细节超出了本论文的范围。 图3.4：假设，观察和生成的建模指令以宏的形式实现，扩展到上面定义的相应过程的应用程序。observe也是根据修改跟踪以使其满足给定约束的实用程序来定义的。该过程依赖于3.3节中描述的随机再生原语来修改跟踪并传播影响。 图可以见原文 3.3 Stochastic regeneration of trace fragments可以通过统一接口访问跟踪，以便随机（重新）生成程序片段的跟踪，从而促进推理元程序的开发。平面跟踪和依赖关系图跟踪表现出不同的渐近扩展行为（参见表3.2），并且还支持不同的常数因子优化和运行时，使它们适用于不同类别的推理策略。由于这些操作部分地决定了随机过程的要求，因此本章简要介绍了每个关键的随机再生操作。有关随机再生的其他观点，请参见[6]和[2]。 随机再生对子问题进行操作，子问题是跟踪的分区，用于重新生成和保留的随机选择的子集，以及重新生成的随机选择的提议分布。从概念上讲，子问题S将跟踪中的每个随机选择分配到三个集合中的一个（RS; CS; OS），其中 RS是“重新生成”的集合，由正在提议的随机选择或可能因提案而改变的值组成。子问题引起提议分布q（RS）。 CS是“约束”集合，由依赖于RS中的值的随机选择组成; 这些是依赖图中RS的子代。如果节点的输入可能因提议而改变，则节点成为CS的一部分，但它可以评估在给定新输入的情况下产生相同输出的密度或似然比。这些节点与评估提议的可能性相关。 OS是跟踪中不参与提议的其他节点 子问题以“局部后验”分布p（RS|CS; OS）$\\propto$ p（RS|OS）p（CS|RS; OS）为目标，并引起与目标密度和提议密度之间的比率对应的权重函数 请注意，此处理仅针对独立提案q。将非独立提案纳入该框架留待将来开展工作; 见[6]可能的方法 在实践中，子问题表示为从跟踪地址到内核的有序映射，这是随机过程元程序。内核实现了与子问题非常相似的接口，但代表了单个随机过程应用程序上的提议分布。R和C中的节点通过后者与约束内核相关联来区分，约束内核是一种特殊类型的内核，其提议分布总是产生相同的输出值。第5节更详细地描述了随机过程的内核。 与子问题交互的操作如下所述。在下面的描述中，ρ表示跟踪中的原始值，ξ表示建议的值，符号RS(ρ)表示对应于RS中的节点的ρ元素(类似的RS(ξ)。 （weight：w, trace_frament:t）&lt;- exact(T, subproblem:S) 改变迹线以去除对应于子问题S所针对的随机选择的值RS（ρ）。提取这些值并将它们存储在新分配的迹线片段中。返回对应于原始完成迹线的目标和建议概率密度之间的比率的（log）权重。 exact如图3.5所示。图3.5：Extract采用trace和子问题，从跟踪中提取子问题所针对的值，并返回对应于跟踪的目标和提议概率与原始值之间的比率的对数权重 (weight:w) &lt;- regen(T, subproblem:S) 根据提议分布q（RS），对子问题S所针对的随机选择采样新值RS（ξ）。返回与新值的目标概率密度和提议概率密度之间的比率相对应的（log）权重. 与exact返回的权重一起，这使得能够基于独立提议q计算MetropolisHastings在ρ和ξ之间转换的接受率。 图3.6：Regen采用跟踪和提取的子问题，使用新的随机性为目标变量建议新值，并返回跟踪的目标和建议概率与新值之间的比率的对数权重。 restore(T, subproblem:S, trace_fragment:t) 将t中的值返回到跟踪T中。这可以用于拒绝转换。restore如图3.7所示。 图3.7：Restore执行跟踪，提取的子问题以及extract提取的跟踪片段，并从跟踪片段的内容恢复跟踪的状态。 w* &lt;- weight_bound(T,subproblem:S) 返回T的再生权重的上限，适用于拒绝采样。 图3.8展示了tricky硬币示例中的随机再生示例。图3.8：图3.2中示例Tricky硬币模型的随机再生描述 4.Meta-programs for stochastic inference大多数概率编程语言都带有用于执行推理的内置的、不变的元程序，即根据一组用户指定的约束来识别概率模型程序的可能执行。在Venture中，这是一种被称为随机推理的计算。这些元程序可以作为使用内置元编程工具的普通用户空间VentureScript程序编写。 4.1 Exact stochastic inference via rejection sampling本节描述了拒绝抽样推理元程序，它可以执行受“足够随机”约束的任意模型程序。“足够随机”约束是那些约束由模型程序表示的随机选择的约束，这些模型程序具有已知边界的已知边际概率密度（作为输入的函数，对于固定输出）。这个拒绝抽样元程序在图4.1中的norma-normal模型上进行了演示，表明拒绝抽样的结果与分析后验分布相匹配。 图4.1：顶部：一个VentureScript程序，它定义一个简单的正态 - 正态模型，并使用拒绝采样得到一个观察到的y的x的后验样本。下图：从每个程序的500次独立运行中获得的样品的直方图，比较在拒绝取样引起的先前和后部分布下的x分布。真密度曲线以黄色显示：先前的N（0,1）和后$N(2, \\sqrt(1/2))$ 图4.2显示了拒绝采样元程序的实现，它利用了3.3节中讨论的随机再生原语。特别地，回想一下regen（T, S）根据提议分布q（RS, CS）生成新值RS（ξ），并返回权重 此外，weight_bound（T; S）计算（保守的）上限w*，使得 通过这两个操作，可以概述一个简单的拒绝采样算法，用于从子问题 - 局部后验p(RS|CS,OS)中进行采样： 计算子问题S的权重约束w*。 不断的执行（a）重新生成S，用新值ξ填充轨迹并获得权重w。（b）用概率exp（w-w ）= exp（w）= exp（w ），接受ξ。否则，拒绝并再试一次 图4.2中的元程序遵循此模板，另外还检查建议值ξ是否与跟踪中记录的observe语句一致; 如果有任何违规行为，该提案将立即被拒绝。确保了拒绝采样步骤总是以观察为条件进行采样，即使所选择的子问题否则会导致观察到的表达式被重新模拟。使用实用程序check_consistent执行此检查，该程序具有如图4.3所示的简单定义。 在normal-normal例子的情况下： RS是变量x，CS是观测变量y; 提议分布q（RS）只是x，N（0,1）的先验分布; 再生权重减小到对数似然log N（y; x, 1）; 并且权重界限是可能性的密度函数的最大值， 因此，拒绝采样元程序通过将由包括模型程序的正常SP提供的元程序（例如，模拟器和密度）组合在一起来恢复该模型的有效且直接的推理算法。 4.2 Approximate stochastic inference via Metropolis-Hastings本节描述了一个基于Metropolis-Hastings方法构建的推理元程序，它适用于与之前的拒绝抽样元程序相同的推理问题。与拒绝采样不同，拒绝采样在每次调用时从目标条件分布p（RSjCS; OS）返回精确样本，此元数据的输出分布在重复应用下渐近收敛到条件分布。这个元程序在图4.4中的正常 - 正常示例模型上进行了演示，表明采样分布接近后验分布，迭代次数更多。 图4.4：顶部：一个VentureScript程序，它在简单的normal-normal模型上使用重新模拟MH来获得x的近似后验样本。下图：通过对不同步数运行马尔可夫链获得的样本的直方图。随着步数的增加，分布接近目标后部（黄色）。 图4.5显示了Metropolis-Hastings元程序的实现。类似于拒绝元程序，它利用随机再生提出新的样本，但与拒绝不同的是，它不需要再生权重的绝对上界。相反，它使用Extract和regen返回的权重之间的比率(或在日志空间中的差值)： 图4.5：重新模拟MH元程序，根据推理子问题操作提取，重新生成和恢复来定义。 这可以用作接受率，产生在目标分布p（RS，CS|OS）上静止的马尔可夫链。图4.5中的实现遵循此方法。请注意，如果违反任何观察check_consistent将再次用于拒绝。此外，在拒绝转换的情况下，还原用于将跟踪返回到其原始状态。 4.3 Custom model-specific inference meta-programs因为可以在用户空间中编写推理，所以Venture可以将自定义推理算法编写为普通的用户空间程序。用户可以根据通用推理元程序的需求调整对问题的需求，但是一旦他们开发了测试用例并且在准确性和运行时成本方面更好地理解功能需求，就可以进行优化。 4.3.1 Custom Metropolis-Hastings samplers虽然Venture提供了一个基于子问题的随机再生建议的Metropolis-Hastings原语，但用户也可以编写他们自己的Metrois-Hastings程序，从而绕过Venture内置的子问题机制。定制过程可以通过避免一般重新生成策略的解释开销，或者利用分析(例如取消或简化接受率)来提高效率。 图4.6显示了一个这样的自定义推理过程的示例应用，该过程使用专门用于我们正常模型的运行示例的自定义高斯drift提议来实现Metropolis-Hastings采样器。在这种情况下，自定义过程在计算上更有效，因为它的代码专用于模型，并且在推理时更有效，因为提议分布更适合推理问题。 图4.6：顶部：VentureScript程序，它使用自定义用户定义的推理过程（如图4.7所示），用于具有高斯漂移建议的随机游走MH。下图：将从该推理程序获得的马尔可夫链的样本轨迹与图4.4中使用独立重新模拟提议的程序的样本轨迹进行比较的图。更高频率地接受高斯drift提议，这表明定制采样器更有效地探索迹线空间。 自定义高斯drift过程的实现如图4.7所示。该实现利用了高斯drift提议是对称的事实所带来的接受率的抵消： 图4.7：使用高斯漂移提议实现随机游走MH的自定义元程序，专门用于图4.6中的normal-normal模型。 然后，通过从Venture中查询正常程序的对数密度，可以直接计算该简化比率。 4.4 Scaling of stochastic regeneration for approximate inference平面轨迹和依赖图轨迹实现了随机再生的不同算法; 因此，基于随机再生的推理策略在两种类型的迹线上表现出不同的渐近缩放行为和常数因子运行时间。 图4.8比较了隐藏马尔可夫模型程序中基于单站点重新模拟的推理的每次迭代的运行时间，作为HMM中的时间步数的函数。 图4.8：HMM模型程序的推理速度的比较，作为HMM中的时间步数的函数。模型程序显示在左侧，以及展开memoized循环的程序版本，显示HMM中的步骤数如何影响程序长度。对单站点子问题进行推断，其为所有其他变量条件下的状态序列的一个元素提出新值。右边的图显示了子问题构建步骤和重新模拟步骤的时间。计时是在展开的程序上执行的。 推理的每次迭代涉及两种类型的操作：子问题构造，其中识别属于再生和约束集的节点; 和随机再生本身，它重放与这些节点对应的程序部分。 在平坦迹线中，两个操作都需要完整遍历迹线，因此在迹线的大小上是线性的。在第一遍中，程序中的每个子表达以程序执行顺序遍历，标记依赖于所提出的值的所有值（即，重新生成的集合RS）。再生在第二遍中完成，模拟程序的新执行，其中RS中的随机选择使用新的随机性重新采样。尽管似乎可以合并两个通道以使再生步骤不需要再次遍历整个程序，但是整体算法仍将表现出相同的线性缩放。 使用依存关系图跟踪，可以使用深度优先搜索从重新生成的节点到依赖它们的节点的依赖边来识别重新生成的集RS。一旦确认子问题，就可以使用只触及子问题所涉及的节点(及其父级)的遍历来进行重新生成。因此，推理的每次迭代只与子问题|S|的大小相同。然而，这是以更高的实现复杂性和内存开销为代价的。 5 Stochastic procedures随机过程（SP）用于封装简单的概率分布，以及用户空间VentureScript程序和外来概率对象。它们由程序和元程序的链接集合组成，这些程序和元程序共同描述概率程序的各个方面，这些程序对于其在建模和推理中的使用非常重要。例如，它们是将模型程序与其相关密度和推理元程序链接起来的主要手段。SP被设计为允许简单的概率分布，用户空间VentureScript和外部概率程序被统一地视为复杂概率计算的构建块。 Church和其他先前的概率编程语言专注于简单的概率分布，这些概率分布完全由标量值模拟器程序和分析概率密度函数指定。BayesDB [7]允许将更大类的概率对象视为封装的基元 - 即生成种群模型，其描述可以有条件地和无条件地模拟（或评估其密度）的多变量联合分布。Venture封装的概率对象类包括这两个类作为适当的子集。 本文主要研究三种随机过程。这些包括（i）适用于封装广泛类型的概率计算的通用接口，包括可交换随机过程，无可能性原语，以及（至少在原理上）其他概率编程语言的解释器和/或推理引擎; （ii）用于随机过程的简单接口，可以很容易地封装具有已知概率密度函数的概率对象; （iii）当该过程被称为“足够随机”时可以使用的简单接口的变体，即，具有输出本身是具有已知的有界概率密度的随机选择。 与这些类型相关的关键方法可归纳如下： 通用随机程序。这些包括（i）适用于随机生成输出的概率程序，（ii）用于提出新输出并使用旧输出评估其边际密度比的“提议核心”概率推理元程序，以及（iii）专门的“ 约束内核“概率推理元程序，它根据输出值与给定约束匹配的约束重新采样内部随机性。这三种功能允许SP封装任意概率程序，这些程序带有自己的内部潜在变量，以及自定义模拟，推理，密度评估和约束执行机制。 “简单”随机过程。当随机过程在输出上具有已知的边际概率密度时，当再模拟是有效的推理建议策略时，就有可能提供通用SP接口的基线实现。这个简化的接口还处理具有内部突变的SP，这些SPS导致对应于重复输出的随机变量之间的可交换耦合。 “尾部可评估的”随机程序。一些随机程序 - 例如代表具有噪声数据可能性的复杂概率生成模型的程序 - 具有难以处理的边际输出密度，但确实以其内部潜在变量为条件诱导“足够随机”的可能性。这是一个非常重要的特殊情况，VentureScript将其用作默认的随机过程构造语法 在UNIX环境中通过类比于软件包来考虑随机过程是有帮助的。这些包通常包括源代码，二进制文件，测试用例和文档的组合。所有这些组件的存在 - 远远不只是预编译的二进制文件 - 有助于最终用户重新组合软件，特别是熟悉相关约定的软件开发人员和系统管理员。在Venture的情况下，推理元程序和端到端应用程序可以扮演最终用户的角色，动态构建新的随机过程，修改源代码和/或运行时行为，以及使用和构建模型结果。 5.1 Generic stochastic procedures随机过程定义了联合分布p（{yi}; z|{xi}），其中xi是过程的第i个应用程序的输入，yi是第i个应用程序的输出，z表示在第i个应用程序期间做出的任何潜在随机选择。除输出yi之外的SP的应用。 在给定z的情况下，yi不需要是独立的，甚至是条件独立的; 这允许表示可交换耦合过程的SP，例如折叠共轭模型。然而，Venture的随机再生算法假设应用程序是可交换的，因此它们可以以不同的顺序重新生成，同时保留相同的分布属性。 随机过程可以具有可变的内部状态，其可以用于记录潜在随机选择的结果或者通过维持先前应用的充分统计来实现可交换的耦合。虽然PET是Venture中直接可用的唯一本机形式的可变存储，但可以在内部绑定使用可变状态的外部过程，或者暴露用户定义的SP可以使用的可变状态源。 SP可以通过提供一个或多个内核来促进推理编程，所述内核在其随机状态空间（fyig; z）的子集上操作。内核类似于跟踪子问题，并且具有非常相似的契约，允许在SP应用程序期间进行随机选择并重新提出。 可以通过make_sp操作创建一般随机过程： P &lt;- make_sp(metadict_expression:e) 从e指定的元程序集合中创建一个随机过程，该过程应该计算为方法名称和值的字典。 认可的方法包括： y &lt;- apply(p, trace_handle:H,application_id: i, input:x) 将过程应用于输入x，产生输出y并可能记录潜在的选择z。这导致分布p（yi; zi|xi; P）。 跟踪句柄H是周围跟踪的接口，可用于对跟踪的执行引擎进行回调; 请参阅下面的跟踪句柄方法。 l &lt;- log_density(P, output:y, inputs:x) （可选）评估对数密度log p（y|x, P）。并非所有随机程序都实现此方法; 那些被称为可评估程序。 k &lt;- proposal_kernal(P, trace_handle:H, application_id:i) 构造一个内核，该内核对P的先前应用程序的结果进行操作（由应用程序id i给出），表示从该应用程序的可能结果的空间中采样的提议分布q。q的支持应该包括p的支持（仅限于与所选应用程序相关联的SP随机状态的子集）。准选择是q = p，即从先前提出。 内核K应该是符合内核接口的方法名称和值的字典（如下所述）。 K &lt;- constrain_kernal(P, trace_handle:H, application_id:i, constraint_value:y) 构造一个内核，该内核对P的先前应用程序的结果进行操作（由应用程序id i给出），表示其输出的边际分布是值y的delta分布的提议。换句话说，约束内核重新采样受输出值约束的内部随机性（如果有的话）。 内核K表示由SP做出的随机选择子集的提议分布，类似于跟踪的子问题。内核有以下方法： (log_weight:w, trace_fragment:F) &lt;- extract(K, output:y, input:x) 从SP的内部状态中提取目标随机选择的值。返回对应于原始值的目标和建议概率之间的比率的对数权重w（包括任何提取的潜在值） 以及跟踪片段F，它是一个对象，可用于恢复提取前存在的SP状态。 (log_weight:w, output:y) &lt;- regen(K, inputs:x) 使用新的随机性为目标随机选择建议新值。返回日志权重w，以获取新值的目标和提议概率之间的比率 以及新的输出值y。 （output:y） &lt;- restore(K, input:x, trace_frament:F) 使用extract返回的跟踪片段恢复SP的状态。 w* &lt;- weight_bound(K, input:x, input_mask: m) 返回此内核的再生权重w的上限，用于计算子问题的拒绝界限。 输入掩码m是布尔值的列表，其长度与x相同，其对于每个输入参数指示在计算边界时是否应该将其视为固定的或变化的。 跟踪句柄H提供以下与周围轨迹交互的方法： a &lt;- request_address(H, request_id:i) 返回从给定请求ID派生的跟踪地址，适合与以下方法一起使用。请求ID可以是SP用于识别其请求的子程序执行的任何Venture值。例如，复合过程使用调用站点的地址（即application_id）作为请求ID请求执行其正文，而mem（在5.5节中描述）使用输入参数的值作为请求ID。 z &lt;- eval_request(H, request_id:i, expression:e, enviroment:T) 执行环境中表达式表示的程序片段。这是环境跟踪eval_request方法的接口，允许SP对跟踪的解释器进行回调。 z &lt;- value_at(H, request_id:i) 获取给定地址处跟踪中记录的值。这是环境跟踪的value_at方法的接口。 uneval_request(H, request_id:i) 撤消执行请求。这以反向执行顺序遍历程序片段，在所有SP应用程序上调用extract。 z &lt;- restore_request(H, request_id:i) 恢复未评估的请求，以正向顺序遍历程序片段并在所有SP应用程序上调用还原。 执行请求为SP提供了一个集成机制，可以对解释器进行回调，从而实现更高阶的过程，如mem（参见第5.5节），eval，apply和map。重要的是，这些回调由与原始SP应用程序相同的跟踪解释器执行，因此在执行期间进行的依赖关系和随机选择将被公开并可供跟踪元程序检查。例如，这允许依赖性信息通过复合过程的主体和高阶过程的应用来传播。 5.2 “Simple” stochastic procedures当随机过程在输出上具有已知的边际概率密度时，并且当重新模拟是用于推断的有效提议策略时，可以提供通用SP接口的基线实现。 可以使用make_elementary_sp过程创建这样的SP： p &lt;- make_elementary_sp(metadict_expression: e) 从e指定的元程序集合中创建随机过程。该集合预计将实现以下简化的界面，该界面假定SP没有“潜在”结构并且表示具有用于模拟和评估密度的过程的分布p（y|x）。 make_elementary_sp期望的接口是： y &lt;- simulate(P, inputs:x) Return a sample y ~ p(.|x). l &lt;- log_density(P, output:y, input:x) Evaluate the log density log p(y|x). l* &lt;- log_density_bound(P, output: y, inputs: x, input_mask: m) 评估对数密度log p（y|x）的上限。 输入掩码m是布尔值的列表，其长度与x相同，其对于每个输入参数指示在计算边界时是否应该将其视为固定的或变化的。 incorporate(P, output: y, inputs: x) 可选：对于维护其应用程序的足够统计信息的SP，记录输入 - 输出对（x; y）。这在每次apply，regen和restore时调用。 unincorporate(P, output: y, inputs: x) 可选：合并的反转：删除输入 - 输出对（x; y），就好像该应用程序从未发生过一样。这在每个exact的开头都被调用。 可以使用以下方法定义通用SP接口：粗略地，apply调用simulate; 提议内核使用模拟实现重新模拟提议，约束内核使用log_density返回可能性权重。如果定义了合并和非合并，则在每次apply/regen/restore结束时和每个extract的开头分别调用它们 图5.1给出了一个随机过程的例子，该过程从beta分布中取样，首先作为“bare”复合过程，然后作为使用make_elementary_sp定义的过程，同时提供simulate和log_density。尽管两个过程在直接调用以生成样本时具有相同的输出行为，但是跟踪和推理元程序对它们的处理方式不同： 裸复合程序my_beta_1被视为其各部分的总和，每次调用主体中的gamma作为单独的随机选择记录，并且beta程序的输出作为从两个gamma样本计算的值。该过程缺少任何有趣的辅助元程序，特别是输出密度或约束内核，因此其输出不能约束到给定值。 相比之下，my_beta_2被视为单个单元。即使它的模拟器主体仍然调用gamma，这些细节也封装在过程中而不是暴露给跟踪。Instead，它有一个log_density，它表征输出的边际分布，允许它接受输出的约束，并报告从给定输入获得输出值的相对可能性，就像密度函数附带的内置基元一样。 通过这种方式，随机过程为跟踪程序提供了一种抽象方法，就像“normal”过程对未跟踪程序所做的那样。 5.3 “Tail-assessable” stochastic procedures上一节中描述的随机过程是“可评估的”随机过程，因为它们带有易于处理的程序来评估其输出的边际概率密度。 一些随机程序 - 例如代表具有噪声数据可能性的复杂概率生成模型的程序 - 具有难以处理的边际输出密度，但确实以其内部潜在变量为条件诱导“足够随机”的可能性。这是一个非常重要的特殊情况，VentureScript将其用作默认的随机过程构造语法 如果有以下条件，程序f被称为“tailor accessable” 这类程序很有意思，因为即使边际密度难以处理，仍然可以实现约束内核，允许在拒绝采样，重要性采样和Metropolis-Hastings样式提议中对输出y进行调节。 要了解如何为第二种情况构造约束内核，请考虑联合空间（z，y），其目标分布由下式给出： 其中ph和pg分别是由h和g引起的概率密度（注意这些密度不一定易于计算）。然后在（z; y）上定义以下提案分布： 从这个分布中很容易模拟：采样一个新的z~h（x），并设置y = yobs。密度比是 如果密度pg易于计算（即g是可评估的），那么我们就完成了 - 我们有一个从联合空间（z; y）提出样本的程序，我们可以评估我们的提案分布和 目标分布。如果不是，g是假设可以尾部评估的，所以我们也可以递归地为它的输出构造一个约束内核。在递归终止的任何地方，我们都可以模拟和评估密度比（可能在扩展空间（z; y; w; :: :)，如果g也有内部潜伏）。 在VentureScript中，可以使用proc语句构造具有这些语义的复合过程： P &lt;- proc(parameters:p, body:e) 使用给定的参数和主体创建随机过程。这是来自Lisp类语言的lambda的概率类比。 语法是：123proc(x){g(h(x))} 其中一般可能有零个或多个参数（这里，x是唯一的参数），而body是一个在尾部位置有一个过程调用的表达式，其运算符（此处为g）是一个可约束的过程 图5.2显示了实现相同beta-bernoulli过程的两个随机过程定义，一个定义为“bare”复合过程，一个定义为使用proc的尾部可评估过程，以及使用通用make_sp接口的等效扩展定义，显示 差异。定义为裸复合过程的版本没有密度或约束内核元程序，因此其输出不受约束。相反，使用proc定义的版本可以通过委托给其程序体中调用的bernoulli SP的密度元程序来约束。 图5.2：左：作为裸化合物的β-Bernoulli过程的朴素定义，它绘制θ~Beta（a; b）并返回一个翻转一个重量为θ的硬币的闭包。与图5.1中的my_beta_1一样，此闭包没有密度元程序，因此其输出不受约束。右：使用proc的等价定义，这是一个元程序，它采用可尾部评估的过程并为其生成约束内核，它将翻转过程的密度作为其权重返回。底部：使用完整的make_sp接口定义的结果SP的扩展版本 图见原文 Tradeoffs between different representations of the Beta-Bernoulli process随机过程接口使得以多种不同方式表示单个随机过程变得容易。概率程序员可以选择将随机变量暴露给Venture; 代表他们，但保持他们的外围; 或通过边缘化将其摧毁。概率编程人员还可以在VentureScript和更快（但可能更不透明）的本机代码之间选择不同的边界。这种灵活性最终可能对可实现的推理性能产生重大影响。 本节中的示例使用Beta-Bernoulli过程探索了这种自由度，可以根据单个潜在硬币重量来考虑这一过程，从而产生可数无限的硬币翻转序列。这个过程最直接的实现是图5.2中的版本，包含一个复合过程，它关闭一个表示硬币权重weight的变量theta。 此外，我们考虑Beta-Bernoulli过程的两个优化实现。第一个，如图5.4所示，是一个“折叠”表示，其中潜在的硬币重量被整合出来。该程序保持了之前硬币翻转的足够统计数据，并使用它们来模拟（并评估）下一次硬币翻转的后期预测分布，利用Beta和Bernoulli分布的共轭。 第二个实现，如图5.6所示，是一个未折叠的表示，因此它对潜在的硬币重量进行采样而不是将其整合出来。 然而，它还保留了足够的统计数据，并以不同的方式利用Beta-Bernoulli共轭，提供了一个自定义的元程序，可以根据需要从后缀共同重新计算硬币重量。 图5.6：beta-Bernoulli模型的未折叠实现，作为具有共轭Gibbs核的有状态过程。与图5.4中的折叠版本一样，它保持了其应用程序的足够统计数据，这里用于从其共轭后验中精确地对θ进行采样。此Gibbs内核作为SP的自定义元程序提供，可以作为推理程序的一部分进行调用。 图5.4：将collasped的β-Bernoulli模型实现为有状态过程，该过程维护足够的统计量N，应用过程的次数，以及K，过程返回的次数为真。该实现对其可变状态使用通用计数器数据结构，该结构公开了读取，递增和递减操作。 表5.1展示了所描述和比较的表示的总结，图5.3比较了运行时和示例的准确度。 表5.1：β-Bernoulli变体的比较。“Runtime”列描述了对θ进行一轮推断（如果适用）然后模拟或合并新观察的运行时复杂性，其中N是已合并的观测总数。 图5.3：top：beta-Bernoulli模型的示例应用。weight不详的硬币翻转五次。观察翻转并逐个合并，并保留所得的对数似然增量。下图：运行时与对数似然权重的图，改变了β-Bernoulli程序的实施以及每次观察之间进行的推断量。请注意，折叠实现获得模型下数据的真实边际可能性，而其他实现产生噪声近似值，通过更好的推断变得更准确。 图见原文 5.5 Memoization as a user-space stochastic procedureMemoization是高阶程序的规范应用。memoizer是一个过程，它将一个过程作为输入，并返回一个新的过程，在计算它们时在内部缓存值。这可以节省计算时间，特别是对于递归过程，以空间为代价。在概率编程的设置中，memoization可以用作许多有趣的半参数贝叶斯模型的构建块[3]。然而，因为memoization是一个更高阶的过程，它不适合早期实现Church [3,14]的“基本随机过程”的简单模板。本节通过给出用户空间实现memoization来说明Venture的灵活性和随机过程接口。 memoizer的实现如图5.7所示。当应用memoized SP时，它首先查找输入参数并返回现有值（如果有），否则委托给unmemoized SP 图5.7：将memoization实现为用户空间过程，使用外部可变计数器实现引用计数，eval_request对原始未标记SP f进行跟踪调用 图片见论文 该实现依赖于前面描述的执行请求，该请求允许它对原始未标记的SP进行跟踪调用。这是通过在f绑定到原始SP的地址的环境中请求执行形式为f（x）的程序片段来完成的。 使用执行请求允许已记忆的SP挂钩到依赖性跟踪机制，例如，当提交到备忘SP的主体中的随机选择时，该选择会影响将返回的值，SP的所有应用程序 通知相同的输入参数，以便它们可以传播新值。这种行为可以由SP定义一个额外的内核propagating_kernel来控制，该内核通过依赖关系跟踪实现用作优化 图5.8显示了使用memoization定义HMM的隐藏状态序列的示例模型程序。 x（t）是一个记忆值，指的是第t个时间步的状态。 通过这种方式，memoization定义了一个无限延迟的随机变量序列，只有在必要时才会实例化。 图5.8：具有二进制状态和观察的HMM的实现，使用mem来记忆状态序列 6 Discussion本文描述了Venture的一个新原型实现，Venture是一个概率元编程平台，解决了其他概率编程语言表达的基本限制。使用Venture，可以将用于描述概率密度函数和执行推理的元程序编写为普通用户空间代码。此外，该语言具有足够的表达能力，允许外国原语和中介语复合程序表示看似同类的概率对象。这些功能仅在早期版本的Venture中部分实现。通过展示如何为必须内置于其他概率语言的对象和操作的用户空间实现来说明所产生的灵活性。 Venture的一个限制是它目前缺少（i）简单的元循环解释器和（ii）形式语义。这两者都是构建Venture行为不完整模型的补充方法。每一个都可以用来澄清语言的设计，帮助进行性能工程，并支持开发更复杂的建模和推理元程序。这两种方法也可以帮助揭示设计缺陷和实施缺陷，并为评估潜在的补救措施提供具体的基础。依赖跟踪和随机再生的元循环实现也可以为调试提供强大的工具。考虑到Venture程序员可以使用建模和推理来提供机器帮助，通过询问“哪些随机选择可能导致此推理元程序显示此特定模型程序跟踪？”来查找指示错误的不太可能的边缘情况。 性能工程是未来工作的关键领域。VentureScript的当前原型实现比几个以前版本的Venture慢。这不是实际应用的基本障碍，但由于开发周期缓慢，它确实阻碍了应用工作。事实上，VentureScript是高阶的，并且在本机代码和VentureScript之间保持对称，这意味着增量编译 - 可能是VentureScript到VentureScript转换，除了VentureScript到本机代码编译器之外 - 可能是一种吸引人的策略。例如，许多模型具有相对静态的结构，因此Venture的通用子问题构造和再生算法总是在跟踪图中的节点上执行类似的遍历。专门的编译器可以消除该遍历，从而使更高效的程序专门用于该模型和推理子问题，使用较低级别的跟踪操作来直接读取和改变跟踪并计算适当的似然比。 未来工作的另一个关键领域是开发特定于领域的语言和用于概率建模和推理的库。 VentureScript是目前唯一的内置语言，它实现了关于如何组合指定模型和推理方案的特定假设。 它为用户提供了一种用元数据注解模型，用元数据构造有意义的子问题，并结合通用推理库例程和自定义推理策略来解决这些子问题的方法。 VentureScript在很大程度上依赖于随机过程接口的约定，但它只是设计空间中的一点，而且这些约定本身可能不是最优的。 至少，需要扩展这些约定，以定义添加其他元程序(如梯度信息)的最佳实践，这些元程序是基于优化的推理和变分技术的关键。 还必须探讨推理程序的静态检查，并尝试开发具有适当的可靠性或完备性的正式保证的推理库。 本文证明了用一种简单的高阶语言来表示随机变量、密度函数和推理算法的概率规划平台是可行的。 关键思想包括扩充Lisp以支持(I)对程序行为的具体化和反思，(Ii)将概率程序和元程序链接到单个包中。 与其他概率编程平台相比，这种对反射元编程的关注带来了更大的灵活性和可扩展性。 它还可能提出新的方法来理解概率规划的基本技术挑战。 考虑UNIX系列操作系统。 UNIX通常用于组装和维护交互程序的集合，包括监视和修改彼此的运行时行为的程序。 这些程序通过共享文件系统和显式回调等机制进行通信。 可以通过反射机制(如strace和gdb)检查正在运行的UNIX程序的内部行为和可变状态的关键方面。 其中一些机制与Venture中用于反射和元编程的工具非常相似，UNIX中的堆分配内存扮演着类似于概率执行跟踪的角色。 UNIX性能工程的思想因此可能与Venture相关。 也可能是来自操作系统和其他形式的系统软件的思想，而不仅仅是编程语言和单语言编程系统，可以帮助我们形式化和自动化概率建模和推理的关键方面。","link":"/2019/04/04/MIT论文1-Venture-用于概率元编程的可扩展平台/"}],"tags":[{"name":"项目","slug":"项目","link":"/tags/项目/"},{"name":"Linux使用","slug":"Linux使用","link":"/tags/Linux使用/"},{"name":"实用工具","slug":"实用工具","link":"/tags/实用工具/"},{"name":"工作日志","slug":"工作日志","link":"/tags/工作日志/"},{"name":"博客遇到的问题","slug":"博客遇到的问题","link":"/tags/博客遇到的问题/"},{"name":"博客有关","slug":"博客有关","link":"/tags/博客有关/"},{"name":"语音合成","slug":"语音合成","link":"/tags/语音合成/"},{"name":"概率编程","slug":"概率编程","link":"/tags/概率编程/"},{"name":"求职","slug":"求职","link":"/tags/求职/"},{"name":"概率计算","slug":"概率计算","link":"/tags/概率计算/"}],"categories":[{"name":"Intel与概率计算","slug":"Intel与概率计算","link":"/categories/Intel与概率计算/"},{"name":"其他","slug":"其他","link":"/categories/其他/"},{"name":"工作周报与报告","slug":"工作周报与报告","link":"/categories/工作周报与报告/"},{"name":"probabilistic programming","slug":"probabilistic-programming","link":"/categories/probabilistic-programming/"},{"name":"数字IC设计","slug":"数字IC设计","link":"/categories/数字IC设计/"}]}