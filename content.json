{"pages":[],"posts":[{"title":"Ubuntu_Linux使用笔记","text":"Ubuntu使用过程遇到的问题所做的笔记 ubuntu 解决“无法获得锁 /var/lib/dpkg/lock -open （11：资源暂时不可用）”的方法 ubuntu 解决“无法获得锁 /var/lib/dpkg/lock -open （11：资源暂时不可用）”的方法在ubuntu系统的termial下，用apt-get install 安装软件的时候，如果在未完成下载的情况下将terminal close。此时 apt-get进程可能没有结束。结果，如果再次运行apt-get install 命令安装如今，可能会发生下面的提示： 无法获得锁 /var/lib/dpkg/lock - open (11: 资源暂时不可用)无法锁定管理目录(/var/lib/dpkg/)，是否有其他进程正占用它？ 解决办法如下： 终端输入 ps aux ，列出进程。找到含有apt-get的进程，直接sudo kill PID。 强制解锁,命令sudo rm /var/cache/apt/archives/locksudo rm /var/lib/dpkg/lock","link":"/2019/04/04/Ubuntu_Linux使用笔记/"},{"title":"MIT概率计算小组","text":"为什么Intel的概率计算会和MIT的概率计算挂钩呢 项目地址：http://probcomp.csail.mit.edu/ 为什么Intel的概率计算会和MIT的概率计算挂钩呢Mayberry在IEEE Spectrum的访谈中提到过：(Mayberry recommends a look at the work of Vikesh Mansighka, who leads the Probablistic Computing Project at MIT.) 同时根据MIT项目小组的新闻公告也提及过： June 2017: Vikash presented at the Technology Strategy and Leadership (TSLRP) meeting at Intel, including Intel’s CEO, management committee, and fellows. We briefed the company on new opportunities in probabilistic AI, including our work on building analogs of TenserFlow and the GPU for probabilistic programing.","link":"/2019/04/02/MIT概率计算小组/"},{"title":"python使用","text":"记录下python使用的小技巧等 1.python查看包的版本 2.python安装包所在的路径 3.pip安装时候报错 a distutils installed project 4.安装时报错 EnvironmentError: [WinError 5] 拒绝访问 1.python查看包的版本12345python -v ## 查看python的包的版本## 进入pythonimport scipyscipy.__version__ ##两条下划线 2.python安装包所在的路径C:\\Users\\XuZhikang\\Anaconda3\\Lib\\site-packages 3.pip安装时候报错 a distutils installed project报错内容如下所示1Cannot uninstall &apos;scipy&apos;. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. 解决方法：强行安装更新更高的版本1pip install --ignore-installed numpy 4.安装时报错 EnvironmentError: [WinError 5] 拒绝访问报错内容：12Could not install packages due to an EnvironmentError: [WinError 5] 拒绝访问。: &apos;c:\\\\users\\\\xuzhikang\\\\anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\.libs\\\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll&apos;Consider using the `--user` option or check the permissions. 解决方法：在pip安装命令后的install后面加上–user便可解决1pip install --user --ignore-installed scipy","link":"/2019/04/26/python使用/"},{"title":"博客搭建","text":"2019年3月29号星期五，我花了一个晚上的时间搭建个人的博客。用来记录下博客搭建过程中的坑。 1.搭建步骤 2 安装主题 3. 设置主题 4.编辑博客 1.搭建步骤参考博客：结合hexo在GitHub上搭建个人博客——全过程） 参考博客：超详细Hexo+Github博客搭建小白教程 搭建过程不难，主要过程为 创建github账户 安装Node.js 安装Git Git在某个文件夹下安装Hexo 连接Github与本地 期间遇到的问题是： 123XuZhikang@DESKTOP-U2I0R4H MINGW64 /e/Blog$ cd ~/.sshbash: cd: /c/Users/XuZhikang/.ssh: No such file or directory 原因是安装git后没有ssh 解决方法参考博客：在windows7下安装git后没有ssh 2 安装主题主题下载网站：https://hexo.io/themes/ 期间遇到一个问题：我最先下载的主题是hexo-theme-A-RSnippet,但是这个好像有问题，还是我没有设置正确，不能正常更新主题。 推荐另外的一个主题是：icuras 主题的安装的方法： 用git clone把主题下载下来 把解压的主题放在根目录下的themes下 更改根目录下的_config.yml文件的language 为zh-CN和theme为icarus 更改主题后：1234hexo g 生成静态网页hexo s 打开本地服务器hexo clean 清除缓存hexo d 上传到github 有一个技巧就是不必要每次更改之后都关闭本地服务器，再重新打开本地无服务，*直接刷新网页，可能更改就已经生效。 3. 设置主题主题安装之后，需要改变E:\\Blog\\themes\\icarus下的_config.yml参数 我改动的项为： menu:下英文改为中文 主页 归类 分类 标签 widgets下的：作者名字 作者title等 把social_link注释掉 link注释了，本来想吧github的链接改为邮箱，貌似不能 打赏的全部注释了 icarus的可玩性貌似没有那么高，如果想更多的去添加博客的网页的功能，可以试一试Next这个主题。 bilibili上有专门讲解的使用Hexo博客搭建的个人博客，使用Next主题来进行优化改造 4.编辑博客在E:\\Blog\\source_posts目录下打开Git bash, 创建新文章： 1hexo n &quot;博客搭建&quot; 这里提供一些基本方法 博客的开头你需要更改才能适配到分类和标签下 123456---title: 博客搭建date: 2019-03-29 23:18:54tags: 博客有关categories: 博客--- 为了只显示部分开头内容，下面加上 1&lt;!-- more --&gt; 添加更多的标签12345678---title: 博客搭建date: 2019-03-29 23:18:54tags: -博客有关 -测试等categories: 博客---","link":"/2019/03/29/博客搭建/"},{"title":"实用工具","text":"推荐一下使用的软件 一键生成视频中的字幕，详细介绍字幕通Yee Caption v2.0.0.05官方版 下载youtube（用浏览器自带的下载），网络上的视频，网站Apowersoft免费在线下载 youtube视频支持双语字幕，YouTube双字幕Chrome插件地址 看论文时，复制粘贴英文论文到翻译工具时，会按照原格式换行，原网站 另外一个自动翻译工具，调用google的API，CopyTranslate下载地址","link":"/2019/04/02/实用工具/"},{"title":"Deep Probabilitic Programming","text":"Deep Probabilitic Programming Absract 1 INTRODUCTION 2 RELATED WORK 3.COMPOSITIONAL REPRESENTATIONS FOR PROBABILISTIC MODELS Absract我们提出Edward，一种图灵完备的概率编程语言。Edward定义了两种成分表征 - 随机变量和推理。通过将推理视为一流的公民，与建模相提并论，我们表明概率编程可以像传统的深度学习一样灵活，计算效率高。为了灵活性，Edward使用各种可组合的推理方法轻松地拟合相同的模型，从点估计到变分推理到MCMC。此外，Edward可以重复使用建模表示作为推理的一部分，促进丰富的变分模型和生成对抗网络的设计。为了提高效率，Edward被集成到TensorFlow中，为现有的概率系统提供了显着的加速。例如，我们在基准逻辑回归任务中表明，Edward比Stan快至少35倍，比PyMC3快6倍。此外，Edward不会产生运行时开销：它与手写的TensorFlow一样快。 1 INTRODUCTION深度神经网络的本质是组成。用户可以创造性地连接图层，而不必担心如何执行测试（向前传播）或推理（基于梯度的优化，具有反向传播和自动区分）。 在本文中，我们设计了概率编程的组合表示。概率编程允许用户将生成概率模型指定为程序，然后将这些模型“编译”为推理过程。概率模型本质上也是成分的，并且许多工作通过随机变量的组合实现了丰富的概率程序(Goodman等人，2012; Ghahramani，2015; Lake等人，2016)。 然而，较少的工作考虑了推理的类似组成。相反，许多现有的概率编程语言将推理引擎视为黑盒子，从模型中抽象出来。这些无法捕捉重用模型表示的概率推论 - 变量推理的最新进展中的一个关键思想（Kingma＆Welling，2014; Rezende＆Mohamed，2015; Tran等，2016b），生成对抗网络（Goodfellow等， 2014），以及更经典的推论（Dayan等，1995; Gutmann＆Hyvärinen，2010）。 我们提出了Edward1，一种图灵完备的概率编程语言，它基于两个组合表示 - 一个用于随机变量，一个用于推理。通过将推理视为一流的公民，与建模相提并论，我们表明概率编程可以像传统的深度学习一样灵活，计算效率高。为了灵活性，我们展示了Edward如何使用各种可组合的推理方法轻松地拟合相同的模型，从点估计到变分推理到MCMC。为了提高效率，我们展示了如何将Edward集成到现有的计算图框架中，例如TensorFlow（Abadi等，2016）。像TensorFlow这样的框架提供了计算优势，如分布式训练，并行性，矢量化和“免费”GPU支持。例如，我们在基准测试任务中显示，Edward的哈密尔顿蒙特卡罗比现有软件快许多倍。此外，Edward不会产生运行时开销：它与手写的TensorFlow一样快。 2 RELATED WORK概率编程语言（PPL）通常利用推理的计算效率来折衷语言的表达性。一方面，有一些语言强调表达能力（Pfeffer，2001; Milch等，2005; Pfeffer，2009; Goodman等，2012），代表了超越图形模型的丰富类。每个都使用通用推理引擎，但在模型和数据大小方面的扩展性很差。另一方面，有一些语言强调效率（Spiegelhalter等，1995; Murphy，2001; Plummer，2003; Salvatier等，2015; Carpenter等，2016）。PPL仅限于特定类型的模型，并且优化推理算法以使该类有效。例如，Infer.NET为图形模型实现了快速消息传递（Minka等，2014），而Augur使用GPU实现数据并行性，以便在贝叶斯网络中进行Gibbs采样（Tristan等，2014）。Edward填补了这一空白 图灵完备的 - 它支持任何可计算的概率分布 - 它支持有效的算法，例如利用模型结构的算法和扩展到海量数据的算法。 先前对图灵完备语言中的高效算法进行了一些研究。Venture和Anglican设计推理作为局部推理问题的集合，在程序片段上定义（Mansinghka等，2014; Wood等，2014）。这产生了我们构建的快速程序特定的推理代码。两种系统都不支持推理方法，例如可编程后验近似，推理模型或数据子采样。与我们的工作同时，WebPPL以摊销推理为特色（Ritchie等，2016）。与Edward不同，WebPPL不重用模型的表示; 相反，它注释原始程序并利用辅助函数，这是一种不太灵活的策略。最后，推理被设计为Kiselyov＆Shan（2009）的程序转换; Scibior等人。（2015）; Zinkov＆Shan（2016）。这使得在其他概率程序内进行推理的灵活性成为可能。Edward建立在这个想法的基础上，不仅包括建模中的推理，还包括推理中的建模（例如，变分模型）。 3.COMPOSITIONAL REPRESENTATIONS FOR PROBABILISTIC MODELS我们首先开发概率模型的组合表示。我们需要两个标准：（a）与计算图形集成，一个有效的框架，其中节点代表对数据的操作，边缘代表它们之间传递的数据（Culler，1986）; （b）图表下的表示的不变性，即表示可以在推理期间重复使用。 Edward将随机变量定义为关键的组成表示。它们是具有方法的类对象，例如，用于计算对数密度和采样。此外，每个随机变量x与张量（多维阵列）x 相关联，其表示单个样本x~p（x）。该关联将随机变量嵌入到张量上的计算图上。 该设计的简单性使得在计算图框架中开发概率程序变得容易。重要的是，所有计算都在图表上表示。这使得人们能够构建具有复杂确定性结构的随机变量，例如深度神经网络，多种数学运算以及构建在相同框架上的第三方库。该设计还使随机变量的组合能够捕获复杂的随机结构。 作为一个例子，我们使用Beta-Bernoulli模型， $p(x,\\theta)=\\mathtt{Beta}(\\theta,1,1)$ Bernoulli $(x_n,\\theta)$，其中 $\\theta$ 是在50个数据点x∈{0,1} 50之间共享的潜在概率。随机变量x是50维的，由随机张量θ*参数化。获取对象x运行图形：它从生成过程模拟并输出50个元素的二进制向量。 图1：Beta-Bernoulli程序（左）及其计算图（右）。从图中获取x会生成50个元素的二进制向量。 所有的计算都是象征性地登记在随机变量上，而不是在它们的执行过程中。符号表示不需要具体化整个模型，这会导致大型模型不合理的内存消耗(Tristan等人，2014)。此外，它使我们能够在执行任何代码之前，简化图中的确定性和随机性操作(Scibior等人，2015；Zinkov&amp;Shan，2016)。 使用计算图，在概率程序中构建可变状态也是很自然的。作为计算图的典型用法，这种状态可以定义模型参数; 在TensorFlow中，这是由tf.Variable给出的。另一个用例是用于构建判别模型p（y | x），其中x是作为训练或测试数据输入的特征。程序可以独立于数据编写，在其图形中使用x的可变状态（tf.placeholder）。在训练和测试期间，我们为占位符提供适当的值。 在附录A中，我们提供了用于分类的贝叶斯神经网络（A.1），潜隐Dirichlet分配（A.2）和高斯矩阵分解（A.3）的示例。我们在下面介绍其他例子","link":"/2019/04/09/Deep-Probabilitic-Programming/"},{"title":"博客使用","text":"记录下博客使用过程中遇到的问题 1.hexo d后 ERROR Deployer not found: git 2.Hexo添加Toc支持，生成文章目录 3.使用本地的Markdown编辑器 4.添加代码段高亮 5.为文章添加分类 1.hexo d后 ERROR Deployer not found: git解决办法 1npm install --save hexo-deployer-git 即可 2.Hexo添加Toc支持，生成文章目录Hexo本身是不支持生成文章目录的，通过如下的方法 参考博客Hexo添加Toc支持，生成文章目录 后面发现不能支持生成目录，是在markdown的笔记中写法不对 开头应该是：1&lt;!-- toc --&gt; 而不是有道云中的[toc] 3.使用本地的Markdown编辑器原来用有道云打开，但是这个蛋疼的是，不会保存本地，只能上传。于是乎下载一个编辑器。 逛了一圈，有收费的还有英文不支持中文的，还有没法调实时显示的。还是用很多人用的MarkdownPad吧。下载地址 安装之后蛋疼的是，右侧也没法实时显示，一直提示有个Bug。 win8和win10,没法实时渲染。解决办法：win10下MarkdownPad 2的html渲染出错解决 4.添加代码段高亮参考：markdwon快速入门 5.为文章添加分类在文章开头的模板为123456789101112---title: 工作日志date: 2019-04-08 10:01:30tags: 工作日志categories: 工作周报与报告---从2019年4月8日开始的工作日志&lt;!-- more --&gt;&lt;!-- toc --&gt;","link":"/2019/03/30/博客使用/"},{"title":"工作日志","text":"从2019年4月8日开始的工作日志 2019年4月2日-2019年4月8日 2019年4月9日-2019年4月15日 2019年4月16日-2019年4月22日 2019年4月23日-2019年4月29日 2019年4月2日-2019年4月8日这周主要内容包括： 整理了一下Intel有关概率计算的报道，其中包括3月1日，英特尔新上任的实验室主任Rich Uhlig接受IEEE Spectrum的访谈，从我理解的来看，概率计算（probabilistic computing）应该就是，概率机器学习，贝叶斯机器学习的内容，实现方式就是概率编程（probabilistic programming）,能够进行少样本的数据学习，理解并能处理自然数据中的不确定性。Intel概率计算报道 论文1《Probabilistic programming in Python using PyMC3》概率编程允许用户定义概率模型进行自动贝叶斯推理。马尔可夫链蒙特卡罗(MCMC)抽样的最新进展允许对越来越复杂的模型进行推理。这类MCMC，称为哈密顿蒙特卡罗，需要梯度信息，而这往往是不容易获得的。PyMC3是用Python编写的一个新的开源概率编程框架，它使用Theano通过自动微分来计算梯度，并在运行时将概率程序编译到C中以提高速度。与其他概率编程语言相反，PyMC3允许直接在Python代码中进行模型定义。由于不需要特定于领域的语言，因此具有很大的灵活性和与模型的直接交互。本文是对此软件包的教程式介绍。 论文2《Venture: an extensible platform for probabilistic meta-programming》,该论文是MIT概率编程团队2016年，介绍了Venture这个概率编程平台，Venture和其他编程语言相比最大的特点是可定制性，它把程序执行过程中查看概率选择的迹（trace）,以及搭建推理程序的基本模块，封装成函数提供给用户，可以在这基础上搭建新的推理方法和进行模型验证 在youtube看了有关概率编程的会议PROBPROG 2018，Talks前10个talk，有关介绍他们的编程库，还有关研究团队谈及他们对概率编程的应用。我的简单笔记 2019年4月9日-2019年4月15日这周学习内容包括： 谷歌基于Tensorflow开源的概率编程语言Edward 《Deep Probabilitic Programming》。Edward，一种图灵完备的概率编程语言。Edward定义了两种成分表征 - 随机变量和推理。通过将推理视为一流的公民，与建模相提并论，我们表明概率编程可以像传统的深度学习一样灵活，计算效率高。为了灵活性，Edward使用各种可组合的推理方法轻松地拟合相同的模型，从点估计到变分推理到MCMC。此外，Edward可以重复使用建模表示作为推理的一部分，促进丰富的变分模型和生成对抗网络的设计。为了提高效率，Edward被集成到TensorFlow中，为现有的概率系统提供了显着的加速。例如，我们在基准逻辑回归任务中表明，Edward比Stan快至少35倍，比PyMC3快6倍。此外，Edward不会产生运行时开销：它与手写的TensorFlow一样快。 Facebook开源的基于Pyto 《Pyro:Deep Universal Probabilistic Programming》Pyro是一种基于Python的概率编程语言，作为在AI研究中开发高级概率模型的平台。为了扩展到大型数据集和高维模型，Pyro使用基于PyTorch构建的随机变分推理算法和概率分布，PyTorch是一个现代GPU加速的深度学习框架。为了适应复杂或模型特定的算法行为，Pyro利用Poutine，一个可组合构建块库，用于修改概率程序的行为。 学了一些关于语音合成的基本知识，找了几篇关于深度学习在语音合成上的应用，其中一篇谷歌2017年发表的《TACONTRON: A Fully End-to-End Text-To-Speech Synthesis Model》通常的TTS模型包含许多模块，例如文本分析， 声学模型， 音频合成等。而构建这些模块需要大量专业相关的知识以及特征工程，这将花费大量的时间和精力，而且各个模块之间组合在一起也会产生很多新的问题。TACOTRON是一个端到端的深度学习TTS模型，它可以说是将这些模块都放在了一个黑箱子里，我们不用花费大量的时间去了解TTS中需要用的的模块或者领域知识，直接用深度学习的方法训练出一个TTS模型，模型训练完成后，给定input,模型就能生成对应的音频。TACOTRON是一个端到端的TTS模型，模型核心是seq2seq + attention。模型的输入为一系列文本字向量，输出spectrogram frame, 然后在使用Griffin_lim算法生成对应音频。模型结构如下图： 对于深度学习中网络架构，激活函数，代价函数的选择有些疑惑。还是回过头翻阅了一下深度学习花皮书。 一般来说参数模型定义了一个分布p,并且简单地使用最大似然原理，意味着我们使用训练数据和模型预测间的交叉熵作为代价函数。输出层的函数选择一般包括用于高斯输出的分布的线性单元，用于Bernoulli输出分布的sigmoid单元，用于Multinoulli输出分布的softmax单元。 激活函数的常用选择是整流线性单元ReLu函数 $g(z)=max(0,z) $。整流线性单元易于优化，因为它们和线性单元非常类似。线性单元和整流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为零。这使得只要整流线性单元处于激活状态，它的导数都能保持较大。它的梯度不仅大而且一致。整流操作的二阶导数几乎处处为0，并且在整流线性单元处于激活状态时，它的一阶导数处处为1。这意味着相比于引入二阶效应的激活函数来说，它的梯度方向对于学习来说更加有用。其他的典型激活函数还包括logistic sigmoid与双曲正切函数，径向基函数RBF,softplus函数，硬双曲正切函数 架构设计：万能的近似性质和深度定理告诉我们，具有单层的前馈网络足够表示任何函数，但是网络层可能大的不可实现，并且无法正确的学习和泛化。在很多情况下,使用更深的模型能够减少表示期望函数所需的单元的数量,并且可以减少泛化误差。这就是为什么要选择深层模型的原因，但是用更深的网络训练带来的问题是，在梯度反向传播的时候，会出现梯度显示，而无法对模型正常训练，并达到收敛 总结：这周在看了关于Edward，和Pyro的概率编程，能够支持贝叶斯深度学习，概率机器学习，想利用Tensorflow等平台提供的概率编程工具搭建概率编程与深度学习，解决的实例可以是语音合成等。当我看的谷歌等关于深度学习在语音合成上的应用，发现对深度学习里面的架构，激活函数等的选择不太理解，返回去补了下相关知识。另外团队购买的开发板ZCU104是可以做深度学习的《ug1327-DNNDK User Guide》，Xlinx给的Demo是包括ResNet-50物体识别，人脸识别，动作检查等，最近也在看它的手册 2019年4月16日-2019年4月22日 深度学习花皮书200页~400页 深度学习中的正则化 深度模型中的优化 卷积神经网络 序列建模：循环与递归网络 台湾大学李宏毅的深度学习课程 Why deep structure Optimization Generalization Specical Network structure，Seq-to-Seq Learning 总结：本周学的内容，让我对深度学习中防止过拟合，正则化手段包括参数范数惩罚，提前终止，Bagging集成方法，Dropout等有了较深的了解。 深度学习中的学习算法的优化，算法主要使用的是，SGD,Momentum(动量)这两种，自适应学习率算法，包括AdaGrad,RMSProp,Adam，这些算法都是利用Heissian矩阵去优化学习率。现在用的比较多的是Adam+Momentum 卷积神经网络CNN与循环神经网络代表LSTM的基本架构。 深度学习中的不稳定性，在ImageNet 上应用GoogLeNet (Szegedy et al., 2014a) 的对抗样本生成的演示。通过添加一个不可察觉的小向量。可以改变GoogLeNet 对此图像的分类结果。 2019年4月23日-2019年4月29日这周主要在整理原来有关概率编程，贝叶斯深度学习的文章。关键点：== 机器知道学到了什么，也要知道没有学习什么，深度学习中的不确定性表征 ==。 LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-44 精读，深度学习的survey 这是深度学习几个大佬2015年发表在Nature上的Survey性质的文章，主要是介绍的是深度学习的基本理论知识，常见的两种架构DNN和RNN和他们的基本使用场景，文章的最后也提到了深度学习的未来包括Unsupervised learning，Natural language understanding，以及complex reasoning（机器怎么去在复杂环境下推理） Ghahramani, Zoubin，”Probabilistic machine learning and artificial intelligence” 10.1038/nature14541(2015/05/27/online) 精读 概率机器学习，机器学习中的概率框架的出发点 机器学习的概率框架的核心思想是：学习可以看做是推理合理模型以用于解释被观测的数据的过程。一台机器可以利用此模型去预测未来的数据，并基于这些预测进行理性的决策。不确定性在这一切中起了基础的作用，观测数据数据可以符合多个模型，因此那个模型适用于给定的数据是不确定的。相似的，未来数据和预测活动的结果也是不确定的。概率框架提供了对不确定性的建模。在科学数据分析，机器学习，机器人技术，认知科学和人工智能领域中扮演着重要的角色。这篇评论介绍了这种框架，并讨论的最新的进展——概率编程，贝叶斯优化，数据压缩以及模型自动发现 Thomas Wiecki(2016,Jun 1).Bayesian Deep Learning Variational Inference: Bayesian Neural Networks.[Web Blog post].Retrieved from:https://twiecki.io/blog/2016/06/01/bayesian-deep-learning/ 精读，讨论了贝叶斯与深度学习的桥接 桥接深度学习与概率编程：一方面概率编程可以让我们以原则化和易于理解的方式构造比较小的，集中的模型来深入了解数据模型。另一方面，使用深度学习启发式方法来训练大量高度复杂的模型，这些模型的预测效果惊人。最近变分推理中的创新能够使概率编程扩大模型复杂性和数据的大小。概率编程可以被应用在广泛的问题中，在深度学习中，可以考虑一下几点。预测中的不确定性，表示中的不确定性，先验正则，知情先验的迁移学习，分层神经网络，其他混合架构。作者给出了一个简单的非线性可分的二分类问题，搭建简单的两层DNN,并为各层的权重赋以正态分布的先验，最后的输出层为Bernoulli分布，观测到样本数据后，利用ADVI变分推理算法计算各层权重的后验分布。结果上，训练的贝叶斯神经网络的预测效果十分的明显，有94.19%分类正确率。更多通过贝叶斯神经网络带来的是，后验分布预测的标准差，反映了预测中的不确定性。越接近决策边界，对哪个标签预测的不确定性越高。可以想象，将预测与不确定性联系起来是许多应用（如医疗，无人驾驶）的关键属性。为了进一步最大化准确度，可以根据来自高不确定区域的样本来重新训练模型。 Thomas Wiecki(2016,July 05)Bayesian Deep Learning Part II: Bridging PyMC3 and Lasagne to build a Hierarchical Neural Network.[Web Blog post].Retrieved from:https://twiecki.io/blog/2016/07/05/bayesian-deep-learning/ 精度，讨论了贝叶斯深度学习中的分层神经网络，卷积贝叶斯网络 作者展示如何利用PyMC3和Lasagne以构建密集的2层ANN。使用mini-batch ADVI将模型拟合到MNIST手写数字数据集上。分层人工神经网络。利用Lasagne模块的功能，构建具有最大池层的分层贝叶斯卷积ANN，以在MNIST上实现98％的准确度。利用处于贝叶斯框架中的优势，能够探索预测中的不确定性。由于预测是类别，不能简单地计算后验预测标准偏差。取而代之的是，计算卡方统计量，能够知道样本预测结果的分布的均匀程度。越均匀，说明不确定性越高。当模型出错时，分类结果越不确定。 Gal Y , Ghahramani Z . Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference[J]. Computer Science, 2015. 精读，CNN的kernel为概率分布，能够有效的防止过拟合，提高系统的鲁棒性 CNN在小数据集上的学习容易过拟合，这是因为使用dropout在中间层中有效，当它放在kernel上时也会导致效果减少。为了解决这个问题，该论文提出了一种有效的贝叶斯卷积神经网络，通过在CNN内核上设计概率分布，能够有效的防止小数据的过拟合，为系统提供了更好的鲁棒性。论文作者假设该模型的复杂后验分布近似于伯努利变分分布，不需要给模型增加额外的学习参数。模型实现使用现有工具，几乎不需要任何开销。根据证明的理论，将casting dropout训练作为贝叶斯神经网络中的近似推断，使用蒙特卡罗MC dropout作为CNN中核的近似积分的理论依据。通过实验观察到MC dropout能够提高了模型架构的性能,而标准dropout近似不能。但这这带来了较慢的测试时间，因此推理近似的最佳选择应该取决于问题的类型与规模。 思考：通信中很多场景下的数据量不能称之为大数据，如果应用到深度学习上进行分类预测，容易造成过拟合。另外通信中信号的传输场景的不确定性，噪声的不确定性，给利用机器学习进行信号处理造成了很大的困难。从论文5可以知道，在CNN内核上假定伯努利变分分布，有类似Dropout的效果，能够有效的防止过拟合,提高小数据量下训练系统的鲁棒性。另外从论文3,4下能看到，利用贝叶斯深度学习进行训练预测，可以得到预测结果的不确定性，能够给噪声环境下的通信，提供有效的预测，与可解释的结果，以对信号进一步进行处理。","link":"/2019/04/08/工作日志/"},{"title":"Pyro:Deep Universal Probabilistic Programming","text":"Pyro:Deep Universal Probabilistic Programming Absract Introduction Design Principle Project Openness and Development 4. Existing Systems 5. Experiments AbsractPyro是一种基于Python的概率编程语言，作为在AI研究中开发高级概率模型的平台。为了扩展到大型数据集和高维模型，Pyro使用基于PyTorch构建的随机变分推理算法和概率分布，PyTorch是一个现代GPU加速的深度学习框架。为了适应复杂或模型特定的算法行为，Pyro利用Poutine，一个可组合构建块库，用于修改概率程序的行为。关键词：概率编程，图形模型，近似贝叶斯推理，生成模型，深度学习 Introduction近年来，结构丰富的概率模型已经在AI的许多基本问题上展示了有希望的结果（Ghahramani（2015））。但是，大多数这样的模型仍然是从零开始实现的系统，这减缓他们的发展，限制他们的范围和可扩展性。概率编程语言（PPL）有望减轻这种负担，但实际上，更高级的模型通常需要针对特定​​应用定制的高性能推理引擎。我们确定了设计原则，使PPL能够在保持灵活性的同时扩展到高级研究应用，我们认为这些原则在Pyro PPL中完全实现。 Design Principle首先，适合开发最先进的AI研究模型的PPL应该具有表现力：它应该能够简明地描述具有数据依赖内部控制流的模型或潜在变量，其存在取决于其他潜在变量的值 ，或仅以封闭形式定义为非标准化联合分布的模型。 为了实现PPL，它必须是可扩展的：其近似推理算法必须能够无缝地处理AI研究中常见的大数据集和非共轭高维模型，并且应尽可能利用编译器加速。 针对研究模型的PPL应该是灵活的：除了可扩展性之外，许多高级模型还需要具有复杂的模型特定行为的推理算法。PPL应该使研究人员能够快速，轻松地实现此类行为，并应在模型，推理和运行时实现之间强制分离关注点。 最后，针对研究人员的PPL作为用户应力求最小化：为了最大限度地减少认知开销，它应该与现有语言和系统共享其大部分语法和语义，并与其他工具（如可视化库）配合使用。 从表2中可以清楚地看出，这四个原则经常是冲突的，其中一个是以牺牲其他原则为代价的。例如，过于灵活的设计可能非常难以有效和可扩展地实现，尤其是在同时将新语言与现有工具集成的同时。类似地，启用自定义推理算法的开发可能是困难的，而不限制模型表达性。在本节中，我们描述了我们在Pyro中做出的设计选择，以平衡所有四个目标。 Pyro嵌入在Python中，Pyro程序被编写为Python函数或callables，只有两个额外的语言原语（其行为被推理算法覆盖）：pyro.sample用于注释对具有内部随机性的函数的调用，以及pyro.param 用可以改变它们的推理算法学习参数。Pyro模型可能包含任意Python代码并以任意方式与其交互，包括通过pyro.sample的obs关键字参数表示非标准化模型。Pyro的语言原语可以与Python的所有控件构造一起使用，包括递归，循环和条件。因此，特定执行中随机变量的存在可能依赖于任何Python控件ow构造。 Pyro实现了几种通用概率推理算法，包括No U-turn采样器（Hoffman和Gelman（2014）），哈密顿蒙特卡罗的变体。然而，主推理算法是基于梯度的随机变分推理（SVI）（Kingma和Welling（2014）），其使用随机梯度下降来优化近似和真实后验分布之间的发散度量的蒙特卡洛估计。由于GPU加速的张量数学和通过PyTorch的反向模式自动分解，Pyro可以扩展到复杂的高维模型，并且由于在SVI中通过小批量数据计算的随机梯度估计，它可以扩展到大型数据集。 Pyro中的一些推理算法，例如SVI和重要性采样，可以使用任意Pyro程序（称为guide，来自webPPL的概念）作为近似后验或提议分布。给定模型的guide必须采用与模型相同的输入参数，并为模型中的每个无约束样本语句包含相应的样本语句，否则不受限制。然后，用户可以自由地表达关于后验分布的复杂假设，例如， 有条件的独立结构。与webPPL和Anglican不同，Pyro guide可能不依赖于模型内部的值。 最后，为了实现灵活性和关注点的分离，Pyro构建在Poutine上，这是一个效果处理程序库(Kammar et al)(2013)实现个人控制和簿记操作，用于检查和修改Pyro程序的行为，将推理算法实现与语言细节分离。 Project Openness and DevelopmentPyro的源代码可以在MIT许可下免费获得，由作者和开源贡献者社区开发，网址为https://github.com/uber/pyro，文档，示例和讨论论坛都在https上在线托管： //pyro.ai。在将代码合并到主代码库之前，通过持续集成服务自动运行全面的测试套件，以保持高水平的项目质量和可用性。 我们还发现，虽然PyTorch是张量运算和自动微分的宝贵基础，但它缺少一个高性能的概率分布库。因此，几位作者在PyTorch分发的上游做了大量的开源贡献。1受TensorFlow分发的启发，一个新的PyTorch核心库(Dillon et al)(2017年)。 4. Existing Systems 概率编程和近似推理是积极研究的领域，因此存在许多现有的概率编程语言和系统。我们简单地提到几个在Pyro开发中特别有用的东西，遗憾地省略（由于空间限制）许多系统，简单的直接比较更加困难。我们还强调，与传统的编程语言开发一样，我们的设计决策并非普遍适用于概率编程，也不适用于概率编程，而其他系统则有目的地使不同的tradof来实现不同的目标。 Stan（Carpenter等人（2017）是一种领域特定语言，用于描述一类受限概率的程序并在这些模型中执行高质量的自动推理。Church（Goodman et al。（2008））是Scheme的概率语言，是一种早期的通用概率编程语言，能够表示任何可计算的概率分布。Venture（Mansinghka et al。（2018））是一种通用语言，专注于表现力和灵活性以及自定义语法和虚拟机。Anglican（Tolpin等人（2016））和webPPL（Goodman和Stuhlmuller（2014））是Church的轻量级后继者，在通用编程语言Clojure和JavaScript中作为句法子集（Wingate等人（2011））嵌入。Edward（Tran et al。（2017））是一个基于静态TensorFlow图的PPL，它具有模型和推理的可组合表示。ProbTorch（Siddharth等人（2017））是一个建立在PyTorch上的PPL，专注于深度生成模型和开发变异推理的新目标。图灵（Ge et al。（2018））是一个嵌入Julia的PPL，具有可组合的MCMC算法 5. Experiments为了证明Pyro符合我们的设计目标，我们实施了几个最先进的模型。这里我们专注于变分自动编码器（VAE; Kingma和Welling（2014））和深马尔可夫模型（DMM; Krishnan等人）（2017）），非线性状态空间模型。 为了证明Pyro满足我们的设计目标，我们实现了几个最先进的模型。2这里我们重点介绍变分自动编码器(VAE；Kingma和Willing(2014)和DeepMarkovModel(DMM；Krishnan等人)。(2017)，这是一个非线性状态空间模型，已用于多种应用，包括音频生成和因果推理。VAE是深度概率建模的标准例子，而DMM有几个特点使其成为理想的比较点：它是一个高维、非共轭的模型，设计为适合于大型数据集；序列中潜在变量的数量取决于输入数据；它使用手工设计的后验近似。 Pyro派生的模型和推理程序几乎完全复制原始论文，除了我们使用蒙特卡罗估计而不是KL分歧项的精确解析表达式。我们使用MNIST数据集和2隐藏层MLP编码器和解码器网络，其中VAE的变化隐藏层大小#h和潜在代码大小#z以及digital music的相同数据集来训练DMM。 为了证明Pyro的抽象不会通过引入太多开销来降低其可扩展性，我们将VAE实现与惯用的PyTorch实现进行了比较.4在验证它们收敛到相同的测试ELBO之后，我们比较了计算一个时钟所需的wall clock时间。梯度更新，在单个NVIDIA GTX 1080Ti上平均超过10个时期的GPU加速小批量随机梯度变化推断（批量大小128）。图3显示Pyro和PyTorch版本之间的相对性能差距是适中的，更重要的是，它随着执行张量操作所花费的总时间的增加而缩小。 我们使用DMM来评估Pyro的灵活性和表现力。如图4所示，我们发现在5000个训练时期之后，我们能够快速简明地复制完整的DMM模型以及论文中报告的推理配置和定量结果。此外，由于Pyro的模块化设计，我们还能够通过自回归（（IAF）构建具有更具表现力的近似后验的DMM变体（Kingma等人（2016）），用几行代码改善结果，计算成本可忽略不计。","link":"/2019/04/09/Pyro-Deep-Universal-Probabilistic-Programming/"},{"title":"Intel概率计算报道","text":"1.英特尔实验室介绍 神经拟态计算简介 概率计算简介 2.概率计算使人工智能进入下一个时代 3.英特尔开始为人工智能进行概率计算的研发工作 4.英特尔实验室主任谈量子，概率和神经拟态计算 1.英特尔实验室介绍英特尔实验室与全球领先的研究机构合作并为其提供赞助。其中包括著名的大学科技中心，国家科学基金会和半导体研究公司。英特尔和这些机构的研究正在改变机器的思考，学习和适应方式。 神经拟态计算简介随着人工智能工作变得更加多样化和复杂化，而当今主流计算架构将达到极限。英特尔的研究人员认为，神经拟态计算提供了前进的方向，并且正在推进旨在提供百万兆级运算的研究，这将提高传统计算能力并为新的计算应用开辟可能性。2017年9月，英特尔实验室推出了第一款具有自学能力的神经拟态研究芯片“Loihi。”英特尔与领先的大学和研究合作伙伴合作，对Loihi芯片进行测试，该芯片具有模拟大脑基本功能的数字电路，使机器学习更快，更高效，同时降低计算功耗需求，帮助处理复杂的数据集和问题。 由英特尔实验室构建的测试板展示了英特尔Loihi神经形态研究芯片的功能。（来自：英特尔公司） Intel给出的神经拟态视频：1.神经拟态，智能和计算的未来 2.神经拟态，旨在模拟人类大脑 3.Intel实验室中的Loihi 概率计算简介计算机的构建是为了帮助人们完成精确的生产任务，如果使计算机有效地处理大规模概率，可以将当前系统和应用程序从高级计算辅助工具，转变为智能合作伙伴以进行理解和决策。2018年5月，英特尔宣布增加对概率计算研究的投资，并呼吁学术界和初创社区与Intel合作，将实验室中的概率计算推进到这些载体：基准应用，对抗性攻击缓解，概率框架，以及软件和硬件优化。在接下来的几年里，英特尔的领导者预计该公司在概率计算方面的研究将带来可靠性和安全性方面的重大改进， Mayberry：Computing In the Area of AI 原网站链接：https://newsroom.intel.com/press-kits/intel-labs 2.概率计算使人工智能进入下一个时代新闻时间：2018年5月 Intel加速在概率计算方面的研究并诚邀合作伙伴探讨下一代人工智能 By Dr. Michael Mayberry 人工智能（AI）的潜在影响从未如此强大 - 但只有AI能够提供更智能，更直观的答案，我们才能取得成功。 今天人工智能的一个主要障碍是，提供给计算机的自然数据在很大程度上是非结构化的并且“嘈杂”。 人类很容易对自然数据进行处理。例如：如果你在住宅街道上开车并在你面前看到一个球滚动，你会停下来，假设有一个小孩子在球的后面不远处。今天的计算机不这样做。它们旨在帮助人们完成精确的生产任务。使计算机有效地处理大规模概率，是我们将当前系统和应用程序，从高级计算辅助工具转换为智能合作伙伴，以进行理解和决策的能力的核心。 这就是为什么概率计算是人工智能的一个关键组成部分，也是应对这些挑战的关键。概率计算将允许未来的系统理解和计算自然数据中固有的不确定性，这将使我们能够构建能够理解，预测和决策的计算机。 今天在英特尔，我们正在观察依赖于对嘈杂的自然数据进行分析的应用的空前增长 - 不同甚至相互冲突的信息。这些应用旨在帮助人们提供更高水平的智能和对其运行环境的认识。切入这个嘈杂的雷区对我们将计算机转变为智能合作伙伴的能力至关重要，这些合作伙伴可以理解并信息，并以人类般的忠诚度般，采取行动。 对概率计算的研究并不是一个新的研究领域，但高性能计算和深度学习算法的改进可能会使概率计算进入一个新时代。在接下来的几年中，我们预计概率计算的研究将导致AI系统的可靠性，安全性，可维护性和性能的显着提高，包括专为概率计算而设计的硬件。这些进步对于将应用程序部署到现实世界至关重要 - 从智能家居到智能城市。 为了加快我们在概率计算方面的工作，英特尔正在增加对概率计算的研究投资，我们正在与合作伙伴共同努力实现这一目标。 建立英特尔概率计算战略研究联盟 实现概率计算的全部潜力涉及计算技术中多个领域。今天，英特尔强调了其对新兴计算架构的整合，协作实施以及健全的生态系统支持战略的承诺，向学术界和初创社区发出呼吁，通过与Intel合作，将概率计算从实验室推进到现实：基准应用程序，对抗性攻击缓解，概率框架以及软件和硬件优化。 关注下一步是什么 我们非常渴望看到推进概率计算的提议，并继续这项研究，有可能提高人工智能可以帮助我们实现的目标。学术提案预计将在5月25日之前提交，其中我们将选择最好的研究团队。 我们通过对神经形态计算的研究开始了这一旅程 - 专注于我们对人类大脑及其相关计算过程的理解。3月1日宣布的神经拟态研究界的开始也正在进行中，我们计划继续扩大我们在云上的Loihi，以便研究人员能够使用先进硬件。我们看到2019年在单一系统上达到1000亿个突触。 此外，作为与普林斯顿大学合作的一部分，英特尔已经致力于解码大脑并推进神经科学的下一阶段。我们期待通过我们的概率计算工作进一步了解人类理解问题和决策的流程。 原网站链接：概率计算使得人工智能进入下一个时代 3.英特尔开始为人工智能进行概率计算的研发工作时间：2018年5月10日 英特尔今天宣布，它正在组建一个战略研究联盟，将人工智能提升到新的水平。自治系统没有足够好的方法来应对现实世界的不确定性，而且它们没有足够好的方法来理解传感器的不确定性如何影响他们需要做出的决策。根据英特尔首席技术官Mayberry的说法，答案是“概率计算”，他说这可能是人工智能的下一波浪潮。 IEEE Spectrum:这项新研究的主旨是什么？ Mayberry:我们正试图弄清楚下一波人工智能是什么。AI的原始浪潮基于逻辑，它基于写下规则; 它最接近你所谓的经典推理。当前的AI浪潮围绕sensing and perception - 使用卷积神经网络扫描图像并查看是否存在感兴趣的东西。这并不人类认知世界的方式。 假如你听到汽车警报声。您会自动考虑与拥有的数据一致的不同场景，并且还会意识到没有的数据。你会推断一个概率。也许概率是在确定警笛是来自你前面还是后面。或者是否会让你迟到会议。您自动执行机器遇到问题的事情。我们在现实生活中始终遇到这些情况，因为目前的情况始终存在不确定性。 目前人工智能和深度学习系统被认为是脆弱的。意思是他们对答案过于自信。他们会毫不犹豫地说，它认为图片中有某些内容可以识别它。但在许多情况下，概率是不正确的; 信心并不像[AI]认为的那么高。 因此，我们想要在一般研究重点中做的是弄清楚如何在我们的推理系统和我们的传感系统中建立概率。而且真的有两个挑战。一个是你如何用概率进行计算，另一个是如何用概率存储记忆或场景。 所以我们已经做了一定数量的内部工作和学术界，我们已经决定在这里有足够的东西我们将开始研究社区。目标是让人们分享他们对它的了解，进行协作，编写软件时如何表示概率，以及如何构建计算机硬件。我们认为这将是……第三波人工智能的一部分。 IEEE Spectrum:概率计算用于描述过去与AI无关的许多事情，例如随机计算(stochastic computing)和容错计算(error-tolerant computing)。它到底是什么样的？ Mayberry:我们使用[概率计算]与以前略有不同。例如，随机计算即使有错误也能获得足够好的答案。模糊逻辑实际上更接近我们在这里讨论的概念，在处理信息时，你故意跟踪不确定性。还有统计计算，这实际上更像是一种软件方法，你可以通过构建树来跟踪概率。所以，这些不一定是新概念。但我们打算以不同于过去的方式应用它们. IEEE Spectrum:这会涉及新型设备吗？ Mayberry:我们最初会通过查看算法来接近它。我们对英特尔的偏见是构建硬件，但如果我们不真正了解使用模型将如何演变或算法将如何演变，那么我们就有可能过早地承诺使用这条路径。因此，我们最初将围绕算法和软件框架进行研究。你必须尽早考虑安全问题。这些是我们将要接近的事情。 （Mayberry推荐了了Vikesh Mansighka 的工作， 他是麻省理工学院Probablistic Computing Project的负责人。） IEEE Spectrum:这如何适应英特尔现有的AI工作？ Mayberry:这是一个包含我们现有工作的大型系统的一部分…. 您不希望您的逻辑系统假设您的传感是100％准确的，但您不希望传感器必然也有关于置信度的错误信息。因此，您必须围绕这两个组件如何相互通信并跟踪这类信息来构建一个系统。因此传感系统可能会报告“我的亮度发生了变化” - 因此我的答案比以前更有信心。 跟踪这类信息是系统设计的一部分。从软件框架的角度来看，我们并不确切知道如何实现这一点。 IEEE Spectrum:有哪些潜在的应用？Mayberry:当然，我们的目标之一是拥有更好的自动机器，无论是汽车还是家用机器人，还是类似的东西。我们认为[概率计算]是使系统更加健壮的重要部分。受到高度约束的系统不太可能需要这种能力。您将系统置于一个开放的环境中的时间越多，有更多的东西需要改变，您就越有可能需要补充我们今天使用的系统。我们当然希望这将在几年内变成产品，但这是前路线图。所以我们现在不承诺任何事情。原网站链接：英特尔开始为人工智能进行概率计算的研发工作# 4.英特尔实验室主任谈量子，概率和神经拟态计算4.英特尔实验室主任谈量子，概率和神经拟态计算 报道时间：2019年3月1日 去年年底接管英特尔实验室的Rich Uhlig讨论了英特尔对未来计算的愿景 英特尔通过不断寻找使CPU更快，更高效的方法，为自己做得非常好。但随着摩尔定律的终结，英特尔一直在探索利用创新架构扩展计算的方法。 量子计算是其中一项举措，英特尔实验室一直在测试自己的49-qubit处理器。除此之外，英特尔实验室正在探索神经形态计算（模拟结构，并希望通过人工神经网络模拟人脑的一些功能）以及概率计算，旨在帮助满足量化人工智能不确定性的应用需求。 Rich Uhlig自2018年12月以来一直担任英特尔实验室的主管，自1996年以来一直在英特尔工作（最近担任英特尔实验室的系统和软件研究总监），所以他似乎很有资格担任该职务。我们与Uhlig讨论了量子，神经形态和概率计算，这些系统将如何帮助我们管理AI，以及这些技术将使这些技术成为可能的事情至少应该引起我们的关注。 IEEE Spectrum:根据英特尔量子计算的时间表，我们目前处于“系统阶段”。这意味着什么，我们将如何过渡到商业阶段？ Rich Uhlig：在英特尔，我们专注于开发商业上可行的量子计算机，这需要比量子比特本身更多。我们已经成功制造了一个49比特的超导芯片，这使我们能够开始将量子处理单元（QPU）集成到一个系统中，在这个系统中我们可以构建所需的所有元件，使量子位同时协同工作以改善效率和可扩展性。我们正在努力创建一个可行的量子系统，从50个量子比特扩展到商业系统所需的数百万个量子比特。 IEEE Spectrum:我们希望通过神经形态计算来模仿它的大脑有什么好处？ Rich Uhlig：大脑的魅力在于它能够实时处理高度复杂的信息，并且能量很少。我们的目标不一定是模仿大脑，而是要了解为大脑提供如此令人印象深刻和高效的功能的原则，然后将这些原则应用于我们可以构建的芯片。许多与细粒度并行性，动态计算，信息时间编码，事件驱动操作等相关的原则直接激发了我们认为将导致两者的突破性增益的新特性，体系结构和算法。计算系统的能力和效率。 IEEE Spectrum:为什么概率计算足以使英特尔的量子和神经拟态并列？ Rich Uhlig：概率计算使我们能够处理我们周围的自然数据的不确定性，并通过理解数据和模型的不确定性来预测世界上的事件。只有当我们知道如何用概率分布模拟我们周围的世界时，才能预测场景中接下来会发生什么，以及我们的行动的影响。通过使用概率方法增强深度学习所提供的不确定性测量打开了理解人工智能系统为何做出决策的大门，这将有助于解决人工智能系统中的偏差等问题。 我们对概率计算的研究实际上是关于建立一种评估下一波人工智能性能的新方法 - 一种需要对“噪声”数据进行实时评估的方法。第一代AI系统专注于逻辑：预编程规则。第二波人工智能旨在提高感知和感知信息的能力，利用神经网络随着时间的推移进行学习。但是，这些解决方案都不能做到人类在我们在真实世界自然而然地做的事情。无法根据您手头的数据思考多种潜在的情景，同时意识到您没有的潜在数据。 为什么这个概念如此重要的一个例子是，如果你正在开车并且看到一个足球滚到街上，你的直接和自然的反应是停车，因为我们可以假设一个孩子在球后跑，并且离的不远。 根据自然数据的经验和人类行为的假设，驾驶员决定停车。但是，传统的计算机很可能无法实时得出相同的结论，因为今天的系统没有被编程为有效地挖掘噪声数据并根据环境意识做出决策。但是，对于像自动驾驶这样的应用程序，可能需要一个概率系统来调用一个可以快速评估情况并立即采取行动。 IEEE Spectrum:是否需要用于神经形态和概率计算的新型设备？这些需要具备哪些属性？ Rich Uhlig：目前，我们相信受这些新计算范例启发的创新可以为使用当今工艺技术制造的芯片提供有意义的收益。但是，在未来几年，并且要继续发展，我们将需要设备级的进步。在神经形态计算的情况下，将需要更密集的存储器技术和具有非易失性塑性动力学的新材料。在概率计算的情况下，它将扩展AI解决方案以包括能够以概率分布进行计算的新颖且有效的实现。对于神经形态和概率计算，最终的效率增益可能需要利用物理噪声源的设备和电路直接体现随机动态。 IEEE Spectrum:新设备是否会影响英特尔所关注的计算类型，或者是为设备设计新的计算方法？ Rich Uhlig：它是两个方向的相互作用。设备技术和摩尔定律的发展使新架构成为可能，新的架构理念正在推动未来设备技术的需求。但是，对两者的真正驱动要求是我们在世界上收集的指数数量的新数据。这些数据的收集，存储和分析将需要新的计算模型，并有可能为我们所有人创造难以置信的新体验。 IEEE Spectrum:AI的未来是否会刺激神经网络？ Rich Uhlig：脉冲神经网络（SNN）是当今用于深度学习的人工神经网络的自然继承者。通过将时间动态直接集成到其操作中，SNN非常适合于处理真实的感觉数据，例如声音或视频，尤其是在需要快速响应和适应时。从算法的角度来看，脉冲神经元为构建神经网络提供了一种原则性方法，可以及时处理事件，例如支持一次性学习或做出决策。从实现角度来看，脉冲允许神经形态体系结构利用这些算法的高度稀疏活动来提高能效。这些优势为边缘设备提供了巨大价值，例如在制造车间，自动驾驶车辆， IEEE Spectrum:您认为大多数人将从中受益的量子和神经形态计算的第一个实际应用是什么？？ Rich Uhlig：量子计算将解决传统计算机需要数月或数年才能解决的问题，或者今天完全难以解决的问题。这可能包括药物开发，财务建模和气候预测等问题。对于神经形态芯片，第一个应用可能是那些需要实时定制预训练功能的应用，这取决于特定设备的独特环境。例如，神经形态芯片可以使语音识别系统能够自主地适应以识别具有强烈重音的用户，或者在动态环境中控制机器人手臂。 IEEE Spectrum:有没有人担心使用这些计算技术会让我们更难理解为什么未来的计算系统会做出他们做出的决定？决策在何种程度上可以解释，我们如何改进？ Rich Uhlig：这是一个有效的关注和活跃的研究领域，你可以称之为“可解释的人工智能”。例如，我们绝不会建议推出一种可能危及人类安全的设备，如果它的工程师无法清楚说明它是如何或为什么会出现在它做了。我们认为概率计算可能提供一些优势，因为它提供了一个框架，用于理解答案中的潜在错误，这可能对更高级别的策略有用，这些策略决定系统最终如何参与物理世界。","link":"/2019/04/01/Intel概率计算报道/"},{"title":"概率编程之PyMC3","text":"《Probabilistic programming in Python using PyMC3》 Abstract Introduction 安装 示例：线性回归模型 generate data Model specification model fitting Maximum a posteriori methods 采样的方法 基于梯度的采样方法 Posterior analysis CASE STUDY 1: STOCHASTIC VOLATILITY model data model implementation Fitting Case study 2:Coal mining disasters PYMC3 FEATURES Arbitrary deterministic variables Arbitrary distributions Generalized linear models Backends DISCUSSION Abstract概率编程允许用户定义概率模型进行自动贝叶斯推理。马尔可夫链蒙特卡罗(MCMC)抽样的最新进展允许对越来越复杂的模型进行推理。这类MCMC，称为哈密顿蒙特卡罗，需要梯度信息，而这往往是不容易获得的。PyMC3是用Python编写的一个新的开源概率编程框架，它使用Theano通过自动微分来计算梯度，并在运行时将概率程序编译到C中以提高速度。与其他概率编程语言相反，PyMC3允许直接在Python代码中进行模型定义。由于缺乏特定于领域的语言，因此具有很大的灵活性和与模型的直接交互。本文是对此软件包的教程式介绍。 Introduction概率编程(PP)允许对贝叶斯统计模型进行灵活的描述和拟合。 PyMC3是一种新的开源PP框架，它具有直观、可读、功能强大的语法，与统计学家用来描述模型的自然语法非常接近。 它具有下一代马尔可夫链蒙特卡罗(MCMC)采样算法，如No-U-Turn(NUTS)(Hoffman&amp;Gelman，2014年)，这 是哈密顿蒙特卡罗(HMC)的自校正变体(Duane等人，1987年)。 这类采样器很好地工作在高维和复杂的后验分布上，并且允许许多复杂的模型在没有关于拟合算法的专门知识的情况下可以被拟合。 HMC和NUTS利用了来自似然的梯度信息，与传统的采样方法相比，具有更快的收敛速度，特别是对于较大的模型。 NUTS也有几种自校正策略来自适应地设置哈密顿蒙特卡罗的可调参数，这意味着不需要关于算法如何工作的专门知识。 PyMC3、STAN(STAN开发团队，2015)和LaplacesDemon R包是目前唯一提供HMC的PP包。 在过去的2-3年中，出现了许多概率编程语言和系统。 最早得到广泛使用的语言之一是Bug语言(Spiegelhalter等人，1995年)，它允许简单地指定贝叶斯模型，并通过马尔可夫链蒙特卡罗方法对其进行拟合。 新的、更具表现力的语言允许创建因子图和概率图形模型。 这些系统中的每一个都是在现有低级语言之上构建的特定于领域的语言；值得注意的例子包括Church(Goodman等人，2012年)(源自Plan)、Anglican(Wood，Van de Meent&amp;Mansinghka，2014年)(与Clojure集成并使用Java虚拟机进行编译)、Venture(Mansinghka，Selsam&amp;Perov，2014年)(构建于C+)、Infer.NET(Minka等人，2010)(基于.NET框架)，Figaro(Pfeffer，2014)(嵌入Scala)，WebPPL。 (Goodman&amp;Stuhlmüller，2014年)(嵌入JavaScript)、Picture(Kulkarni等人，2015年)(嵌入Julia)和Quicksand线(Ritchie，2014年)(嵌入Lua)。 Python中的概率编程(PythonSoftwareFoundation，2010)提供了许多优势，包括多平台兼容性、表达能力强但清晰易读的语法、与其他科学库的轻松集成，以及通过C、C+、Fortran或Cython实现的可扩展性(Behnel等人，2011)。 这些特性使编写和使用自定义统计分布、采样器和转换函数变得非常简单，正如贝叶斯分析所要求的那样。 虽然PyMC3的大多数面向用户的特性都是用纯Python编写的，但它利用Theano(Bergstra等人，2010；Bastian等人，2012)透明地将模型代码转换为C并将其编译为机器码，从而提高了性能。 Theano是一个库，它允许使用称为Tensor的广义矢量数据结构定义表达式，这些数据结构与流行的NumPy(Van der Walt，Colbert，Varoquaux，2011)ndarray数据结构紧密集成，并且类似地允许广播和高级索引，就像NumPy数组一样。 Theano还自动优化可能的计算图形的速度，并提供简单的GPU集成。 在这里，我们介绍了一个使用PyMC3解决一般贝叶斯统计推断和预测问题的引物。 我们将首先描述PyMC3的基本用法，包括安装、数据创建、模型定义、模型拟合和后验分析。 然后，我们将使用两个案例研究来说明如何定义和适应更复杂的模型。 最后，我们将展示如何扩展PyMC3，并讨论更高级的特性，如广义线性模型(GeneralizedLinearModels，GLM)子包、自定义分布、自定义转换和备用存储备份。 安装运行PyMC3需要一个工作的Python解释器(PythonSoftwareFoundation，2010)，版本2.7(或更新的版本)或3.4(或更新的版本)；我们建议新用户安装版本3.4。通过ContinuumIO下载并安装免费的AnacondaPythonDistributions，可以最容易地获得适用于MacOSX、Linux和Windows的完整Python安装。 PyMC3可以使用“pip”安装： 1pip install git+https://github.com/pymc-devs/pymc3 PyMC3依赖于几个第三方Python软件包，这些软件包将在通过PIP安装时自动安装。四个必需的依赖项是：Theano、NumPy、SciPy和Matplotlib。为了充分利用PyMC3，还应该安装可选的依赖 项Pandas和Patsy。 1pip install patsy pandas PyMC3的源代码托管在GitHub的PyMC3上，并在自由的ApacheLicense2.0下分发。在GitHub站点上，用户还可以报告bug和其他问题，并为项目贡献代码，这是我们积极鼓励的。全面的文档可在pymc3文档上找到。 示例：线性回归模型为了介绍模型的定义、拟合和后验分析，我们首先考虑一个参数具有正态先验的简单贝叶斯线性回归模型。我们感兴趣的是作为正态分布的观测值来预测结果Y，其期望值是两个预测变量X1和X2的线性函数。\\begin{equation}\\begin{split}Y \\sim N(\\mu, \\sigma^2)\\newline \\mu= \\alpha+\\beta_{1}X_1+\\beta_2X_2\\end{split}\\end{equation} 这里是截距，是协变量$\\x_i$的系数，而代表观测或测量误差。 我们将对两个回归系数应用方差为10的零均值正态先验，这两个回归系数对应于关于真实参数值的弱信息。 由于方差必须是正的，我们还将选择一个半正态分布(正态分布在零下界)作为先验。 generate data我们可以使用NumPy的随机模块来模拟这个模型中的一些数据，然后使用PyMC3来尝试恢复相应的参数。下面的代码实现了这个模拟，结果数据如图所示。123456789101112131415import numpy as npimport matplotlib.pyplot as plt# Intialize random number generatornp.random.seed(123)# True parameter valuesalpha, sigma = 1, 1beta = [1, 2.5]# Size of datasetsize = 100# Predictor variableX1 = np.linspace(0, 1, size)X2 = np.linspace(0,.2, size)# Simulate outcome variableY = alpha + beta[0]*X1 + beta[1]*X2 + np.random.randn(size)*sigma Model specification在PyMC3中指定此模型很简单，因为语法类似于统计表示法。在大多数情况下，每行Python代码对应于上面模型符号中的一行。首先，我们从PyMC3导入我们需要的组件。123456789101112from pymc3 import Model, Normal, HalfNormalbasic_model = Model()with basic_model:# Priors for unknown model parameters alpha = Normal('alpha', mu=0, sd=10) beta = Normal('beta', mu=0, sd=10, shape=2) sigma = HalfNormal('sigma', sd=1) # Expected value of outcome mu = alpha + beta[0]*X1 + beta[1]*X2 # Likelihood (sampling distribution) of observations Y_obs = Normal('Y_Obs', mu=mu, sd=sigma, observed=Y) 第一行basic_model = Model() 创建一个新的Model对象，它是模型随机变量的容器。在实例化模型之后，模型组件的后续规范在with语句中执行： with basic_model: 这将创建一个上下文管理器，我们的basic_model作为上下文，包括所有语句，直到缩进块结束。这意味着在with语句下面的缩进代码块中引入的所有PyMC3对象都将添加到幕后的模型中。如果没有这个上下文管理器习惯用法，我们将被迫在创建时将每个变量与basic_model手动关联，这将导致更详细的代码。如果您尝试在模型上下文管理器之外创建新的随机变量，则会引发错误，因为没有明显的模型可以添加变量。 上下文管理器中的前三个语句创建随机随机变量，其中回归系数的正态先验分布，以及观察标准偏差的半正态分布 这些是随机的，因为它们的值部分地由其父项在随机变量的依赖图中确定，其对于先验是简单常数，并且根据指定的概率分布是部分随机的。 Normal构造函数创建一个正常的随机变量以用作先验。随机变量构造函数的第一个参数始终是变量的名称，它应该几乎总是与分配给的Python变量的名称匹配，因为它可以用于在汇总输出时从模型中检索变量。随机对象的剩余必需参数是参数，在正态分布的情况下是平均μ和标准差sd，我们为模型分配超参数值。通常，分布的参数是确定随机变量的位置，形状或比例的值，具体取决于分布的参数化。最常用的分布，如Beta，Exponential，Categorical，Gamma，Binomial等，可作为PyMC3对象使用，不需要由用户手动编码。 beta变量有一个附加的Shape参数，将其表示为大小为2的向量值参数。Shape参数可用于所有分布，并指定随机变量的长度或形状；如果未指定，则默认为1的值(即标量)。它可以是指定数组的整数，也可以是指定多维数组的元组。例如，Shape=(5，7)创建以5×7矩阵为其值的随机变量。 有关分布，采样方法和其他PyMC3功能的详细说明可通过帮助功能获得。 定义了先验后，下一个语句创建结果的预期值mu，指定线性关系： 1mu = alpha + beta[0]*X1 + beta[1]*X2 这会创建一个确定性的随机变量，这意味着它的值完全由其父项的值决定。也就是说，变量没有超出父母价值所固有的不确定性。这里，mu只是截距α与β系数和预测变量的两个乘积之和，无论它们的当前值是什么。 PyMC3随机变量和数据可以任意添加，减去，分割或相乘，以及索引（提取值的子集）以创建新的随机变量。还提供了许多常见的数学函数，如sum，sin，exp和线性代数函数，如dot（用于内积）和inv（用于逆）。将运算符和函数应用于PyMC3对象会产生巨大的模型表达能力。 模型的最后一行定义了Y_obs，即响应数据的采样分布。 1Y_obs = Normal(’Y_obs’, mu=mu, sd=sigma, observed=Y) 这是随机变量的一种特殊情况，我们称之为观测随机变量，它是模型的数据似然(likehood)。它与标准随机变量相同，只是其观察到的参数(将数据传递给变量)表明该变量的值已被观察到，并且不应通过应用于模型的任何拟合算法进行更改。数据可以numpy.ndarray或Pandas.DataFrame对象的形式传递。 注意，与先前的分布不同，Y_obs的正态分布的参数不是固定值，而是确定性对象mu和随机sigma。这在可能性和这两个变量之间创建了父子关系，作为模型的有向无环图的一部分。 model fitting完全指定了我们的模型后，下一步是获得模型中未知变量的后验估计。理想情况下，我们可以通过分析得出后验估计值，但对于大多数非平凡模型，这是不可行的。我们将考虑两种方法，其适当性取决于模型的结构和分析的目标：使用优化方法找出最大后验（MAP）点，并使用MCMC采样方法基于从后验分布中抽取的样本计算summaries。 Maximum a posteriori methods模型的最大后验（MAP）估计是后验分布的模式，并且通常使用数值优化方法找到。这通常是快速且容易的，但是仅给出参数的点估计，并且如果模式不代表分布则可能误导。PyMC3使用find_MAP函数提供此功能。 下面我们找到原始模型的MAP。MAP作为参数点返回，该参数点始终由变量名称的Python字典表示为参数值的NumPy数组。 123456from pymc3 import find_MAPmap_estimate = find_MAP(model=basic_model)print(map_estimate){‘alpha’: array(1.0136638069892534),‘beta’: array([ 1.46791629, 0.29358326]),‘sigma_log’: array(0.11928770010017063)} 默认情况下，find_MAP使用Broyden-Fletcher-Goldfarb-Shanno（BFGS）优化算法来查找log-posterior的最大值，但也允许scipy.optimize模块中选择其他优化算法。例如，下面我们使用Powell的方法来查找MAP。 12345map_estimate = find_MAP(model=basic_model, fmin=optimize.fmin_powell)print(map_estimate){’alpha’: array(1.0175522109423465),’beta’: array([ 1.51426782, 0.03520891]),’sigma_log’: array(0.11815106849951475)} 重要的是要注意MAP估计并不总是合理的，特别是如果模式处于极端。这可能是一个微妙的问题; 由于样本集非常小，所以可以具有极高密度但总概率低的区域。这通常发生在具有随机效应的方差参数的分层模型中。如果单个组均值相同，则组均值的比例参数几乎为零，则后验将具有接近无限密度，即使这样的小比例参数的概率很小，因为组均值必须非常接近一起。 此外，用于查找MAP估计的大多数技术仅发现本地优化（这通常足够好），并且因此如果不同模式有意义地不同，则可能对于多模式后验很难。 采样的方法尽管找到MAP是获得良好行为模型的参数估计的快速且简单的方法，但是它是有限的，因为没有与MAP估计产生的参数值的不确定性性的估计。相反，基于模拟的方法（例如MCMC）可用于获得马尔可夫值链，其在给定满足某些条件的情况下与来自后验分布的样本无法区分。 为了在PyMC3中进行MCMC采样以生成后验样本，我们指定了一个步骤方法对象，该对象对应于特定MCMC算法的单次迭代，例如Metropolis，Slice采样或No-U-Turn采样器（NUTS）。PyMC3的step_methods子模块包含以下采样器：NUTS，Metropolis，Slice，HamiltonianMC和BinaryMetropolis。 基于梯度的采样方法PyMC3实现了几种标准采样算法，例如自适应MetropolisHastings和自适应切片采样，但PyMC3最有能力的步骤方法是No-U-Turn采样器。NUTS对于从具有许多连续参数的模型中采样特别有用，这种情况下较旧的MCMC算法工作得非常慢。它利用有关较高概率区域的信息，基于对数后验密度的梯度。与传统的采样方法相比，这有助于它在大问题上实现快速收敛。PyMC3依靠Theano通过自动区分后密度来分析计算模型梯度。NUTS还有几种自适应策略，用于自适应地设置Hamiltonian Monte Carlo的可调参数。对于不可区分的随机变量（即离散变量），不能使用NUTS，但它仍可用于包含不可微变量的模型中的可微变量。 NUTS需要一个缩放矩阵参数，类似于Metropolis-Hastings中跳转建议分布的方差参数，尽管NUTS使用它有些不同。矩阵给出了后验分布的近似形状，因此NUTS不会使跳跃在某些方向上过大而在其他方向上过小。将此缩放参数设置为合理的值以便于有效采样非常重要。对于具有许多未观察到的随机随机变量或具有高度非正态后验分布的模型的模型尤其如此。较差的缩放参数会显着减慢NUTS，有时几乎完全停止它。采样的合理起点对于有效采样也很重要，但并不常见。 幸运的是，NUTS通常可以对缩放参数做出好的猜测。如果将参数空间中的一个点（作为变量名的字典到参数值，与find_MAP返回的格式相同）传递给NUTS，它将查看对数后验密度的局部曲率（Hessian矩阵的对角线） ）在那一点上猜测一个好的缩放矢量的值，这可以产生一个好的值。MAP估计通常是用于启动采样的好点。也可以将自己的矢量或缩放矩阵提供给NUTS。另外，find_hessian或find_hessian_diag函数可用于修改特定点处的Hessian以用作缩放矩阵或向量。 在这里，我们将使用NUTS使用MAP作为起始点和缩放点从后验采样2000个绘制。在模型的上下文中执行采样。 12345678from pymc3 import NUTS, samplewith basic_model: # obtain starting values via MAP start = find_MAP(fmin=optimize.fmin_powell) # instantiate sampler step = NUTS(scaling=start) # draw 2000 posterior samples trace = sample(2000, step, start=start) 样本函数运行传递给它的步骤方法达到给定的迭代次数，并按照收集的顺序返回包含所收集样本的Trace对象。跟踪对象的查询方式与包含从变量名到numpy.arrays的映射的dict类似。数组的第一个维度是采样索引，后面的维度与变量的形状匹配。我们可以如下提取alpha变量的最后5个值 12trace[’alpha’][-5:]array([ 0.98134501, 1.04901676, 1.03638451, 0.88261935, 0.95910723]) Posterior analysisPyMC3提供绘图和汇总功能，用于检查采样输出。可以使用traceplot创建一个简单的后验图，其输出如图2所示。 12from pymc3 import traceplottraceplot(trace) 左列包括每个随机随机变量的边缘后验的平滑直方图（使用核密度估计），而右列包含按顺序绘制的马尔可夫链的样本。作为矢量值的β变量产生两个直方图和两个样本迹线，对应于两个预测器系数。 对于表格分析，分析函数提供基于文本的常见后验统计信息输出： CASE STUDY 1: STOCHASTIC VOLATILITY我们提出了随机波动率，时变股市波动性的案例研究，以说明PyMC3解决更现实问题的能力。市场回报的分布非常不正常，这使得对波动率的抽样变得更加困难。此示例具有400多个参数，因此使用较旧的采样算法（如Metropolis-Hastings）效率较低，会生成具有较低有效样本量的高度自相关样本。相反，我们使用NUTS，效率显着提高。 model资产价格具有随时间变化的波动性（日常回报的差异）。在某些时期，回报变化很大，而在其他时期，回报非常稳定。随机波动率模型用潜在波动率变量解决这个问题，允许随时间变化。以下模型类似于NUTS论文中描述的模型（Hoffman＆Gelman，2014，第21页）。 这里，y是响应变量，每日返回系列，我们用具有未知自由度参数的Student-T分布建模，以及由潜在过程s确定的标度参数。单个si是潜在对数波动率过程中的每日对数波动率。 这里，y是响应变量，每日返回系列，我们用具有未知自由度参数的Student-T分布建模，以及由隐过程s确定的标度参数。单个si是潜在对数波动率过程中的每日对数波动率。 data我们的数据包括2008年金融危机期间标准S&amp;P 500指数的每日回报。有关每日回报数据的图表，请参见图3。可以看出，2008年金融危机期间股市波动性显着增加。 12import pandas as pdreturns = pd.read_csv(’data/SP500.csv’, index_col=0, parse_dates=True) model implementation与线性回归示例一样，在PyMC3中实现模型反映了其统计规范。该模型采用了几种新的分布：指数分布为？和？的先验，返回分布的Student-T（StudentT）分布，以及潜在波动率的先验的GaussianRandomWalk。 虽然(与PyMC2中的模型规范不同)我们通常不会在模型规范阶段为变量提供起始点，但是可以使用testval参数为任何发行版(在Theano中称为“测试值”)提供初始值。这将覆盖分布的默认测试值(通常是分布的平均值、中值或模式)，如果某些值无效，并且我们希望确保选择有效的值，这通常是有用的。默认情况下，分布的测试值也被用作采样和优化的起点，尽管这很容易被忽略。 潜在波动率s的矢量由GaussianRandomWalk对象给出先验分布。顾名思义，GaussianRandomWalk是一个向量值分布，其中向量的值形成长度为n的随机正态步行，由shape参数指定。随机游走sigma的创新规模是根据正态分布式创新的精确度来规定的，可以是标量或向量。 12345678from pymc3 import Exponential, StudentT, exp, Deterministicfrom pymc3.distributions.timeseries import GaussianRandomWalkwith Model() as sp500_model: nu = Exponential(’nu’, 1./10, testval=5.) sigma = Exponential(’sigma’, 1./.02, testval=.1) s = GaussianRandomWalk(’s’, sigma**-2, shape=len(returns)) volatility_process = Deterministic(’volatility_process’, exp(-2*s)) r = StudentT(’r’, nu, lam=1/volatility_process, observed=returns[’S&amp;P500’]) 请注意，我们通过exp（-2 * s）将对数波动率过程转换为波动率过程。这里，exp是一个Theano函数，而不是NumPy中的相应函数; Theano提供了NumPy所做的大部分数学函数。 Fitting在我们从后验中抽取样本之前，谨慎的做法是找到一个合适的起始值，我们指的是一个相对较高概率的点。对于该模型，所有变量的完全最大后验（MAP）点是简并的并且具有无限密度。但是，如果我们修复log_sigma和nu它不再退化，那么我们发现MAP只关注波动率过程，使log_sigma和nu保持其默认值（请记住我们为sigma设置testval = .1）。我们使用由scipy.optimize包提供的限制内存BFGS（L-BFGS）优化器，因为它对于高维函数更有效; 该模型包括400个随机随机变量（主要来自s）。 作为抽样策略，我们执行短暂的初始运行以定位高概率的体积，然后在新的起始点再次开始以获得可用于推断的样本。trace [-1]给出了采样跟踪的最后一点。NUTS将根据新点重新计算缩放参数，在这种情况下，由于更好的缩放，它会导致更快的采样。 12345678import scipywith sp500_model: start = find_MAP(vars=[s], fmin=scipy.optimize.fmin_l_bfgs_b) step = NUTS(scaling=start) trace = sample(100, step, progressbar=False) # Start next run at the last sampled position. step = NUTS(scaling=trace[-1], gamma=.25) trace = sample(2000, step, start=trace[-1], progressbar=False, njobs=2) 请注意，对sample的调用包括一个可选的njobs = 2参数，它允许对4个链进行并行采样（假设我们有2个处理器可用）。我们可以通过查看nu和sigma的traceplot来检查我们的样本; 每条平行链将绘制在同一组轴内（图4）。 1traceplot(trace, [nu, sigma]); 最后，我们通过在同一图表上绘制我们的许多采样波动率路径来绘制波动率路径的分布（图5）。每个都呈现为部分透明（通过Matplotlib的绘图函数中的alpha参数），因此许多路径重叠的区域被更加阴暗地着色。 12345fig, ax = plt.subplots(figsize=(15, 8))returns.plot(ax=ax)ax.plot(returns.index, 1/np.exp(trace[’s’,::30].T), ’r’, alpha=.03);ax.set(title=’volatility_process’, xlabel=’time’, ylabel=’volatility’);ax.legend([’S&amp;P500’, ’stochastic volatility process’]) 如您所见，该模型正确地推断出2008年金融危机期间波动性的增加。 由于其在随机游走分布中的高维度和依赖性结构，值得强调该模型的复杂性。然而，在PyMC3中实现的NUT正确地推断了后验分布。 Case study 2:Coal mining disasters本案例研究实现了1851年至1962年英国记录的煤矿灾害时间序列的变点模型（Jarrett，1979）。据认为，在此期间，每年的灾害数量都受到安全法规变化的影响，如图6所示。我们还包括一对缺失数据的年份，被NumPy MaskedArray确认为缺失 - 999作为该值。 我们的目标是在存在缺失数据的情况下估计变化发生的时间，使用多步法使我们能够拟合包含离散和连续随机变量的模型。 1234567891011disaster_data = np.ma.masked_values([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,2, 2, 3, 4, 2, 1, 3, -999, 2, 1, 1, 1, 1, 3, 0, 0,1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,3, 3, 1, -999, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1], value=-999)year = np.arange(1851, 1962)plot(year, disaster_data, ’o’, markersize=8);ylabel(\"Disaster count\")xlabel(\"Year\") 时间序列中的灾难计数被认为遵循泊松过程，在时间序列的早期具有相对大的速率参数，而在后面的部分中具有较小的速率。这种问题的贝叶斯方法是将变化点视为模型中的未知量，并为其分配先验分布，我们使用数据集中的证据将其更新为后验。 在我们的模型中： 参数定义如下： 1234567891011from pymc3 import DiscreteUniform, Poisson, switch with Model() as disaster_model: switchpoint = DiscreteUniform(’switchpoint’, lower=year.min(), upper=year.max(), testval=1900) # Priors for pre- and post-switch rates number of disasters early_rate = Exponential(’early_rate’, 1) late_rate = Exponential(’late_rate’, 1) # Allocate appropriate Poisson rates to years before and after current rate = switch(switchpoint &gt;= year, early_rate, late_rate) disasters = Poisson(’disasters’, rate, observed=disaster_data) 该模型引入了具有泊松似然性的离散变量和在变化点s上的离散均匀先验。我们对rate变量的实现是一个条件确定性变量，其值取决于s的当前值。 1rate = switch(switchpoint &gt;= year, early_rate, late_rate) 使用Theano函数开关实现条件语句，该函数开关使用第一个参数来选择接下来的两个参数中的任何一个。 在创建观察到的随机随机变量时，通过将带有NaN值的MaskedArray或pandas.DataFrame传递给观察到的参数来简明地处理缺失值。由此，PyMC3自动创建另一个随机变量disasters.missing_values，它将缺失值视为未观察到的随机节点。我们需要做的就是处理缺失值，确保我们为这个随机变量分配一个步骤方法。 不幸的是，因为它们是离散变量，因此没有有意义的梯度，我们不能使用NUTS对开关点或丢失的灾难观测进行采样。相反，我们将使用Metroplis步骤方法进行采样，该方法实现了自调整Metropolis-Hastings，因为它旨在处理离散值。 这里，样本函数接收包含NUTS和Metropolis采样器的列表，并且通过首先在每次迭代时应用step1然后step2来进行采样。 123456from pymc3 import Metropoliswith disaster_model: step1 = NUTS([early_rate, late_rate]) step2 = Metropolis([switchpoint, disasters.missing_values[0]] ) trace = sample(10000, step=[step1, step2])[-----------------100%-----------------] 10000 of 10000 complete in 6.9 sec PYMC3 FEATURESArbitrary deterministic variables由于依赖于Theano，PyMC3提供了许多数学函数和运算符，用于将随机变量转换为新的随机变量。但是，Theano中的函数库并不详尽，因此PyMC3提供了在纯Python中创建任意Theano函数的功能，并在PyMC3模型中包含这些函数。as_op函数装饰器支持此功能。 12345678910111213import theano.tensor as Tfrom theano.compile.ops import as_op@as_op(itypes=[T.lscalar], otypes=[T.lscalar])def crazy_modulo3(value): if value &gt; 0: return value % 3 else : return (-value + 1) % 3with Model() as model_deterministic: a = Poisson(’a’, 1) b = crazy_modulo3(a) Theano要求声明函数的输入和输出的类型，这些类型是由输入的itypes和输出的otype指定的as_op。这种方法的一个重要缺点是Theano无法检查这些函数以计算基于哈密顿量的采样器所需的梯度。因此，不可能将HMC或NUTS采样器用于使用这种运算符的模型。但是，如果我们从theano.Op继承而不是使用as_op，则可以添加渐变。 Arbitrary distributionsPyMC3中的统计分布库虽然很大，但并不详尽，但PyMC允许创建用户定义的概率分布。对于简单的统计分布，DensityDist函数将任何计算对数概率日志（p（x））的函数作为参数。该函数可以在其计算中使用其他父随机变量。这是一个受VanderPlas（2014）博客文章启发的例子，其中Jeffreys先验用于指定对变换不变的先验。在简单线性回归的情况下，这些是： 可以将这些函数的对数指定为DensityDist的参数并插入到模型中。 12345678910import theano.tensor as Tfrom pymc3 import DensityDist, Uniformwith Model() as model: alpha = Uniform(’intercept’, -100, 100) # Create custom densities beta = DensityDist(’beta’, lambda value: -1.5 * T.log(1 + value**2), testval=0) eps = DensityDist(’eps’, lambda value: -T.log(T.abs_(value)), testval=1) # Create likelihood like = Normal(’y_est’, mu=alpha + beta * X, sd=eps, observed=Y) 对于更复杂的分布，可以根据需要创建Continuous或Discrete的子类并提供自定义logp函数。这就是如何指定PyMC3中的内置分布函数。例如，心理学和天体物理学等领域对于可能需要数值近似的特定过程具有复杂的似然函数。在这些情况下，根据预定义的Theano运算符编写函数是不可能的，我们必须使用as_op或继承自theano.Op的自定义Theano运算符。 下面显示了将上面的beta变量实现为Continuous子类，以及使用as_op装饰器的子函数，尽管这不是绝对必要的。 123456789101112131415161718from pymc3.distributions import Continuousclass Beta(Continuous): def __init__(self, mu, *args, **kwargs): super(Beta, self).__init__(*args, **kwargs) self.mu = mu self.mode = mu def logp(self, value): mu = self.mu return beta_logp(value - mu)@as_op(itypes=[T.dscalar], otypes=[T.dscalar])def beta_logp(value): return -1.5 * np.log(1 + (value)**2)with Model() as model: beta = Beta(’slope’, mu=0, testval=0) Generalized linear models广义线性模型(GLM)是一类灵活的模型，广泛用于估计单个结果变量与一个或多个预测因子之间的回归关系。由于这些模型非常常见，PyMC3提供了一个GLM子模块，该模块允许灵活地创建简单的GLM，以及通过Patsy模块实现的直观的类R语法。 glm子模块需要将数据包含为pandas DataFrame。因此，对于我们的线性回归示例： 123# Convert X and Y to a pandas DataFrameimport pandasdf = pandas.DataFrame({’x1’: X1, ’x2’: X2, ’y’: Y}) 然后可以在一行代码中非常简洁地指定模型。 123from pymc3.glm import glmwith Model() as model_glm: glm(’y ~ x1 + x2’, df) 如果未通过family参数指定，则错误分布被认为是正常的。在逻辑回归的情况下，可以通过传入二项式族对象来修改它。 1234from pymc3.glm.families import Binomial df_logistic = pandas.DataFrame({’x1’: X1, ’x2’: X2, ’y’: Y &gt; 0})with Model() as model_glm_logistic: glm(’y ~ x1 + x2’, df_logistic, family=Binomial()) 通过glm指定的模型可以使用与标准PyMC3模型相同的样本函数进行采样。 BackendsPyMC3支持不同的方法来存储来自MCMC模拟的样本，称为后端。这些包括将输出存储在内存中，文本文件中或SQLite数据库中。默认情况下，使用内存中的ndarray，但是对于非常大的模型运行很长时间，这可能会超出可用的RAM，并导致失败。例如，将SQLite后端指定为sample的trace参数将导致将样本保存到由模型自动初始化的数据库中。 1234567from pymc3.backends import SQLitewith model_glm_logistic: backend = SQLite(’logistic_trace.sqlite’) trace = sample(5000, Metropolis(), trace=backend)[-----------------100%-----------------] 5000 of 5000 complete in 2.0 sec 使用磁盘后端的第二个优点是模型输出的可移植性，因为随后可以使用加载函数重新加载存储的跟踪（例如，在另一个会话中）：1234from pymc3.backends.sqlite import loadwith basic_model: trace_loaded = load(’logistic_trace.sqlite’) DISCUSSION概率编程是统计学习中的一种新兴范式，其中贝叶斯建模是一个重要的子学科。概率编程的特征特征？将变量指定为概率分布和其他变量和观测值的条件变量？使其成为在各种设置和模型复杂度范围内构建模型的有力工具。伴随着概率编程的兴起，贝叶斯模型拟合方法的创新突然爆发，代表了对现有MCMC方法的显着改进。然而，尽管有这种扩展，但很少有软件包能够跟上方法创新的步伐，而且很少有非专家用户能够实现模型。 PyMC3为定量研究人员提供了一个概率编程平台，可灵活，简洁地实施统计模型。一个庞大的统计分布库和几个预定义的拟合算法允许用户专注于手头的科学问题，而不是贝叶斯建模的实现细节。选择Python作为开发语言而不是特定于域的语言意味着PyMC3用户能够使用动态的高级编程语言以交互方式工作来构建模型，内省模型对象以及调试或分析他们的工作 这很容易学习。PyMC3的模块化，面向对象设计意味着添加新的拟合算法或其他功能非常简单。此外，PyMC3具有大多数其他软件包中没有的几个特性，最值得注意的是基于哈密顿量的采样器以及仅由STAN提供的约束随机变量的自动变换。然而，与STAN不同，PyMC3支持离散变量以及非基于梯度的采样算法，如Metropolis-Hastings和Slice采样。 PyMC3的开发是一项持续的工作，并计划在未来版本中使用多种功能。最值得注意的是，变分推理技术通常比MCMC采样更有效，但代价是普遍性。然而，最近，已经开发了黑盒变分推理算法，例如自动微分变分推理（ADVI）（Kucukelbir等，2015）。该算法计划添加到PyMC3。作为一个开源科学计算工具包，我们鼓励研究人员为贝叶斯模型开发新的拟合算法，以便在PyMC3中提供参考实现。由于采样器可以用纯Python代码编写，因此可以通常实现它们以使它们在任意PyMC3模型上工作，从而为作者提供更多的用户来使用它们的方法。","link":"/2019/04/03/概率编程之PyMC3/"},{"title":"数字IC设计面试100题","text":"主要来自知乎的整理 1. 什么是同步逻辑和异步逻辑？ 2.同步电路和异步电路的区别： 3. 时钟设计的实质： 4. 建立时间和保持时间的改变： 5. 为什么触发器要满足建立时间和保持时间？ 6. 什么是亚稳态？为什么两级触发器可以防止亚稳态？ 7. 系统最高速度计算（最快时钟频率）和流水设计思想？ *8.时钟约束的基本概念和基本策略？ 9.附加约束的作用？ 10.FPGA设计工程师努力的方向： 11.对于多位的异步信号如何进行同步？ 12.FPGA和CPLD的区别？ 13.锁存器（latch）和触发器(flip-flop)的区别？ 14.FPGA芯片内有哪两种的存储器资源？ 15.什么是时钟抖动？ 16.FPGA设计中对时钟的使用 17: FPGA设计中如何实现同步时序电路的延时 18.FPGA中可以综合实现为RAM/ROM/CAM的三种资源及其他注意事项？ 19. Xilinx中与全局时钟资源和DLL相关的硬件原语 20. HDL语言的层次概念？ 21:查找表的原理与结构？ 22.IC设计前端到后端的流程的EDA工具？ *23.寄生电容效应在IC设计中怎样克服和利用 24.设计题1–用触发器和逻辑门设计一个一位加法器 25. 设计自动饮料贩卖机 *26.什么是“线与逻辑”，要实现它，在硬件特性上有什么具体要求？ 27.什么是竞争冒险？怎么判断？如何消除？ *28.常用的逻辑电平？TTL和CMOS电平可以相互直连吗？ 29：IC设计中同步复位与异步复位的区别？ 30.Moore与Meeley状态机的特征？ 31.多时钟域设计中，如何处理信号跨时域问题？ 32.说说静态、动态时序模拟的优缺点？ *33.一个四级的Mux，其中第二级为关键信号，如何改善timing? 34.给出一个门级图，又给出了各个门的传输延时，问关键路径是什么？给出了输入，使得输出依赖于关键路径？ 35.为什么一个标准的倒相器中P管的宽长比要比N管的宽长比大？ 36.用mos管搭出一个与非门？ 37.画出NOT,NAND,NOR的符号，真值表，还有transistor level的电路 38.画出CMOS图，画出two-to-one mux gate(二选一电路)？ 39.用一个二选一mux和一个inv实现异或？ 40.画出CMOS电路的晶体管架构，实现Y=AB+C(D+E)?画出Y=AB+C的CMOS电路图，画出Y=AB+CD的CMOS电路图。 41.用与非门等设计全加法器？ 未解答*42.A、B、C、D、E进行投票，少数服从多数，输出是F(ABCDE中1的个数比0的多输出1，否则输出0)，用与非门实现，输出数目没有限制？ 未解答*43.画出一种CMOS的D锁存器的电路图和版图？ 44.LATCH和DFF概念和区别？ 45.latch和register的区别，为什么现在多用register.行为级描述中latch是如何产生的？ 46.用D触发器做个二分频电路 47.什么是状态图？ 48.用你熟悉的设计方式设计一个可以预置初值的7进制循环计数器，15进制呢？ 49.你知道的可编程逻辑器件有哪些？ 50.用Verilog或VHDL写一段代码，实现消除一个glitch(毛刺)？ 51. SRAM、FLASH、Memory, DRAM, SSRAM和SDRAM有什么区别？ 52.有四种复用方式，频分多路复用，写出另外三种？ 未解答53.ASIC设计流程中什么时候修正Setup time violation 和Hold time violation?如何修正？解释setup和hold time violation，画图说明，并说明解决办法。 54.给出一个组合逻辑电路，要求分析逻辑功能。 55.如何防止亚稳态？ 56.基尔霍夫定理的内容 57.描述反馈电路的概念，列举他们的应用。 58.有源滤波器和无源滤波器的区别 59.给出了reg的Setup,Hold时间，求中间组合逻辑的delay范围 60.时钟周期为T,触发器D1的寄存器到输出时间（触发器延时Tco）最大为T1max，最小为T1min。组合逻辑电路最大延迟为T2max,最小为T2min。问，触发器D2的建立时间T3和保持时间应满足什么条件。 *61.给出某个一般时序电路图，有Tsetup, Tdelay, Tclk-&gt;q(Tco)，还有clock的delay，写出决定最大时钟的因素，同时给出表达式 *62.实现三分频电路，2/3分频电路(偶数倍分频，奇数倍分频) 63.名词解释 64.三极管的特性 65.用波形表示D触发器的功能 66.用传输门和倒向器搭建一个边沿触发器 67.用逻辑门画出D触发器。 原文地址ictown_数字IC设计工程师笔试面试经典100题-有答案陈恩 1. 什么是同步逻辑和异步逻辑？答：同步逻辑是电路中的信号和FPGA时钟信号存在逻辑上的因果关系，而异步逻辑则是电路中的信号和FPGA时钟信号没有固有的因果关系。 同步时序逻辑电路的特点：各触发器的时钟端全部连在同一个时钟，只有在时钟上升沿或者下降沿，电路状态才会发生改变，改变的状态将保持到下一个时钟脉冲到来。因此无论外部输入信号有无变化，在这段时间内，状态表中的每个状态是稳定的。 异步时序电路：电路中除了可以使用带时钟的触发器以外，还可以使用不带时钟的触发器和延迟元件作为存储元件，电路中没有统一的时钟，电路的状态由外部输入的变化直接引起。 2.同步电路和异步电路的区别：答：同步电路：电路中所有的触发器都连接的是同一个时钟源，因此所有触发器的状态的变化都与所加的时钟脉冲信号同步。 异步电路：电路中没有统一的时钟，有的触发器的时钟输入与时钟脉冲源相连，只有这些脉冲的状态变化和时钟脉冲源同步，而其他的触发器状态不与时钟脉冲同步。 3. 时钟设计的实质：答：时钟设计的实质是满足每一个触发器的建立/保持时间的要求。 4. 建立时间和保持时间的改变：答：建立时间，触发器在时钟上升沿到来之前，数据输入端的数据必须保持不变的最小时间。 保持时间，触发器在时钟上升沿到来之后，数据输入端的数据必须保持不变的最小时间。 5. 为什么触发器要满足建立时间和保持时间？答：因为触发器内部数据的形成是需要一定的时间的，如果不满足建立时间和保持时间，输入在这段时间变化，触发器将进入亚稳态，进入亚稳态的输出将不稳定，在0和1之间变化，这时需要一个恢复时间，输出才能变得稳定。但稳定之后的输出可能不是你的输出值。 为了防止亚稳态的传播，我们通常用两级触发器来同步异步输入信号，这样可以防止异步输入信号对于本级时钟可能不满足建立保持时间而使本级触发器产生的亚稳态传播到下一级。 6. 什么是亚稳态？为什么两级触发器可以防止亚稳态？答：这是一个异步电路同步化的问题。亚稳态指的是触发器无法在某个规定时间段内到达一个可以确认的状态。使用两级触发器来使异步电路同步化的电路其实叫做“一位同步器”，他只能用来对一位异步信号进行同步。 两级触发器可以防止亚稳态传播的原理：假设第一级触发器输入不满足其建立时间保持时间，它的第一个脉冲到来后输出的数据就为亚稳态，那么在下一个脉冲到来之前，其输出的亚稳态数据将在一段恢复时间后必须平稳下来，而且稳定的数据必须满足第二级触发器的建立时间，如果都满足了，下一个脉冲沿到来之前，第二级脉冲器便不会出现亚稳态，因为其输入端的数据满足其建立保持时间。同步的有效条件：第一级触发器的进入亚稳态后的恢复时间+第二级触发器的建立时间&lt;=时间周期。 更确切的说，输入脉冲宽度必须大于同步时钟周期与第一级触发器所需的保持时间之和。最保险的脉冲宽度是两倍同步时钟周期，所以，这样的同步电路对于从慢的时钟域来的异步信号进入较快的时钟域是比较有效的，对于进入一个较慢的时钟域，则没有效果。 7. 系统最高速度计算（最快时钟频率）和流水设计思想？答：同步电路的速度是指同步系统时钟的速度，同步时钟越快，电路处理数据的时间间隔越短，电路在单位时间内处理的数据量就越大。 假设Tco是触发器的输入数据被时钟打入到触发器到数据到达触发器的输出端的延时（Tco=Tsetup+Thold)。Tsetup是D触发器的建立时间；Tdelay是组合逻辑的延时。 加入数据已经被打入D触发器，那么数据到达第一个触发器Q输入出端需要的延时是Tco，经过组合逻辑延时Tdeleay，到达第二个触发器的D端，要希望时钟能在第二个触发器再次被稳定的打入到触发器，则时钟的延迟必须大于Tco+Tdelay+Tsetup，也就是说最小的时钟周期为Tmin=Tco+Tdelay+Tsetup，最快的时钟频率为Fmax=1/Tmin。 FPGA开发软件也是通过这种方式来计算系统的最高允许速度Fmax。因为Tco和Tsetup都是由具体的器件工艺决定的，固设计电路只能改变组合逻辑的延迟时间Tdelay，所以说缩短触发器间的组合逻辑的延时时间是提高同步电路速度关键所在。 由于一般同步电路都大于以及锁存，而要是电路稳定工作，时钟周期必须满足最大延时要求。故只有缩短最长延时路径，才能提高电路的工作频率，可以将较大的组合逻辑分为N个小模块，通过适当的方法平均分配组合逻辑，然后中间插入寄存器，并和原触发器使用相同的时钟。这样就可以提高电路的工作频率。这就是所谓的“流水线技术”实现的基本设计思想，即原设计速度受限部分用一个时钟周期实现，采用流水线技术插入寄存器，可以用N个时钟周期实现，因此系统的工作速度可以加快，吞吐量加大。但是，流水线设计会在源数据通路上加上延时，另外硬件面积开销增加。 *8.时钟约束的基本概念和基本策略？答：时钟约束主要包括周期约束，偏移约束，静态时序路径约束三种。通过附加时序约束可以综合布线工具调整映射和布局布线，使设计达到时序要求。 附加时序约束一般策略是先附加全局约束，然后对快速和慢速例外路径附加专门约束。附加全局约束时，首先先定义设计的所有时钟，对各时钟域的同步元件进行分组，对分组附加周期约束，然后对FPGA/CPLD输入输出PAD附加偏移约束、对全组合逻辑的PAT TO PAD路径附加约束。附加专门约束时，首先约束分组之间的路径，然后约束快，慢速路径和多周期路径，以及其他特殊路径。 9.附加约束的作用？答： 提高设计的工作频率（减少逻辑和布线延时)； 获得正确的时序分析报告；(静态时序分析工具以约束作为判断时序是否满足设计要求的标准，因此要求设计者正确输入约束，以便静态时序分析工具可以正确输出时序报告） 指定FPGA/CPLD的电器标准和引脚位置 10.FPGA设计工程师努力的方向：答：SOPC，高速串行I/O，低功耗，可靠性，可测试性和设计验证流程优化等方面。 随着芯片工艺的提高，芯片容量、密集度都在增加，FPGA设计也在朝着高速，高度集成、低功耗、高可靠性、高可测、可验证性发展。 芯片可测、可验证，正成为复杂设计所必备的条件，尽量在上板之前查出BUG，将发现BUG的时间提前，这也是一些公司花大气力设计仿真平台的原因。随着单板功能的提高、成本的压力，低功耗也逐渐进入FPGA设计者考虑的范围，完成相同的功能下如何能够使芯片的功耗最低，据说altera、xilinx都在根据自己的芯片特点整理出如何降低功耗的文档。 高速串行IO的应用，也丰富了FPGA的应用范围，像xilinx的v2 pro中的高速链路也逐渐被应用。 11.对于多位的异步信号如何进行同步？答：对于一位的异步信号可以使用“一位同步器进行同步”（使用两级触发器），而对于多位的异步信号，可以采用如下方法：1：可以采用保持寄存器加握手信号的方法（多数据，控制，地址）；2：特殊的具体应用电路的结构，根据应用的不同而不同；3：异步FIFO。（最常用的是DPRAM） 12.FPGA和CPLD的区别？答： CPLD更适合完成各种算法和组合逻辑，FPGA更适合于完成时序逻辑。换句话说，FPGA更适合于触发器丰富的结构，而CPLD更适合触发器有限而乘积项丰富的结构。 CPLD的连续式布线结构决定了它的时序延迟是均匀的和可预测的，而FPGA的分段式布线结构决定了其延迟的不可预测性。 在编程上FPGA比CPLD具有更大的灵活性。CPLD通过修改具有固定内连电路的逻辑功能来编程，FPGA主要通过改变内部连线的布线来编程；FPGA可在逻辑门下编程，而CPLD是在逻辑块下编程。 FPGA的集成度比CPLD高，具有更复杂的布线结构和逻辑实现。 CPLD比FPGA使用起来更方便。CPLD的编程采用E2PROM或FASTFLASH技术，无需外部存储器芯片，使用简单。而FPGA的编程信息需存放在外部存储器上，使用方法复杂。 CPLD的速度比FPGA快，具有较大的时间可预测性。这是由于FPGA是门级编程，并且CLB之间采用分布式互联，而CPLD是逻辑块级编程，并且其逻辑块之间互联是集总式的。 在编程方式上，CPLD主要是基于E2PROM或FLASH存储器编程，编程次数可达1万次，优点是系统断电时编程信息也不丢失。CPLD又可分为在编 程器上编程和在系统编程两类。FPGA大部分是基于SRAM编程，编程信息在系统断电时丢失，每次上电时，需从器件外部将编程数据重新写入SRAM中。其 优点是可以编程任意次，可在工作中快速编程，从而实现板级和系统级的动态配置。 CPLD保密性好，FPGA保密性差。 一般情况下，CPLD的功耗要比FPGA大，且集成度越高越明显。 13.锁存器（latch）和触发器(flip-flop)的区别？答：电平敏感的存储器称为锁存器。可分为高电平锁存器和低电平锁存器，用于不同时钟之间信号的同步。 由交叉耦合的门构成的双稳态的存储原件称为触发器。分为上升沿触发和下降沿触发。可以认为是两个不同电平敏感的锁存器串联而成。前一个锁存器决定触发器的建立时间，后一个锁存器决定保持时间。 14.FPGA芯片内有哪两种的存储器资源？答：FPGA芯片内部有两种存储器资源：一种是BLOCK RAM，另一种是由LUT配置成的内部存储器（分布式RAM）。 BLOCK RAM是由一定数量固定大小的存储块构成的，使用BLOCK RAM资源不占额外的逻辑资源，而且速度快。但是使用的时候消耗的BLOCK RAM资源是其块大小的整数倍。 15.什么是时钟抖动？答：时钟抖动是指芯片的某一个点上时钟周期发生暂时性的变化，也就是时钟周期在不同的周期上可能加长或者缩短。它是一个平均值为0的平均变量。 16.FPGA设计中对时钟的使用答：FPGA芯片有固有的时钟路由，这些路由能有减少时钟抖动和偏差。需要对时钟进行相位移动和变频的时候，一般不允许对时钟进行逻辑操作，这样会增加时钟的偏差和抖动，还会使时钟带上毛刺，一般的处理方法是采用FPGA芯片自带的时钟管理器PLL,DLL或DCM，或者把逻辑转换到触发器的D输入（这些也是对时钟逻辑操作的替代方案） 17: FPGA设计中如何实现同步时序电路的延时答：首先异步电路的延时实现：异步电路一半是通过加Buffer、两级与非门等来实现延时，但这不是很适合同步电路实现延时。在同步电路中，对于比较大的和特殊的要求的延时，一般是通过高速时钟产生计数器，通过计数器来控制延时，对于比较小的延时，可以通过触发器打一拍，不过这样只能延迟一个时钟周期。 18.FPGA中可以综合实现为RAM/ROM/CAM的三种资源及其他注意事项？答：三种资源：BLOCK RAM，触发器（FF），查找表（LUT）; 注意事项： 在生成RAM等存储单元时，应该首选BLOCK RAM；原因有二：第一：使用BLOCK RAM等资源，可以节约更多的FF和4-LUT等底层可编程单元。使用BLOCK RAM可以说是“不用白不用”，是最大程度发挥器件性能，节约成本的一种体现。第二：BLOCK RAM是一种可以配置的硬件结构，其可靠性和速度与用LUT和Register构建的存储更有优势的。 弄清FPGA的硬件结构，合理使用BLOCK RAM资源。 分析BLOCK RAM容量，高效使用BLOC RAM资源。 分布式RAM资源（Distribute RAM） 19. Xilinx中与全局时钟资源和DLL相关的硬件原语答：常用的与全局时钟资源有关的Xilinx器件原语包括：IBUFG,IBUFGS,BUFG,BUFGP,BUFGCE,BUFGMX,BUFGDLL,DCM等，关于各个器件原语的解释可以参考《FPGA设计指导准则》p50部分 20. HDL语言的层次概念？答：HDL语言是分层次的、类型的，最常用的层次概念有系统与标准级，行为级，寄存器传输级和门级。 系统级，算法级，RTL级(行为级)，门级，开关级。 21:查找表的原理与结构？答：查找表（Look up table）简称LUT, LUT本质上就是一个RAM。目前FPGA中多使用4输入LUT,所以每一个LUT可以看成一个有4位地址线的16x1的RAM。当用户通过原理图或者HDL语言描述了一个逻辑电路，PLD/FPGA开发软件会自动计算逻辑电路的所有可能的结果，并把结果事先写入RAM，每输入一个信号进行逻辑运算就等于输入一个地址进行查表，找出地址对应的内容，然后输出即可。 22.IC设计前端到后端的流程的EDA工具？答：设计前端也称为逻辑设计，后端也称为物理设计，两者并没有严格的界限，一般涉及与工艺有关的设计就是后端设计。 规格制定：客户向芯片设计公司提出设计要求。 详细设计：芯片设计公司（Fabless）根据客户提出的规格要求，拿出设计解决方案和具体实现架构，划分模块功能。目前架构的验证一般基于systemC语言，对价后模型的仿真可以使用systemC的仿真工具。例如CoCentric和Visual Elite等。 HDL编码：设计输入工具：ultra， visiual VHDL等 仿真验证：modelsim 逻辑综合：synplify 静态时序分析：synopsys的Prime Time 形式验证：Synopsys的Formality *23.寄生电容效应在IC设计中怎样克服和利用或者，IC设计过程中将寄生效应怎样反馈影响设计师的设计方案？答：所谓寄生效应就是那些溜进你的PCB并在电路中大破坏、令人头疼、原因不明的小故障。他们就是渗入高速电路中隐藏的寄生电容和寄生电感。其中包括由封装引脚和印制线过长形成的寄生电感；焊盘到地、焊盘到电源平面和焊盘到印制线之间形成的寄生电容；通孔之间的相互影响，以及许多其它可能的寄生效应。 理想状态下，导线是没有电阻，电容和电感的。而在实际中，导线用到了金属铜，它有一定的电阻率，如果导线足够长，积累的电阻也相当可观。两条平行的导线，如果互相之间有电压差异，就相当于形成了一个平行板电容器。通电的导线周围会形成磁场（特别是电流变化时），磁场会产生感生电场，会对电子的移动产生影响，可以说每条实际的导线包括元器件的管脚都会产生感生电动势，这也就是寄生电感。 在直流或者低频情况下，这种寄生效应看不太出来。而在交流特别是高频交流条件下，影响就非常巨大了。根据复阻抗公式，电容、电感会在交流情况下会对电流的移动产生巨大阻碍，也就可以折算成阻抗。这种寄生效应很难克服，也难摸到。只能通过优化线路，尽量使用管脚短的SMT元器件来减少其影响，要完全消除是不可能的。 24.设计题1–用触发器和逻辑门设计一个一位加法器1234567891011121314151617181920212223module (clk, rst_n, current_stage, carryin,next_stage,carryout);input clk, rst_n;//时钟和复位，复位低电平有效input current_stage; //输人加数input carryin; //输入进位output reg next_stage; //加法输出output reg carryout;// 输出进位标识always @(posedge clk or rst_n)begin//触发器 if(!rst_n) begin carryout &lt;= 1'b0; next_stage &lt;= 1'b0; end else begin carryout &lt;= carryin &amp;&amp; current_stage; //与门 next_stage &lt;= (~carryin&amp;&amp;current_stage)||(carryin&amp;&amp;~current_stage); //两个与门加上或门 endendendmodule 25. 设计自动饮料贩卖机要求：饮料10分钱，硬币有5分钱和10分钱两种，并考虑找零 画出fsm(有限状态机) 用verilog编程，语法要符合FPGA设计的要求 设计工程中可食用的工具及设计过程 设计过程： 首先确定输入输出，A=1表示投入10分，B=1表示投入5分，Y=1表示弹出饮料，Z=1表示找零 画出电路的状态，S0表示没有进行投币，S1表示已有的5分硬币 画出状态转移图 12345678910111213141516171819202122232425262728293031323334353637383940414243444546module test(clk, rst_n, a, b, y, z);input clk, rst_n;input a, b; //a, 投入5分；b, 投入10分output reg y; //弹出饮料output reg z; //找零reg state, next_state; //两段式状态机写法parameter s0 = 1'b0, s1 = 1'b1;//s0: 没有进行投币， s1,已经有5分硬币always @(posedge clk or negedge rst_n)beginif(!rst_n) state &lt;= s0;else state &lt;= next_state;endalways @(posedge clk or negedge rst_n)beginif(!rst_n) begin y &lt;= 1'b0; z &lt;= 1'b0;endelse begin case(state) s0: if(a&amp;&amp;!b) next_state &lt;= s1; //投入了5分 else if(!a&amp;&amp;b) begin //投入了10分 next_state &lt;= s0; y &lt;= 1'b1; end else next_state &lt;= s0; s1: if(a&amp;&amp;!b) begin //再投入5分 next_state &lt;= s0; y &lt;= 1'b1; end else if(!a&amp;&amp;b) begin next_state &lt;= s0; y &lt;= 1'b1; z &lt;= 1'b1; end else next_state &lt;= s1; default : next_state &lt;= s0; endcaseendendendmodule 状态转移图如下所示： *26.什么是“线与逻辑”，要实现它，在硬件特性上有什么具体要求？答：线与逻辑是两个输出信号相连可以实现与的功能。在硬件上，要用oc门来实现，由于不用oc门可能使灌电流过大，而烧坏逻辑门，同时在输出端口应加一个上拉电阻。oc 门是集电极开路门。od门是漏机开路门。 27.什么是竞争冒险？怎么判断？如何消除？答：在组合电路，门电路两个输入信号同时向相反的逻辑电平跳变称为竞争，某输入变量经过不同的路径传输后，到达电路中某一回合点的时间有先后，由于竞争而使电路输出发生错误的现象称为冒险。（也就是由于竞争产生的毛刺） 判断方法： 代数法（如果布尔式中有相反的信号则可能产生竞争和冒险现象） 卡诺图：有两个相切的卡诺圈并且相切处没有被其他卡诺圈包围，就有出现竞争冒险的可能 实验法: 示波器观测 解决方法： 加滤波电容，消除毛刺的影响 加选通信号，避开毛刺 增加冗余项，消除逻辑冒险 *28.常用的逻辑电平？TTL和CMOS电平可以相互直连吗？答：常用的逻辑电平有12v、5v、3.3v TTL和CMOS不可以直连，由于TTL是在0.3-3.6v，而CMOS是12v有的是5v，CMOS输出接到TTL可以直连。TTL接到CMOS需要在输出端口加上一上拉电阻接到5v或者12v 用CMOS可以直接驱动TTL; 加上上拉电阻后，TTL可以驱动CMOS 上拉电阻用途： 当TTL电路驱动COMS电路时，如果TTL电路输出的高电平低于COMS电路的最低高电平（一般为3.5V），这时就需要在TTL的输出端接上拉电阻，以提高输出高电平的值。 OC门电路必须加上拉电阻，以提高输出的高电平值。 为加大输出引脚的驱动能力，有的单片机管脚上也常使用上拉电阻。 在COMS芯片上，为了防止静电造成损坏，不用的管脚不能悬空，一般接上拉电阻产生降低输入阻抗，提供泄荷通路。 芯片的管脚加上拉电阻来提高输出电平，从而提高芯片输入信号的噪声容限增强抗干扰能力。 提高总线的抗电磁干扰能力。管脚悬空就比较容易接受外界的电磁干扰。 长线传输中电阻不匹配容易引起反射波干扰，加上下拉电阻是电阻匹配，有效的抑制反射波干扰。 上拉电阻阻值的选择原则包括: 从节约功耗及芯片的灌电流能力考虑应当足够大；电阻大，电流小。 从确保足够的驱动电流考虑应当足够小；电阻小，电流大。 对于高速电路，过大的上拉电阻可能边沿变平缓。综合考虑以上三点,通常在1k到10k之间选取。对下拉电阻也有类似道理。 OC门电路必须加上拉电阻，以提高输出的高电平值。 OC门电路要输出“1”时才需要加上拉电阻不加根本就没有高电平 在有时我们用OC门作驱动（例如控制一个 LED）灌电流工作时就可以不加上拉电阻 总之加上拉电阻能够提高驱动能力。 29：IC设计中同步复位与异步复位的区别？答：同步复位在时钟沿变化，完成复位动作。异步复位不管时钟，只要复位信号满足条件，就完成复位动作。异步复位对复位信号要求比较高，不能有毛刺，如果其与时钟关系不确定，也可能出现亚稳态。 30.Moore与Meeley状态机的特征？答：Moore状态机的输出仅与当前状态值有关，且只在时钟边沿到来时才会发生变化。 Mealy状态机的输出不仅与当前状态值有关，而且与当前输入值有关。 31.多时钟域设计中，如何处理信号跨时域问题？答：不同时钟域之间的信号通信需要进行同步处理，这样可以防止新时钟域中的第一级触发器出现的亚稳态对下级逻辑造成影响。 信号跨时钟域同步：当单个信号跨时钟域时，可以采用两次触发器来同步；数据或地址总线跨时钟域时可以采用异步FIFO来实现时钟同步；第三种方法是采用握手信号。 32.说说静态、动态时序模拟的优缺点？答：静态时序分析是采用穷尽的分析方式来提取出整个电路存在的所有时序，计算信号在这些路径上的传播延时，检查信号的建立时间和保持时间是否满足时序的要求，通过最大路径延时和最小路径延时延时的分析，找出违背时序约束的错误。它不需要输入向量就能穷尽所有路径，且运行速度快，占用内存较少，不仅可以对芯片设计进行全面的时序功能检查，而且还可以利用时序分析的结果优化设计，因此时序分析越来越多的被用到了数字集成电路设计的验证中。 动态时序模拟就是通常的仿真，因为不可能产生完备的测试向量，覆盖门级网表的每一条路径。因此在动态时序分析中，无法暴露一些路径上可能存在的时序问题。 *33.一个四级的Mux，其中第二级为关键信号，如何改善timing?答：将第二级信号放到最后一级输出，同时注意改善片选信号，保证其优先级没有被修改。 34.给出一个门级图，又给出了各个门的传输延时，问关键路径是什么？给出了输入，使得输出依赖于关键路径？答:关键路径就是输入到输出的延时路径的最大路径，找到了关键路径就能求最大时钟频率。 35.为什么一个标准的倒相器中P管的宽长比要比N管的宽长比大？答：和载流子有关，P管是空穴导电，N管是电子导电，电子迁移率大于空穴，同样的电场下，N管的电流大于P管，因此要增大P管的宽长比，使之对称，这样才能使得两者上升时间下降时间相等、高低电平的噪声容限一样、充放电的时间相等。 36.用mos管搭出一个与非门？答：与非门，上并下串。或非门，上串下并 参考博客：MOS管及简单的CMOS逻辑门电路原理图 37.画出NOT,NAND,NOR的符号，真值表，还有transistor level的电路答：NOT门,其他两个门参考题36 38.画出CMOS图，画出two-to-one mux gate(二选一电路)？答：CMOS图为 Y=SA+S’B利用与非门和反相器，进行变换后Y=((SA)’*(S’A)’)’，三个与非门，一个反相器。也可以用传输门来实现数据选择器或者异或门 39.用一个二选一mux和一个inv实现异或？答:异或的逻辑为Y=AB’+A’B，而二选一的逻辑为Y=SA+S’B,可以让选择S解B,输入信号分别接A和A’,Y=SA+S’B=BA’+B’A 利用四选一实现F(x,y,z)=xz+yz’ F(x,y,z)=xyz + xy’z + xyz’ + x’yz’=x’y’0 + x’yz’ + xy’z + xy1 Y = A’B’D0 + A’BD1 + AB’D2 + ABD3 所以D0=0, D1=z’, D2=z, D3=1 40.画出CMOS电路的晶体管架构，实现Y=AB+C(D+E)?画出Y=AB+C的CMOS电路图，画出Y=AB+CD的CMOS电路图。答：CMOS电路和与非门的电路图在题38和题36，考虑用与非门实现上诉电路 Y=AB+C(D+E)=((AB)’(CD)’(CE)’)’, 三个两输入与非门，一个三输入与非门 Y=AB+C=((AB)’C’)’，两个与非门，两个反相器 Y=AB+CD=((AB)’(CD)’)’，三个两输入与非门 41.用与非门等设计全加法器？答： 全加法器的输入为A, B, Cin。 A，B是加法的输入，Cin是进位输入。输出是Sum和Cout，Sum是加法输出，Cout是进位输出。 未解答*42.A、B、C、D、E进行投票，少数服从多数，输出是F(ABCDE中1的个数比0的多输出1，否则输出0)，用与非门实现，输出数目没有限制？未解答*43.画出一种CMOS的D锁存器的电路图和版图？44.LATCH和DFF概念和区别？答：DFF是边沿敏感，LATHC是电平敏感。 latch（锁存器）与 DFF（D触发器）的区别 latch由电平触发，非同步控制。在使能信号有效时latch相当于通路，在使能信号无效时latch保持输出状态。DFF由时钟沿触发，同步控制。 latch容易产生毛刺（glitch），DFF则不易产生毛刺。 如果使用门电路来搭建latch和DFF，则latch消耗的门资源比DFF要少，这是latch比DFF优越的地方。所以，在ASIC中使用latch的集成度比DFF高，但在FPGA中正好相反，因为FPGA中没有标准的latch单元，但有DFF单元，一个LATCH需要多个LE才能实现。 latch将静态时序分析变得极为复杂。 一般的设计规则是：在绝大多数设计中避免产生latch。它会让您设计的时序完蛋，并且它的隐蔽性很强，非老手不能查出。latch最大的危害在于不能过滤毛刺。这对于下一级电路是极其危险的。所以，只要能用D触发器的地方，就不用latch。 45.latch和register的区别，为什么现在多用register.行为级描述中latch是如何产生的？答： latch是电平敏感，register是边沿触发，register在同一时钟边沿边沿触发下动作，符合同步电路的设计思想，而Latch则属于异步电路设计，往往会导致时序分析困难，不适合的应用到Latch则会大量浪费芯片资源。 1234567891011121314module latch(Din, Dout, enable);input enable;input Din;output reg Dout;always @(enable or Din)begin if(enable) Dout &lt;= Din; else Dout &lt;= Dout;endendmodule 46.用D触发器做个二分频电路答：由D触发器构建的二分频电路 现实工程中一般不采用这样的方式实现，二分频一般通过DCM或者PLL产生，这样得到的分频信号没有相位差 47.什么是状态图？答：状态图是以几何图形的方式描述时序逻辑电路的状态转移规律以及输入和输出的关系。 48.用你熟悉的设计方式设计一个可以预置初值的7进制循环计数器，15进制呢？答：7位进制循环计数器123456789101112131415161718192021222324252627module counter7(clk , rst_n, load, data_in, counter_out, carry_out);input clk, rst_n;input load; //加载数字开始计数input[2:0] data_in;output reg [2:0] counter_out;output reg carry_out; //计数满输出always @(posedge clk or negedge rst_n)beginif(!rst_n) begin counter_out &lt;= 3'b0; carry_out &lt;= 1'b0;endelse if(load) counter_out &lt;= data_in;else if(counter_out=3'd6) begin counter_out &lt;= 3'b0; carry_out &lt;= 1'b1;endelse begin counter_out &lt;= counter_out + 3'b1; carry_out &lt;= 1'b0endendendmodule 15进制循环计算器，对应的将上面位宽加1，计数满和达到计数值改为14 49.你知道的可编程逻辑器件有哪些？答：PAL，PLA，GAL，CPLD，FPGA 50.用Verilog或VHDL写一段代码，实现消除一个glitch(毛刺)？答：将通过传输过来的信号经过两级触发器就可以消除毛刺（这种消除毛刺的方式是需要满足一定的条件的，并不能保证一定可以消除）123456789101112131415161718192021module (clk, rst_n, data_in, data_out);input clk, rst_n;input data_in;output data_out;reg data_r1, data_r2;always @(posedge clk or negedge rst_n)beginif(!rst_n) begin data_r1 &lt;= 1'b0; data_r2 &lt;= 1'b0;endelse begin data_r1 &lt;= data_in; data_r2 &lt;= data_r1;endendassign data_out &lt;= data_r2;endmodule 51. SRAM、FLASH、Memory, DRAM, SSRAM和SDRAM有什么区别？答：SRAM:静态随机存储，存取速度快，但是容量小，掉电后数据会丢失，不像DRAM那样需要不停的REFLASH，制造成本比较高，通常用来作为(CACHE)记忆体使用。 FLASH:闪存，存取速度慢，容量大，掉电后数据不会丢失 DRAM:动态随机存储器，必须不断的更新加强（REFRESHED）电位差，否则电位差将降低至无法有足够的能力表现每一个记忆体单位处于何种状态。价格是比SRAM便宜，但是访问速度慢，耗电量较大，常用作计算机的内存使用。 SSRAM:即同步静态随机存储器。对于SSRAM的所有访问都在时钟的上升、下降沿启动。地址、数据输入和其他控制信号均于时钟信号相关。 SDRAM:即同步动态随机存取存储器 52.有四种复用方式，频分多路复用，写出另外三种？答：四种复用方式，频分多路复用（FDMA），时分多路复用（TDMA），码分多路复用（CDMA），波分多路复用（WCDMA）。 未解答53.ASIC设计流程中什么时候修正Setup time violation 和Hold time violation?如何修正？解释setup和hold time violation，画图说明，并说明解决办法。54.给出一个组合逻辑电路，要求分析逻辑功能。答：所谓组合逻辑电路的分析，就是要找出给定逻辑电路输入和输出的关系，并指定电路的逻辑功能。 分析的过程一般按以下的步骤进行： 根据给定的逻辑电路，从输入端开始，逐级的推导出输出端的逻辑函数表达式。 根据输出函数的表达式列出真值表 用文字概括电路的逻辑功能 55.如何防止亚稳态？答：亚稳态是指触发器无法在某个规定时间段内达到一个可以确认的状态，当一个触发器进入亚稳态时，即无法预测该单元的输出电平，也无法预测何时输出才能稳定在某个正确的电平。在这个稳定期间，触发器输出一些中间级电平，或者可能处于震荡状态，并且这种无用的输出电平可以沿信号通道上的各个触发器级联式传播下去。 解决方法： 降低系统的时钟频率 用更快的FF 引入同步机制，防止亚稳态（可以用两级触发器） 改善时钟质量，用边沿变化更快的时钟信号 56.基尔霍夫定理的内容答：基尔霍夫定理包括电流定律和电压定律： 电流定律：在集总电路中，在任意一瞬间，流向某一节点的电流之和恒等于有该节点流出的电流之和。 电压定律：在集总电路中，在任一瞬间，沿电路中任一回路绕行一周，在该回路上的电动势之和恒等于个电阻上的电压降之和。 57.描述反馈电路的概念，列举他们的应用。答：反馈，就是在电路系统中，把输出回路中的电量（电流或者电压），输出到输入回路中去。 反馈的类型有：电压串联负反馈，电流串联负反馈，电压并联负反馈，电流并联负反馈。 负反馈的优点：降低放大器的增益灵敏度，改变输入电阻和输出电阻，改善放大器的线性和非线性失真，有效地扩展放大器的通频带，自动调节的作用。 电压负反馈的特点：电路的输出电压趋于维持恒定。 电路负反馈的特点：电路的输出电流趋于维持恒定。 58.有源滤波器和无源滤波器的区别答：无源滤波器：这种电路主要有无源元件R、L、C组成 有源滤波器：集成运放和R、C组成，具有不用电感，体积小，重量轻等优点 集成运放的开环电压增益和输入阻抗均很高，输出电阻小，构成有源滤波电路后还具有一定的电压放大和缓冲作用。但集成运放带宽有限，所以目前有源电路的工作频率难以做的很高 59.给出了reg的Setup,Hold时间，求中间组合逻辑的delay范围答：$$T_{delay} &lt;T_{period}-T_{setup}-T_{hold}\\T_{period}&gt;T_{setup}+T_{hold}+T_{delay}(用来计算最高时钟频率)\\T_{co}=T_{setup}+T_{hold} $$ 触发器的传输延时 60.时钟周期为T,触发器D1的寄存器到输出时间（触发器延时Tco）最大为T1max，最小为T1min。组合逻辑电路最大延迟为T2max,最小为T2min。问，触发器D2的建立时间T3和保持时间应满足什么条件。答：T3setup&gt;T+T2max 时钟沿到来之前数据稳定的时间（越大越好），一个时钟周期T加上最大的逻辑延时。 T3hold&gt;T1min+T2min 时钟沿到来之后数据保持的最短时间，一定要大于最小的延时也就是T1min+T2min *61.给出某个一般时序电路图，有Tsetup, Tdelay, Tclk-&gt;q(Tco)，还有clock的delay，写出决定最大时钟的因素，同时给出表达式 答：T + Tclkdelay &gt; Tsetup + Tco + Tdelay Thold &gt; Tclkdelay + Tco + Tdelay;保持时间与时钟周期无关 *62.实现三分频电路，2/3分频电路(偶数倍分频，奇数倍分频) 答：图2是3分频电路，用JK-FF实现3分频很方便，不需要附加任何逻辑电路就能实现同步计数分频。但用D-FF实现3分频时，必须附加译码反馈电路，如图2所示的译码复位电路，强制计数状态返回到初始全零状态，就是用NOR门电路把Q2，Q1=“11B”的状态译码产生“H”电平复位脉冲，强迫FF1和FF2同时瞬间（在下一时钟输入Fi的脉冲到来之前）复零，于是Q2，Q1=“11B”状态仅瞬间作为“毛刺”存在而不影响分频的周期，这种“毛刺”仅在Q1中存在，实用中可能会造成错误，应当附加时钟同步电路或阻容低通滤波电路来滤除，或者仅使用Q2作为输出。D-FF的3分频，还可以用AND门对Q2，Q1译码来实现返回复零。 63.名词解释答：CMOS（Complementary Metal Oxide Semiconductor），互补金属氧化物半导体，电压控制的一种放大器件。是组成CMOS数字集成电路的基本单元。 MCU(Micro Controller Unit)中文名称为微控制单元，又称单片微型计算机(Single Chip Microcomputer)或者单片机，是指随着大规模集成电路的出现及其发展，将计算机的CPU、RAM、ROM、定时数计器和多种I/O接口集成在一片芯片上，形成芯片级的计算机，为不同的应用场合做不同组合控制。 RISC（reduced instruction set computer，精简指令集计算机）是一种执行较少类型计算机指令的微处理器，起源于80年代的MIPS主机（即RISC机），RISC机中采用的微处理器统称RISC处理器。这样一来，它能够以更快的速度执行操作（每秒执行更多百万条指令，即MIPS）。因为计算机执行每个指令类型都需要额外的晶体管和电路元件，计算机指令集越大就会使微处理器更复杂，执行操作也会更慢。 DSP（digital signal processor）是一种独特的微处理器，是以数字信号来处理大量信息的器件。其工作原理是接收模拟信号，转换为0或1的数字信号。再对数字信号进行修改、删除、强化，并在其他系统芯片中把数字数据解译回模拟数据或实际环境格式。它不仅具有可编程性，而且其实时运行速度可达每秒数以千万条复杂指令程序，远远超过通用微处理器，是数字化电子世界中日益重要的电脑芯片。它的强大数据处理能力和高运行速度，是最值得称道的两大特色。 FPGA（Field－Programmable Gate Array），即现场可编程门阵列，它是在PAL、GAL、CPLD等可编程器件的基础上进一步发展的产物。它是作为专用集成电路（ASIC）领域中的一种半定制电路而出现的，既解决了定制电路的不足，又克服了原有可编程器件门电路数有限的缺点。 ASIC:专用集成电路，它是面向专门用途的电路，专门为一个用户设计和制造的。根据一个用户的特定要求，能以低研制成本，短、交货周期供货的全定制，半定制集成电路。与门阵列等其它ASIC(Application Specific IC)相比，它们又具有设计开发周期短、设计制造成本低、开发工具先进、标准产品无需测试、质量稳定以及可实时在线检验等优点 PCI(Peripheral Component Interconnect) 外围组件互连，一种由英特尔（Intel）公司1991年推出的用于定义局部总线的标准。 ECC是“Error Correcting Code”的简写，中文名称是“错误检查和纠正”。ECC是一种能够实现“错误检查和纠正”的技术，ECC内存就是应用了这种技术的内存，一般多应用在服务器及图形工作站上，这将使整个电脑系统在工作时更趋于安全稳定。 DDR=Double Data Rate双倍速率同步动态随机存储器。严格的说DDR应该叫DDR SDRAM，人们习惯称为DDR，其中，SDRAM 是Synchronous Dynamic Random Access Memory的缩写，即同步动态随机存取存储器。 IRQ全称为Interrupt Request，即是“中断请求”的意思（以下使用IRQ称呼）。IRQ的作用就是在我们所用的电脑中，执行硬件中断请求的动作，用来停止其相关硬件的工作状态 USB ,是英文Universal Serial BUS（通用串行总线）的缩写，而其中文简称为“通串线，是一个外部总线标准，用于规范电脑与外部设备的连接和通讯。 BIOS是英文”Basic Input Output System”的缩略语，直译过来后中文名称就是”基本输入输出系统”。其实，它是一组固化到计算机内主板上一个ROM芯片上的程序，它保存着计算机最重要的基本输入输出的程序、系统设置信息、开机后自检程序和系统自启动程序。 其主要功能是为计算机提供最底层的、最直接的硬件设置和控制。 64.三极管的特性答： 65.用波形表示D触发器的功能答： 66.用传输门和倒向器搭建一个边沿触发器答： 67.用逻辑门画出D触发器。答：电平触发的D锁存器 边沿触发的,D触发器","link":"/2019/03/30/数字IC设计面试100题/"},{"title":"MIT论文1-Venture:用于概率元编程的可扩展平台","text":"《Venture: an extensible platform for probabilistic meta-programming》 Abstract Introduction 概率密度的元程序 2.1标准分布的密度和模拟器 2.2 贝叶斯规则作为概率元程序 2.3 隐藏马尔可夫模型的优化边缘密度 3.Probabilistic execution traces 3.1 跟踪作为概率空间的元素 3.2 概率执行跟踪的接口 3.3 Stochastic regeneration of trace fragments 4.Meta-programs for stochastic inference 4.1 Exact stochastic inference via rejection sampling 4.2 Approximate stochastic inference via Metropolis-Hastings 4.3 Custom model-specific inference meta-programs 4.3.1 Custom Metropolis-Hastings samplers 4.4 Scaling of stochastic regeneration for approximate inference 5 Stochastic procedures 5.1 Generic stochastic procedures 5.2 “Simple” stochastic procedures 5.3 “Tail-assessable” stochastic procedures Tradeoffs between different representations of the Beta-Bernoulli process 5.5 Memoization as a user-space stochastic procedure 6 Discussion Abstract本文描述了Venture，一个用于概率元编程的可扩展平台。 在Venture中，概率生成模型，概率密度函数和概率推理算法都是第一类对象。任何随机选择的Venture程序都可以被视为在程序可能执行的空间中定义的概率模型。这些概率模型程序也可以在记录它们所做的随机选择的同时运行。Venture中的建模和推理涉及两类额外的概率程序。第一，概率密度元程序部分地描述了概率模型程序的输入 - 输出行为。第二个随机推理元程序在给定随机约束的情况下识别模型程序的可能执行，并且通常使用密度元程序作为指导。与其他概率编程平台不同，Venture允许将模型程序，密度元程序和推理元程序编写为单个概率编程语言中的用户空间代码。Venture本质上是一种类似Lisp的高阶语言，增加了两个新颖的抽象：（i）概率执行轨迹，表示概率程序产生的随机选择序列的第一类对象，以及（ii）随机过程， 封装了允许简单概率分布，用户空间VentureScript程序和外来的概率程序所需的概率程序和元程序，它们被统一视为概率计算的组成部分。Venture还为执行跟踪片段的随机再生提供运行时支持，该跟踪片段利用在执行原始跟踪程序期间调用的所有随机过程的程序和元程序。本文描述了Venture的一个新的原型实现，结合了这些想法，并通过为Church和其他概率语言内置的原语和推理策略提供简洁的用户空间实现来说明Venture的灵活性。 Introduction概率编程是一个新兴领域，旨在使用编程语言和系统软件的思想形式化和简化概率建模和推理。几种早期的概率编程语言[5] [9] [13] [11] [3]侧重于概率生成建模，其中使用随机选择的程序来定义概率模型。在这些语言中，以及随后开发的大多数语言中，概率推断是通过用户空间程序无法替换或扩展的语言中的内置机制来完成的。 本文描述了Venture，一个用于概率元编程的可扩展平台。在Venture中，概率生成模型，概率密度函数和概率推理算法都是一级的对象。任何随机选择的Venture程序都可以被视为在程序可能执行的空间中定义的概率模型。这种“概率模型程序”也可以在记录它们所做的随机选择的同时运行。这种“跟踪执行”作为普通的原始过程暴露给最终用户，并且是用于概率推理的蒙特卡罗技术的核心，但对于检查和调试也是有用的。 本文使用术语“元程序”来指代描述，检查，创建和/或转换其他程序的文本或执行的程序。在Venture，到目前为止我们已经看到了两种类型的元程序的需求： 1.概率密度元程序：这些部分描述了概率模型程序的输入 - 输出行为。密度有时可以通过简单的分析公式给出，但有时它们本身由复杂的算法组成。例如，可以通过简单的动态程序计算来自隐马尔可夫模型[12]的输出符号序列的边际概率密度; 在Venture中，这个程序是一个有效的元程序，可以与一个程序相关联，该程序对潜在序列及其产生的观察结果进行采样。贝叶斯规则可以被视为用于评估后验密度的密度元程序，给出两个密度元程序 - 一个用于先验，一个用于可能性 - 以及（数据依赖）值的边际概率。先前和可能密度下的数据。 2.随机推理元程序。这些元程序在给定随机约束的情况下发现模型程序的可能执行，并且通常使用密度元程序作为指导。本论文包括一个拒绝抽样推理元程序，它可以执行受“足够随机”约束的任意模型程序，即对具有已知边界的已知边际概率密度的模型程序所代表的随机选择的约束（作为函数的函数） 输入，用于固定输出）。本论文还提出了使用Metropolis-Hastings方法构建的推理元程序，包括特定模型的专用采样器以及适用于同一类推理问题的通用近似推理算法。 与其他概率编程平台不同，Venture允许将模型程序，密度元程序和推理元程序编写为单个概率编程语言中的用户空间代码。通过这种方式，Venture旨在充分表达和扩展以用于通用目的。尽管Venture有一个用于建模和推理的内置标准库，但该库并不是为了提供高性能。相反，它旨在促进快速原型设计和运行时反射，以便进行测试和调试。一旦调试了概率计算，就可以通过用高性能本机代码替换关键组件来逐步优化它。这一目标仅在早期版本的Venture [6]中得到部分实现。 概率执行痕迹（PET），有时也简称为“痕迹”。PET是第一类对象，表示概率程序产生的随机选择序列。PET在Venture中作为可变存储的唯一本机形式，并将在程序执行过程中分配的动态“地址”映射到程序在这些地址处采用的清单值。Venture支持“平面轨迹”，它简单地记录了从地址到值的映射，遵循[14]，以及“依赖图形轨迹”，可以看作是有向图形模型的扩展[10] [6] [2]。这些跟踪可以通过统一接口访问，以（重新）生成程序片段的跟踪，从而促进推理元程序的开发。平面轨迹和依赖图轨迹表现出不同的渐近缩放行为，并且还支持不同的常数因子优化和运行时，使它们适用于不同类别的推理策略。 随机程序（SP）。SP用于封装简单概率分布，以及用户空间VentureScript程序和外部概率对象。SP由一组链接的程序和元程序组成，这些程序和元程序共同描述概率程序的各个方面，这些方程对于其在建模和推理中的使用非常重要。例如，SP是将模型程序与其相关密度和推理元程序链接起来的主要手段。SP被设计为允许简单的概率分布，用户空间VentureScript和外部概率程序被统一地视为复杂概率计算的构建块。 本文描述了Venture的一个新的原型实现，其中包含了这些想法，并通过为Church [3]以及其他概率语言内置的原语和推理策略提供简洁的用户空间实现来说明Venture的灵活性。 概率密度的元程序概率建模和推理的数学处理使用概率分布的多个表示。最常见的选择是使用概率密度函数：计算特定输出值的概率密度的数学函数（可能给定输入参数）。 在编程术语中，密度函数可以被视为从生成过程模拟的代码行为的不完整声明性规范。在Venture中，概率程序可以与表征其输入 - 输出密度的概率密度元程序相关联。这种关联对程序的行为进行了数学断言，后续的元程序如随机推理元程序可以依赖。 本节的其余部分将介绍如何将概率程序与Venture中的概率密度元程序相关联，以便其他元程序可以利用此信息。 2.1标准分布的密度和模拟器图2.1显示了表示标准正态分布的Venture程序，其中包括从分布模拟的过程和计算其（对数）概率密度函数的过程。 模拟过程使用众所周知的Box-Muller变换，该变换从标准正态分布生成示例X： 以下是BoX-Muller变换，推导的x的概率分布的原文： 作为第二个例子，图2.2显示了一个代表Gamma分布的Venture程序，包括模拟和密度程序。这里的模拟器是一个更复杂的程序，由于[8]实现了一个拒绝采样算法，用于生成具有形状参数α的Gamma随机变量y： 采样得到的x服从如下的分布，经过变换可以得到y的分布，服从参数为α的Gamma分布 在这些示例程序中，我们已经看到用于将模拟过程与密度相关联的原始make_elementary_sp。在后面的部分中，我们将看到这对于Venture的内置跟踪和推理工具进行互操作是如何有用的。同时，也可以编写直接使用密度模拟器的用户程序。 2.2 贝叶斯规则作为概率元程序某些形式的贝叶斯规则可以理解为概率密度元程序。回想一下，贝叶斯规则给出了条件概率密度的公式 就先前的p（x）而言，似然性p（y|x）和数据的边际概率p（y）。通常，p（y）不是以闭合形式给出，而是可以用x上的蒙特卡罗积分近似： 图2.3显示了实施蒙特卡罗方法的Venture计划。先验分布通过随机过程表示，该过程生成样本并具有相关的密度; 贝叶斯规则元程序使用来自该过程的样本来形成蒙特卡罗估计。似然分布由另一个随机过程表示，该过程仅需要具有概率密度。 为了说明，请考虑以下简单的正态-正态模型： 图2.3 一个元程序，通过贝叶斯规则计算后验密度，使用蒙特卡罗估计来计算边际密度。 我们观察y的值，并对后验分布p（x|y）感兴趣。我们将使用它作为一个运行示例来演示各种推理元程序; 这个问题虽然简单，但它可以作为一个有用的最小测试用例来检查各种推理策略的工作情况。 图2.4显示应用于此问题的贝叶斯规则元程序，观察值y = 4.0，使用N = 500个样本估算密度。 2.3 隐藏马尔可夫模型的优化边缘密度对于受限类别的概率模型，通常可以给出用于评估边际概率密度的优化算法。其中一些，例如隐马尔可夫模型的前向后向算法[12]，最初被视为具有里程碑意义的结果。Venture可以将这些算法创新表示为普通的用户空间元程序，并将它们附加到随机过程中。这样，无论何时请求随机过程的概率密度，都可以使用优化的算法。 图2.5显示了描述HMM模型的模拟器和密度程序的集合，包括模拟隐藏状态和观察序列的程序; 评估隐藏状态和观察的联合概率的程序; 使用前向算法计算观测的精确边际概率的过程; 以及使用两个密度程序直接计算给定观察的状态的后验概率的过程。 图2.5：一组元程序，用于从隐藏的马尔可夫模型进行模拟，并评估隐藏状态和观察结果的联合，边际和后验概率密度。 具体代码略，可以参考原论文 3.Probabilistic execution traces对于做出许多随机选择的较大概率程序，我们通常有兴趣不仅仅是用密度程序表征其输入 - 输出行为。我们希望捕获有关程序中发生的所有随机选择的信息，以便我们可以对其他部分的程序调节部分进行推断。 概率执行轨迹（PET），有时也缩写为“轨迹”，是一类新的第一类对象，表示概率程序所做的随机选择序列。PET明确表示概率程序对特定执行的明显行为。所有PET都包含从动态“地址”的映射，每个动态“地址”对应于执行某些概率程序的可区分位置，以及程序在这些地址处采用的清单值。因此，它们包含对程序源代码的补充信息，这隐含地表示程序的潜在行为。换句话说，程序的可能行为空间对应于可以通过跟踪其执行而生成的PET空间。 这种“跟踪执行”的概念对于Venture的核心能力至关重要：能够将任何概率程序视为在程序可能执行的空间中定义的概率模型。概率模型程序在可能的PET空间上定义概率模型，该模型可以通过追踪其执行来产生。Venture将“跟踪执行”作为语言中的普通原始程序公开，允许用户运行Venture程序并记录程序所做的随机选择序列。PET中的值可以通过简单的界面进行变异，该界面会反射回用户空间。改变PET中的值的能力是用于概率推理的蒙特卡罗技术的核心，但也可用于调试。图3.1显示了运行模型程序，捕获其执行跟踪以及通过探索替代执行历史来执行推理的示例。 Venture支持两种迹： 扁平迹。这些记录了从地址到值的映射，如下[14]。因为它们不表示依赖性信息，所以它们消耗更少的内存并支持广泛的常量性能优化。但是，由于它们不表示依赖性信息，因此如果更改某个其他值，则很难确定平面跟踪中的哪些值可能会失效。最简单的一般策略是在更改单个值后始终重新执行整个跟踪程序。该策略导致关键推理操作的不利渐近缩放，尤其是对于局部采样和基于梯度的优化算法。有关示例模型程序及其相应扁平迹线的表示，请参见图3.2。 依赖关系图跟踪。这些可以看作是有向图形模型的扩展[10] [6] [2]。因为它们包含依赖性信息，所以它们可用于重新执行跟踪程序的片段而无需重新执行整个程序。有关示例，请参见图3.3。 图3.2 图3.2：示例tricky硬币模型程序和示例程序的平面跟踪数据结构的打印输出。/ 2/0/1表达式是地址; 看主要文字。 在跟踪执行中，寻址方案用于为程序执行期间的每个随机选择分配名称，类似于[14]。在我们的方案中，为每个产生结果的子计算分配一个唯一的地址。地址是以下之一： Toplevel地址。每个顶层建模命令(assume, observe, or generate)触发跟踪子计算，该子计算与从1开始的递增序列号相关联。例如，在图3.2中的程序中，地址/ 1指的是假设表达式bernoulli（0.1 ），地址/ 3指的是观察到的表达bernoulli（weight）。 Subexpression地址。这对应于遍历抽象语法树中的边。子表达式地址由基地址后跟数字索引组成。当基地址引用过程应用程序的结果时，索引0选择正在应用的运符，索引1选择第一个操作数等。例如，/ 1/0指的是第一个顶层表达式的运算符 在程序中，和1/1到它的参数。 请求地址。一些随机程序在应用时将“请求”执行另一个程序片段。最常见的例子是复合过程，它要求执行它们的过程体。当这样的过程发出执行请求时，它给请求一个唯一的ID，以便为所请求的子程序分配地址r（sp_address，request_id），其中sp_address是创建或定义请求过程的地址。在复合过程的情况下，请求ID是呼叫站点的地址，因此该地址类似于调用堆栈地址。例如，由于在/ 2处应用过程，r（/ 1，/ 2）指的是在/ 1处定义的过程的主体的执行。 在依赖关系图跟踪中，依赖关系图中的节点与地址一一对应。因此，每个节点表示程序执行中的子计算的结果。 值得注意的是，PET也是Venture中唯一的可变存储本地形式。通过跟踪随机选择的执行来分配新的存储位置，并且可以为了执行概率推断之外的目的而进行突变。例如，可交换耦合的基元可以使用跟踪来存储和更新足够的统计信息。这允许用户空间VentureScript程序模拟在其本机实现中使用变异操作的外来原语的行为。 3.1 跟踪作为概率空间的元素执行跟踪代表一个点$\\rho$在所有可能的程序执行的示例空间$\\Omega$中。在形式上，我们定义为$\\Omega$从所有可能的随机过程应用程序到这些应用程序的结果的映射空间： 给定$\\rho$，产生结果的每个程序子计算对应于随机变量$f:\\Omega$V将样本空间中的点映射到可能值为V的空间。f（？）的值由程序以？为条件执行时对应于f的子计算结果确定，即使用？确定所有随机选择的结果。 因为跟踪是Venture中的第一类对象，所以可以使用与随机变量相对应的表达式，这些随机变量本身具有值。这允许随机推断程序表示为输出其他程序的随机执行轨迹的程序，其通常从与模型程序的无条件分布不同的分布中进行采样。通常，所述不同分布是对感兴趣条件分布的近似。 请注意，在上面的定义中，元素是抽象的无限维对象，它们代表潜在的程序执行，描述程序可以做出的每个可能的随机选择的结果。相反，通过跟踪执行Venture程序获得的PET对应于该程序的实现执行，其包含由程序做出的有限数量的随机选择（假设程序停止）。这两种追踪概念 - 粗略地说，执行“未来”和执行“历史” - 是不同的，但密切相关。鉴于未来的执行？和程序的源代码，有一个相应的执行历史，它是通过执行程序使用？获得的。作为发生的所有随机选择的随机性来源并记录这些选择的结果。换句话说，执行历史是限制？在程序执行期间实际实现的随机选择集。相反，如果给定通过跟踪程序执行而获得的执行历史，则可以通过使用随机数生成器状态来增强它来构建执行未来，该随机数生成器状态用于生成程序执行过程中实现的随机选择以外的任何随机选择的结果。 这两个跟踪概念一起提供了一个框架，用于修改程序的执行历史并根据这些修改重新运行程序。Venture以随机再生的形式提供此功能的一个版本（在第3.3节中描述）。随机再生可以被视为一种操作，它提取执行历史的一部分并将其转换为可能的执行未来的表示，然后对新的执行未来进行采样，然后可以将其合并回历史。 在本论文的其余部分，PET和跟踪将用于指代实现的执行历史和表示它们的数据结构。跟踪“未来”目前在随机再生中使用的对象之外没有明确的表示; 进一步统一这些概念是未来工作的有趣基础，但超出了本论文的范围。 3.2 概率执行跟踪的接口本节简要介绍Venture原型实现中概率执行跟踪支持的关键操作。在下文中，跟踪对象表示为T. a &lt;- next_base_address(T) 获取跟踪中的下一个未分配的基址，并递增下一个地址指针。 T &lt;- global_env(T) 获取跟踪的全部环境。 eval_request(T, base_address:a, expression: e, enviroment:T) 执行环境中表达式表示的程序片段并记录所有中间结果，将结果存储在给定的基址中。 v &lt;- value_at(T, address:a) 获取给定地址处跟踪中记录的值。 blind_global(T, symbol:s, address:a) 将跟踪的全局环境中的符号绑定到给定地址的结果。 a &lt;- find_symbol(T, enviroment: T, symbol, s) 在给定环境中查找符号并返回相应的地址 register_observation(T, address:a, value:v) 记录已观察到给定地址的结果为给定值。就其本身而言，这对执行跟踪没有影响，特别是不会修改存储在该地址的值以与观察一致。但是，各种元程序将检查不一致的跟踪并将它们视为零概率（例如，通过拒绝导致这种跟踪的转换）。 {(address:a, value:v)} &lt;- get_observation{T} 获取已记录的观察列表。这可以与value_at一起使用，以检查跟踪是否与所有观察结果一致。 set_value_at{T, address:a, value:v} 修改为地址结果存储的值。这主要用于低级推理程序而不是最终用户。 T* &lt;- clone_trace(T) 创建当前跟踪的副本 S &lt;- single_site_subproblem(T, address:a) 将跟踪的分区定义为子集，当重新生成单个随机选择（随机过程应用程序）时，这些子集将被重新生成并保留。这大致相当于[6,2]中“支架”的概念。 表3.1给出了我们原型中定义的跟踪数据结构中这些操作的渐近运行时间。 表3.1：跟踪操作的索引，具有渐近运行时。|e|是运行给定程序e所涉及的子操作的数量; |T|是概率执行轨迹的大小; |S|是子问题的大小，它由取决于建议值的下游随机选择的数量确定。 使用这些跟踪原语，可以定义建模指令以及推理过程和实用程序。有关常见建模指令的实现，请参见图3.4。推理编程将在第4节中介绍。 在我们的原型中，跟踪还提供了可以调用随机过程的关键行为的接口。例子包括应用随机程序; 评估对数密度; 还有模拟内核。这些实现细节超出了本论文的范围。 图3.4：假设，观察和生成的建模指令以宏的形式实现，扩展到上面定义的相应过程的应用程序。observe也是根据修改跟踪以使其满足给定约束的实用程序来定义的。该过程依赖于3.3节中描述的随机再生原语来修改跟踪并传播影响。 图可以见原文 3.3 Stochastic regeneration of trace fragments可以通过统一接口访问跟踪，以便随机（重新）生成程序片段的跟踪，从而促进推理元程序的开发。平面跟踪和依赖关系图跟踪表现出不同的渐近扩展行为（参见表3.2），并且还支持不同的常数因子优化和运行时，使它们适用于不同类别的推理策略。由于这些操作部分地决定了随机过程的要求，因此本章简要介绍了每个关键的随机再生操作。有关随机再生的其他观点，请参见[6]和[2]。 随机再生对子问题进行操作，子问题是跟踪的分区，用于重新生成和保留的随机选择的子集，以及重新生成的随机选择的提议分布。从概念上讲，子问题S将跟踪中的每个随机选择分配到三个集合中的一个（RS; CS; OS），其中 RS是“重新生成”的集合，由正在提议的随机选择或可能因提案而改变的值组成。子问题引起提议分布q（RS）。 CS是“约束”集合，由依赖于RS中的值的随机选择组成; 这些是依赖图中RS的子代。如果节点的输入可能因提议而改变，则节点成为CS的一部分，但它可以评估在给定新输入的情况下产生相同输出的密度或似然比。这些节点与评估提议的可能性相关。 OS是跟踪中不参与提议的其他节点 子问题以“局部后验”分布p（RS|CS; OS）$\\propto$ p（RS|OS）p（CS|RS; OS）为目标，并引起与目标密度和提议密度之间的比率对应的权重函数 请注意，此处理仅针对独立提案q。将非独立提案纳入该框架留待将来开展工作; 见[6]可能的方法 在实践中，子问题表示为从跟踪地址到内核的有序映射，这是随机过程元程序。内核实现了与子问题非常相似的接口，但代表了单个随机过程应用程序上的提议分布。R和C中的节点通过后者与约束内核相关联来区分，约束内核是一种特殊类型的内核，其提议分布总是产生相同的输出值。第5节更详细地描述了随机过程的内核。 与子问题交互的操作如下所述。在下面的描述中，ρ表示跟踪中的原始值，ξ表示建议的值，符号RS(ρ)表示对应于RS中的节点的ρ元素(类似的RS(ξ)。 （weight：w, trace_frament:t）&lt;- exact(T, subproblem:S) 改变迹线以去除对应于子问题S所针对的随机选择的值RS（ρ）。提取这些值并将它们存储在新分配的迹线片段中。返回对应于原始完成迹线的目标和建议概率密度之间的比率的（log）权重。 exact如图3.5所示。图3.5：Extract采用trace和子问题，从跟踪中提取子问题所针对的值，并返回对应于跟踪的目标和提议概率与原始值之间的比率的对数权重 (weight:w) &lt;- regen(T, subproblem:S) 根据提议分布q（RS），对子问题S所针对的随机选择采样新值RS（ξ）。返回与新值的目标概率密度和提议概率密度之间的比率相对应的（log）权重. 与exact返回的权重一起，这使得能够基于独立提议q计算MetropolisHastings在ρ和ξ之间转换的接受率。 图3.6：Regen采用跟踪和提取的子问题，使用新的随机性为目标变量建议新值，并返回跟踪的目标和建议概率与新值之间的比率的对数权重。 restore(T, subproblem:S, trace_fragment:t) 将t中的值返回到跟踪T中。这可以用于拒绝转换。restore如图3.7所示。 图3.7：Restore执行跟踪，提取的子问题以及extract提取的跟踪片段，并从跟踪片段的内容恢复跟踪的状态。 w* &lt;- weight_bound(T,subproblem:S) 返回T的再生权重的上限，适用于拒绝采样。 图3.8展示了tricky硬币示例中的随机再生示例。图3.8：图3.2中示例Tricky硬币模型的随机再生描述 4.Meta-programs for stochastic inference大多数概率编程语言都带有用于执行推理的内置的、不变的元程序，即根据一组用户指定的约束来识别概率模型程序的可能执行。在Venture中，这是一种被称为随机推理的计算。这些元程序可以作为使用内置元编程工具的普通用户空间VentureScript程序编写。 4.1 Exact stochastic inference via rejection sampling本节描述了拒绝抽样推理元程序，它可以执行受“足够随机”约束的任意模型程序。“足够随机”约束是那些约束由模型程序表示的随机选择的约束，这些模型程序具有已知边界的已知边际概率密度（作为输入的函数，对于固定输出）。这个拒绝抽样元程序在图4.1中的norma-normal模型上进行了演示，表明拒绝抽样的结果与分析后验分布相匹配。 图4.1：顶部：一个VentureScript程序，它定义一个简单的正态 - 正态模型，并使用拒绝采样得到一个观察到的y的x的后验样本。下图：从每个程序的500次独立运行中获得的样品的直方图，比较在拒绝取样引起的先前和后部分布下的x分布。真密度曲线以黄色显示：先前的N（0,1）和后$N(2, \\sqrt(1/2))$ 图4.2显示了拒绝采样元程序的实现，它利用了3.3节中讨论的随机再生原语。特别地，回想一下regen（T, S）根据提议分布q（RS, CS）生成新值RS（ξ），并返回权重 此外，weight_bound（T; S）计算（保守的）上限w*，使得 通过这两个操作，可以概述一个简单的拒绝采样算法，用于从子问题 - 局部后验p(RS|CS,OS)中进行采样： 计算子问题S的权重约束w*。 不断的执行（a）重新生成S，用新值ξ填充轨迹并获得权重w。（b）用概率exp（w-w ）= exp（w）= exp（w ），接受ξ。否则，拒绝并再试一次 图4.2中的元程序遵循此模板，另外还检查建议值ξ是否与跟踪中记录的observe语句一致; 如果有任何违规行为，该提案将立即被拒绝。确保了拒绝采样步骤总是以观察为条件进行采样，即使所选择的子问题否则会导致观察到的表达式被重新模拟。使用实用程序check_consistent执行此检查，该程序具有如图4.3所示的简单定义。 在normal-normal例子的情况下： RS是变量x，CS是观测变量y; 提议分布q（RS）只是x，N（0,1）的先验分布; 再生权重减小到对数似然log N（y; x, 1）; 并且权重界限是可能性的密度函数的最大值， 因此，拒绝采样元程序通过将由包括模型程序的正常SP提供的元程序（例如，模拟器和密度）组合在一起来恢复该模型的有效且直接的推理算法。 4.2 Approximate stochastic inference via Metropolis-Hastings本节描述了一个基于Metropolis-Hastings方法构建的推理元程序，它适用于与之前的拒绝抽样元程序相同的推理问题。与拒绝采样不同，拒绝采样在每次调用时从目标条件分布p（RSjCS; OS）返回精确样本，此元数据的输出分布在重复应用下渐近收敛到条件分布。这个元程序在图4.4中的正常 - 正常示例模型上进行了演示，表明采样分布接近后验分布，迭代次数更多。 图4.4：顶部：一个VentureScript程序，它在简单的normal-normal模型上使用重新模拟MH来获得x的近似后验样本。下图：通过对不同步数运行马尔可夫链获得的样本的直方图。随着步数的增加，分布接近目标后部（黄色）。 图4.5显示了Metropolis-Hastings元程序的实现。类似于拒绝元程序，它利用随机再生提出新的样本，但与拒绝不同的是，它不需要再生权重的绝对上界。相反，它使用Extract和regen返回的权重之间的比率(或在日志空间中的差值)： 图4.5：重新模拟MH元程序，根据推理子问题操作提取，重新生成和恢复来定义。 这可以用作接受率，产生在目标分布p（RS，CS|OS）上静止的马尔可夫链。图4.5中的实现遵循此方法。请注意，如果违反任何观察check_consistent将再次用于拒绝。此外，在拒绝转换的情况下，还原用于将跟踪返回到其原始状态。 4.3 Custom model-specific inference meta-programs因为可以在用户空间中编写推理，所以Venture可以将自定义推理算法编写为普通的用户空间程序。用户可以根据通用推理元程序的需求调整对问题的需求，但是一旦他们开发了测试用例并且在准确性和运行时成本方面更好地理解功能需求，就可以进行优化。 4.3.1 Custom Metropolis-Hastings samplers虽然Venture提供了一个基于子问题的随机再生建议的Metropolis-Hastings原语，但用户也可以编写他们自己的Metrois-Hastings程序，从而绕过Venture内置的子问题机制。定制过程可以通过避免一般重新生成策略的解释开销，或者利用分析(例如取消或简化接受率)来提高效率。 图4.6显示了一个这样的自定义推理过程的示例应用，该过程使用专门用于我们正常模型的运行示例的自定义高斯drift提议来实现Metropolis-Hastings采样器。在这种情况下，自定义过程在计算上更有效，因为它的代码专用于模型，并且在推理时更有效，因为提议分布更适合推理问题。 图4.6：顶部：VentureScript程序，它使用自定义用户定义的推理过程（如图4.7所示），用于具有高斯漂移建议的随机游走MH。下图：将从该推理程序获得的马尔可夫链的样本轨迹与图4.4中使用独立重新模拟提议的程序的样本轨迹进行比较的图。更高频率地接受高斯drift提议，这表明定制采样器更有效地探索迹线空间。 自定义高斯drift过程的实现如图4.7所示。该实现利用了高斯drift提议是对称的事实所带来的接受率的抵消： 图4.7：使用高斯漂移提议实现随机游走MH的自定义元程序，专门用于图4.6中的normal-normal模型。 然后，通过从Venture中查询正常程序的对数密度，可以直接计算该简化比率。 4.4 Scaling of stochastic regeneration for approximate inference平面轨迹和依赖图轨迹实现了随机再生的不同算法; 因此，基于随机再生的推理策略在两种类型的迹线上表现出不同的渐近缩放行为和常数因子运行时间。 图4.8比较了隐藏马尔可夫模型程序中基于单站点重新模拟的推理的每次迭代的运行时间，作为HMM中的时间步数的函数。 图4.8：HMM模型程序的推理速度的比较，作为HMM中的时间步数的函数。模型程序显示在左侧，以及展开memoized循环的程序版本，显示HMM中的步骤数如何影响程序长度。对单站点子问题进行推断，其为所有其他变量条件下的状态序列的一个元素提出新值。右边的图显示了子问题构建步骤和重新模拟步骤的时间。计时是在展开的程序上执行的。 推理的每次迭代涉及两种类型的操作：子问题构造，其中识别属于再生和约束集的节点; 和随机再生本身，它重放与这些节点对应的程序部分。 在平坦迹线中，两个操作都需要完整遍历迹线，因此在迹线的大小上是线性的。在第一遍中，程序中的每个子表达以程序执行顺序遍历，标记依赖于所提出的值的所有值（即，重新生成的集合RS）。再生在第二遍中完成，模拟程序的新执行，其中RS中的随机选择使用新的随机性重新采样。尽管似乎可以合并两个通道以使再生步骤不需要再次遍历整个程序，但是整体算法仍将表现出相同的线性缩放。 使用依存关系图跟踪，可以使用深度优先搜索从重新生成的节点到依赖它们的节点的依赖边来识别重新生成的集RS。一旦确认子问题，就可以使用只触及子问题所涉及的节点(及其父级)的遍历来进行重新生成。因此，推理的每次迭代只与子问题|S|的大小相同。然而，这是以更高的实现复杂性和内存开销为代价的。 5 Stochastic procedures随机过程（SP）用于封装简单的概率分布，以及用户空间VentureScript程序和外来概率对象。它们由程序和元程序的链接集合组成，这些程序和元程序共同描述概率程序的各个方面，这些程序对于其在建模和推理中的使用非常重要。例如，它们是将模型程序与其相关密度和推理元程序链接起来的主要手段。SP被设计为允许简单的概率分布，用户空间VentureScript和外部概率程序被统一地视为复杂概率计算的构建块。 Church和其他先前的概率编程语言专注于简单的概率分布，这些概率分布完全由标量值模拟器程序和分析概率密度函数指定。BayesDB [7]允许将更大类的概率对象视为封装的基元 - 即生成种群模型，其描述可以有条件地和无条件地模拟（或评估其密度）的多变量联合分布。Venture封装的概率对象类包括这两个类作为适当的子集。 本文主要研究三种随机过程。这些包括（i）适用于封装广泛类型的概率计算的通用接口，包括可交换随机过程，无可能性原语，以及（至少在原理上）其他概率编程语言的解释器和/或推理引擎; （ii）用于随机过程的简单接口，可以很容易地封装具有已知概率密度函数的概率对象; （iii）当该过程被称为“足够随机”时可以使用的简单接口的变体，即，具有输出本身是具有已知的有界概率密度的随机选择。 与这些类型相关的关键方法可归纳如下： 通用随机程序。这些包括（i）适用于随机生成输出的概率程序，（ii）用于提出新输出并使用旧输出评估其边际密度比的“提议核心”概率推理元程序，以及（iii）专门的“ 约束内核“概率推理元程序，它根据输出值与给定约束匹配的约束重新采样内部随机性。这三种功能允许SP封装任意概率程序，这些程序带有自己的内部潜在变量，以及自定义模拟，推理，密度评估和约束执行机制。 “简单”随机过程。当随机过程在输出上具有已知的边际概率密度时，当再模拟是有效的推理建议策略时，就有可能提供通用SP接口的基线实现。这个简化的接口还处理具有内部突变的SP，这些SPS导致对应于重复输出的随机变量之间的可交换耦合。 “尾部可评估的”随机程序。一些随机程序 - 例如代表具有噪声数据可能性的复杂概率生成模型的程序 - 具有难以处理的边际输出密度，但确实以其内部潜在变量为条件诱导“足够随机”的可能性。这是一个非常重要的特殊情况，VentureScript将其用作默认的随机过程构造语法 在UNIX环境中通过类比于软件包来考虑随机过程是有帮助的。这些包通常包括源代码，二进制文件，测试用例和文档的组合。所有这些组件的存在 - 远远不只是预编译的二进制文件 - 有助于最终用户重新组合软件，特别是熟悉相关约定的软件开发人员和系统管理员。在Venture的情况下，推理元程序和端到端应用程序可以扮演最终用户的角色，动态构建新的随机过程，修改源代码和/或运行时行为，以及使用和构建模型结果。 5.1 Generic stochastic procedures随机过程定义了联合分布p（{yi}; z|{xi}），其中xi是过程的第i个应用程序的输入，yi是第i个应用程序的输出，z表示在第i个应用程序期间做出的任何潜在随机选择。除输出yi之外的SP的应用。 在给定z的情况下，yi不需要是独立的，甚至是条件独立的; 这允许表示可交换耦合过程的SP，例如折叠共轭模型。然而，Venture的随机再生算法假设应用程序是可交换的，因此它们可以以不同的顺序重新生成，同时保留相同的分布属性。 随机过程可以具有可变的内部状态，其可以用于记录潜在随机选择的结果或者通过维持先前应用的充分统计来实现可交换的耦合。虽然PET是Venture中直接可用的唯一本机形式的可变存储，但可以在内部绑定使用可变状态的外部过程，或者暴露用户定义的SP可以使用的可变状态源。 SP可以通过提供一个或多个内核来促进推理编程，所述内核在其随机状态空间（fyig; z）的子集上操作。内核类似于跟踪子问题，并且具有非常相似的契约，允许在SP应用程序期间进行随机选择并重新提出。 可以通过make_sp操作创建一般随机过程： P &lt;- make_sp(metadict_expression:e) 从e指定的元程序集合中创建一个随机过程，该过程应该计算为方法名称和值的字典。 认可的方法包括： y &lt;- apply(p, trace_handle:H,application_id: i, input:x) 将过程应用于输入x，产生输出y并可能记录潜在的选择z。这导致分布p（yi; zi|xi; P）。 跟踪句柄H是周围跟踪的接口，可用于对跟踪的执行引擎进行回调; 请参阅下面的跟踪句柄方法。 l &lt;- log_density(P, output:y, inputs:x) （可选）评估对数密度log p（y|x, P）。并非所有随机程序都实现此方法; 那些被称为可评估程序。 k &lt;- proposal_kernal(P, trace_handle:H, application_id:i) 构造一个内核，该内核对P的先前应用程序的结果进行操作（由应用程序id i给出），表示从该应用程序的可能结果的空间中采样的提议分布q。q的支持应该包括p的支持（仅限于与所选应用程序相关联的SP随机状态的子集）。准选择是q = p，即从先前提出。 内核K应该是符合内核接口的方法名称和值的字典（如下所述）。 K &lt;- constrain_kernal(P, trace_handle:H, application_id:i, constraint_value:y) 构造一个内核，该内核对P的先前应用程序的结果进行操作（由应用程序id i给出），表示其输出的边际分布是值y的delta分布的提议。换句话说，约束内核重新采样受输出值约束的内部随机性（如果有的话）。 内核K表示由SP做出的随机选择子集的提议分布，类似于跟踪的子问题。内核有以下方法： (log_weight:w, trace_fragment:F) &lt;- extract(K, output:y, input:x) 从SP的内部状态中提取目标随机选择的值。返回对应于原始值的目标和建议概率之间的比率的对数权重w（包括任何提取的潜在值） 以及跟踪片段F，它是一个对象，可用于恢复提取前存在的SP状态。 (log_weight:w, output:y) &lt;- regen(K, inputs:x) 使用新的随机性为目标随机选择建议新值。返回日志权重w，以获取新值的目标和提议概率之间的比率 以及新的输出值y。 （output:y） &lt;- restore(K, input:x, trace_frament:F) 使用extract返回的跟踪片段恢复SP的状态。 w* &lt;- weight_bound(K, input:x, input_mask: m) 返回此内核的再生权重w的上限，用于计算子问题的拒绝界限。 输入掩码m是布尔值的列表，其长度与x相同，其对于每个输入参数指示在计算边界时是否应该将其视为固定的或变化的。 跟踪句柄H提供以下与周围轨迹交互的方法： a &lt;- request_address(H, request_id:i) 返回从给定请求ID派生的跟踪地址，适合与以下方法一起使用。请求ID可以是SP用于识别其请求的子程序执行的任何Venture值。例如，复合过程使用调用站点的地址（即application_id）作为请求ID请求执行其正文，而mem（在5.5节中描述）使用输入参数的值作为请求ID。 z &lt;- eval_request(H, request_id:i, expression:e, enviroment:T) 执行环境中表达式表示的程序片段。这是环境跟踪eval_request方法的接口，允许SP对跟踪的解释器进行回调。 z &lt;- value_at(H, request_id:i) 获取给定地址处跟踪中记录的值。这是环境跟踪的value_at方法的接口。 uneval_request(H, request_id:i) 撤消执行请求。这以反向执行顺序遍历程序片段，在所有SP应用程序上调用extract。 z &lt;- restore_request(H, request_id:i) 恢复未评估的请求，以正向顺序遍历程序片段并在所有SP应用程序上调用还原。 执行请求为SP提供了一个集成机制，可以对解释器进行回调，从而实现更高阶的过程，如mem（参见第5.5节），eval，apply和map。重要的是，这些回调由与原始SP应用程序相同的跟踪解释器执行，因此在执行期间进行的依赖关系和随机选择将被公开并可供跟踪元程序检查。例如，这允许依赖性信息通过复合过程的主体和高阶过程的应用来传播。 5.2 “Simple” stochastic procedures当随机过程在输出上具有已知的边际概率密度时，并且当重新模拟是用于推断的有效提议策略时，可以提供通用SP接口的基线实现。 可以使用make_elementary_sp过程创建这样的SP： p &lt;- make_elementary_sp(metadict_expression: e) 从e指定的元程序集合中创建随机过程。该集合预计将实现以下简化的界面，该界面假定SP没有“潜在”结构并且表示具有用于模拟和评估密度的过程的分布p（y|x）。 make_elementary_sp期望的接口是： y &lt;- simulate(P, inputs:x) Return a sample y ~ p(.|x). l &lt;- log_density(P, output:y, input:x) Evaluate the log density log p(y|x). l* &lt;- log_density_bound(P, output: y, inputs: x, input_mask: m) 评估对数密度log p（y|x）的上限。 输入掩码m是布尔值的列表，其长度与x相同，其对于每个输入参数指示在计算边界时是否应该将其视为固定的或变化的。 incorporate(P, output: y, inputs: x) 可选：对于维护其应用程序的足够统计信息的SP，记录输入 - 输出对（x; y）。这在每次apply，regen和restore时调用。 unincorporate(P, output: y, inputs: x) 可选：合并的反转：删除输入 - 输出对（x; y），就好像该应用程序从未发生过一样。这在每个exact的开头都被调用。 可以使用以下方法定义通用SP接口：粗略地，apply调用simulate; 提议内核使用模拟实现重新模拟提议，约束内核使用log_density返回可能性权重。如果定义了合并和非合并，则在每次apply/regen/restore结束时和每个extract的开头分别调用它们 图5.1给出了一个随机过程的例子，该过程从beta分布中取样，首先作为“bare”复合过程，然后作为使用make_elementary_sp定义的过程，同时提供simulate和log_density。尽管两个过程在直接调用以生成样本时具有相同的输出行为，但是跟踪和推理元程序对它们的处理方式不同： 裸复合程序my_beta_1被视为其各部分的总和，每次调用主体中的gamma作为单独的随机选择记录，并且beta程序的输出作为从两个gamma样本计算的值。该过程缺少任何有趣的辅助元程序，特别是输出密度或约束内核，因此其输出不能约束到给定值。 相比之下，my_beta_2被视为单个单元。即使它的模拟器主体仍然调用gamma，这些细节也封装在过程中而不是暴露给跟踪。Instead，它有一个log_density，它表征输出的边际分布，允许它接受输出的约束，并报告从给定输入获得输出值的相对可能性，就像密度函数附带的内置基元一样。 通过这种方式，随机过程为跟踪程序提供了一种抽象方法，就像“normal”过程对未跟踪程序所做的那样。 5.3 “Tail-assessable” stochastic procedures上一节中描述的随机过程是“可评估的”随机过程，因为它们带有易于处理的程序来评估其输出的边际概率密度。 一些随机程序 - 例如代表具有噪声数据可能性的复杂概率生成模型的程序 - 具有难以处理的边际输出密度，但确实以其内部潜在变量为条件诱导“足够随机”的可能性。这是一个非常重要的特殊情况，VentureScript将其用作默认的随机过程构造语法 如果有以下条件，程序f被称为“tailor accessable” 这类程序很有意思，因为即使边际密度难以处理，仍然可以实现约束内核，允许在拒绝采样，重要性采样和Metropolis-Hastings样式提议中对输出y进行调节。 要了解如何为第二种情况构造约束内核，请考虑联合空间（z，y），其目标分布由下式给出： 其中ph和pg分别是由h和g引起的概率密度（注意这些密度不一定易于计算）。然后在（z; y）上定义以下提案分布： 从这个分布中很容易模拟：采样一个新的z~h（x），并设置y = yobs。密度比是 如果密度pg易于计算（即g是可评估的），那么我们就完成了 - 我们有一个从联合空间（z; y）提出样本的程序，我们可以评估我们的提案分布和 目标分布。如果不是，g是假设可以尾部评估的，所以我们也可以递归地为它的输出构造一个约束内核。在递归终止的任何地方，我们都可以模拟和评估密度比（可能在扩展空间（z; y; w; :: :)，如果g也有内部潜伏）。 在VentureScript中，可以使用proc语句构造具有这些语义的复合过程： P &lt;- proc(parameters:p, body:e) 使用给定的参数和主体创建随机过程。这是来自Lisp类语言的lambda的概率类比。 语法是：123proc(x){g(h(x))} 其中一般可能有零个或多个参数（这里，x是唯一的参数），而body是一个在尾部位置有一个过程调用的表达式，其运算符（此处为g）是一个可约束的过程 图5.2显示了实现相同beta-bernoulli过程的两个随机过程定义，一个定义为“bare”复合过程，一个定义为使用proc的尾部可评估过程，以及使用通用make_sp接口的等效扩展定义，显示 差异。定义为裸复合过程的版本没有密度或约束内核元程序，因此其输出不受约束。相反，使用proc定义的版本可以通过委托给其程序体中调用的bernoulli SP的密度元程序来约束。 图5.2：左：作为裸化合物的β-Bernoulli过程的朴素定义，它绘制θ~Beta（a; b）并返回一个翻转一个重量为θ的硬币的闭包。与图5.1中的my_beta_1一样，此闭包没有密度元程序，因此其输出不受约束。右：使用proc的等价定义，这是一个元程序，它采用可尾部评估的过程并为其生成约束内核，它将翻转过程的密度作为其权重返回。底部：使用完整的make_sp接口定义的结果SP的扩展版本 图见原文 Tradeoffs between different representations of the Beta-Bernoulli process随机过程接口使得以多种不同方式表示单个随机过程变得容易。概率程序员可以选择将随机变量暴露给Venture; 代表他们，但保持他们的外围; 或通过边缘化将其摧毁。概率编程人员还可以在VentureScript和更快（但可能更不透明）的本机代码之间选择不同的边界。这种灵活性最终可能对可实现的推理性能产生重大影响。 本节中的示例使用Beta-Bernoulli过程探索了这种自由度，可以根据单个潜在硬币重量来考虑这一过程，从而产生可数无限的硬币翻转序列。这个过程最直接的实现是图5.2中的版本，包含一个复合过程，它关闭一个表示硬币权重weight的变量theta。 此外，我们考虑Beta-Bernoulli过程的两个优化实现。第一个，如图5.4所示，是一个“折叠”表示，其中潜在的硬币重量被整合出来。该程序保持了之前硬币翻转的足够统计数据，并使用它们来模拟（并评估）下一次硬币翻转的后期预测分布，利用Beta和Bernoulli分布的共轭。 第二个实现，如图5.6所示，是一个未折叠的表示，因此它对潜在的硬币重量进行采样而不是将其整合出来。 然而，它还保留了足够的统计数据，并以不同的方式利用Beta-Bernoulli共轭，提供了一个自定义的元程序，可以根据需要从后缀共同重新计算硬币重量。 图5.6：beta-Bernoulli模型的未折叠实现，作为具有共轭Gibbs核的有状态过程。与图5.4中的折叠版本一样，它保持了其应用程序的足够统计数据，这里用于从其共轭后验中精确地对θ进行采样。此Gibbs内核作为SP的自定义元程序提供，可以作为推理程序的一部分进行调用。 图5.4：将collasped的β-Bernoulli模型实现为有状态过程，该过程维护足够的统计量N，应用过程的次数，以及K，过程返回的次数为真。该实现对其可变状态使用通用计数器数据结构，该结构公开了读取，递增和递减操作。 表5.1展示了所描述和比较的表示的总结，图5.3比较了运行时和示例的准确度。 表5.1：β-Bernoulli变体的比较。“Runtime”列描述了对θ进行一轮推断（如果适用）然后模拟或合并新观察的运行时复杂性，其中N是已合并的观测总数。 图5.3：top：beta-Bernoulli模型的示例应用。weight不详的硬币翻转五次。观察翻转并逐个合并，并保留所得的对数似然增量。下图：运行时与对数似然权重的图，改变了β-Bernoulli程序的实施以及每次观察之间进行的推断量。请注意，折叠实现获得模型下数据的真实边际可能性，而其他实现产生噪声近似值，通过更好的推断变得更准确。 图见原文 5.5 Memoization as a user-space stochastic procedureMemoization是高阶程序的规范应用。memoizer是一个过程，它将一个过程作为输入，并返回一个新的过程，在计算它们时在内部缓存值。这可以节省计算时间，特别是对于递归过程，以空间为代价。在概率编程的设置中，memoization可以用作许多有趣的半参数贝叶斯模型的构建块[3]。然而，因为memoization是一个更高阶的过程，它不适合早期实现Church [3,14]的“基本随机过程”的简单模板。本节通过给出用户空间实现memoization来说明Venture的灵活性和随机过程接口。 memoizer的实现如图5.7所示。当应用memoized SP时，它首先查找输入参数并返回现有值（如果有），否则委托给unmemoized SP 图5.7：将memoization实现为用户空间过程，使用外部可变计数器实现引用计数，eval_request对原始未标记SP f进行跟踪调用 图片见论文 该实现依赖于前面描述的执行请求，该请求允许它对原始未标记的SP进行跟踪调用。这是通过在f绑定到原始SP的地址的环境中请求执行形式为f（x）的程序片段来完成的。 使用执行请求允许已记忆的SP挂钩到依赖性跟踪机制，例如，当提交到备忘SP的主体中的随机选择时，该选择会影响将返回的值，SP的所有应用程序 通知相同的输入参数，以便它们可以传播新值。这种行为可以由SP定义一个额外的内核propagating_kernel来控制，该内核通过依赖关系跟踪实现用作优化 图5.8显示了使用memoization定义HMM的隐藏状态序列的示例模型程序。 x（t）是一个记忆值，指的是第t个时间步的状态。 通过这种方式，memoization定义了一个无限延迟的随机变量序列，只有在必要时才会实例化。 图5.8：具有二进制状态和观察的HMM的实现，使用mem来记忆状态序列 6 Discussion本文描述了Venture的一个新原型实现，Venture是一个概率元编程平台，解决了其他概率编程语言表达的基本限制。使用Venture，可以将用于描述概率密度函数和执行推理的元程序编写为普通用户空间代码。此外，该语言具有足够的表达能力，允许外国原语和中介语复合程序表示看似同类的概率对象。这些功能仅在早期版本的Venture中部分实现。通过展示如何为必须内置于其他概率语言的对象和操作的用户空间实现来说明所产生的灵活性。 Venture的一个限制是它目前缺少（i）简单的元循环解释器和（ii）形式语义。这两者都是构建Venture行为不完整模型的补充方法。每一个都可以用来澄清语言的设计，帮助进行性能工程，并支持开发更复杂的建模和推理元程序。这两种方法也可以帮助揭示设计缺陷和实施缺陷，并为评估潜在的补救措施提供具体的基础。依赖跟踪和随机再生的元循环实现也可以为调试提供强大的工具。考虑到Venture程序员可以使用建模和推理来提供机器帮助，通过询问“哪些随机选择可能导致此推理元程序显示此特定模型程序跟踪？”来查找指示错误的不太可能的边缘情况。 性能工程是未来工作的关键领域。VentureScript的当前原型实现比几个以前版本的Venture慢。这不是实际应用的基本障碍，但由于开发周期缓慢，它确实阻碍了应用工作。事实上，VentureScript是高阶的，并且在本机代码和VentureScript之间保持对称，这意味着增量编译 - 可能是VentureScript到VentureScript转换，除了VentureScript到本机代码编译器之外 - 可能是一种吸引人的策略。例如，许多模型具有相对静态的结构，因此Venture的通用子问题构造和再生算法总是在跟踪图中的节点上执行类似的遍历。专门的编译器可以消除该遍历，从而使更高效的程序专门用于该模型和推理子问题，使用较低级别的跟踪操作来直接读取和改变跟踪并计算适当的似然比。 未来工作的另一个关键领域是开发特定于领域的语言和用于概率建模和推理的库。 VentureScript是目前唯一的内置语言，它实现了关于如何组合指定模型和推理方案的特定假设。 它为用户提供了一种用元数据注解模型，用元数据构造有意义的子问题，并结合通用推理库例程和自定义推理策略来解决这些子问题的方法。 VentureScript在很大程度上依赖于随机过程接口的约定，但它只是设计空间中的一点，而且这些约定本身可能不是最优的。 至少，需要扩展这些约定，以定义添加其他元程序(如梯度信息)的最佳实践，这些元程序是基于优化的推理和变分技术的关键。 还必须探讨推理程序的静态检查，并尝试开发具有适当的可靠性或完备性的正式保证的推理库。 本文证明了用一种简单的高阶语言来表示随机变量、密度函数和推理算法的概率规划平台是可行的。 关键思想包括扩充Lisp以支持(I)对程序行为的具体化和反思，(Ii)将概率程序和元程序链接到单个包中。 与其他概率编程平台相比，这种对反射元编程的关注带来了更大的灵活性和可扩展性。 它还可能提出新的方法来理解概率规划的基本技术挑战。 考虑UNIX系列操作系统。 UNIX通常用于组装和维护交互程序的集合，包括监视和修改彼此的运行时行为的程序。 这些程序通过共享文件系统和显式回调等机制进行通信。 可以通过反射机制(如strace和gdb)检查正在运行的UNIX程序的内部行为和可变状态的关键方面。 其中一些机制与Venture中用于反射和元编程的工具非常相似，UNIX中的堆分配内存扮演着类似于概率执行跟踪的角色。 UNIX性能工程的思想因此可能与Venture相关。 也可能是来自操作系统和其他形式的系统软件的思想，而不仅仅是编程语言和单语言编程系统，可以帮助我们形式化和自动化概率建模和推理的关键方面。","link":"/2019/04/04/MIT论文1-Venture-用于概率元编程的可扩展平台/"}],"tags":[{"name":"Linux使用","slug":"Linux使用","link":"/tags/Linux使用/"},{"name":"项目","slug":"项目","link":"/tags/项目/"},{"name":"python使用过程中的记录","slug":"python使用过程中的记录","link":"/tags/python使用过程中的记录/"},{"name":"博客有关","slug":"博客有关","link":"/tags/博客有关/"},{"name":"实用工具","slug":"实用工具","link":"/tags/实用工具/"},{"name":"概率编程","slug":"概率编程","link":"/tags/概率编程/"},{"name":"博客遇到的问题","slug":"博客遇到的问题","link":"/tags/博客遇到的问题/"},{"name":"工作日志","slug":"工作日志","link":"/tags/工作日志/"},{"name":"求职","slug":"求职","link":"/tags/求职/"},{"name":"概率计算","slug":"概率计算","link":"/tags/概率计算/"}],"categories":[{"name":"其他","slug":"其他","link":"/categories/其他/"},{"name":"Intel与概率计算","slug":"Intel与概率计算","link":"/categories/Intel与概率计算/"},{"name":"probabilistic programming","slug":"probabilistic-programming","link":"/categories/probabilistic-programming/"},{"name":"工作周报与报告","slug":"工作周报与报告","link":"/categories/工作周报与报告/"},{"name":"数字IC设计","slug":"数字IC设计","link":"/categories/数字IC设计/"}]}